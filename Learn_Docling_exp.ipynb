{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tejusn/doc-ai-exp/blob/main/Learn_Docling_exp.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bee18bb3"
      },
      "source": [
        "## Setup"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "04364670",
        "outputId": "c53492fa-2335-4133-96c6-183c1d179862"
      },
      "source": [
        "!pip install docling"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting docling\n",
            "  Downloading docling-2.58.0-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from docling) (2.11.10)\n",
            "Collecting docling-core<3.0.0,>=2.48.2 (from docling-core[chunking]<3.0.0,>=2.48.2->docling)\n",
            "  Downloading docling_core-2.49.0-py3-none-any.whl.metadata (6.7 kB)\n",
            "Collecting docling-parse<5.0.0,>=4.7.0 (from docling)\n",
            "  Downloading docling_parse-4.7.0-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (10 kB)\n",
            "Collecting docling-ibm-models<4,>=3.9.1 (from docling)\n",
            "  Downloading docling_ibm_models-3.10.1-py3-none-any.whl.metadata (7.3 kB)\n",
            "Collecting filetype<2.0.0,>=1.2.0 (from docling)\n",
            "  Downloading filetype-1.2.0-py2.py3-none-any.whl.metadata (6.5 kB)\n",
            "Collecting pypdfium2!=4.30.1,<5.0.0,>=4.30.0 (from docling)\n",
            "  Downloading pypdfium2-4.30.0-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (48 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m48.5/48.5 kB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pydantic-settings<3.0.0,>=2.3.0 in /usr/local/lib/python3.12/dist-packages (from docling) (2.11.0)\n",
            "Requirement already satisfied: huggingface_hub<1,>=0.23 in /usr/local/lib/python3.12/dist-packages (from docling) (0.35.3)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.32.2 in /usr/local/lib/python3.12/dist-packages (from docling) (2.32.4)\n",
            "Collecting rapidocr<4.0.0,>=3.3 (from docling)\n",
            "  Downloading rapidocr-3.4.2-py3-none-any.whl.metadata (1.2 kB)\n",
            "Requirement already satisfied: certifi>=2024.7.4 in /usr/local/lib/python3.12/dist-packages (from docling) (2025.10.5)\n",
            "Collecting rtree<2.0.0,>=1.3.0 (from docling)\n",
            "  Downloading rtree-1.4.1-py3-none-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl.metadata (2.1 kB)\n",
            "Collecting typer<0.20.0,>=0.12.5 (from docling)\n",
            "  Downloading typer-0.19.2-py3-none-any.whl.metadata (16 kB)\n",
            "Collecting python-docx<2.0.0,>=1.1.2 (from docling)\n",
            "  Downloading python_docx-1.2.0-py3-none-any.whl.metadata (2.0 kB)\n",
            "Collecting python-pptx<2.0.0,>=1.0.2 (from docling)\n",
            "  Downloading python_pptx-1.0.2-py3-none-any.whl.metadata (2.5 kB)\n",
            "Requirement already satisfied: beautifulsoup4<5.0.0,>=4.12.3 in /usr/local/lib/python3.12/dist-packages (from docling) (4.13.5)\n",
            "Requirement already satisfied: pandas<3.0.0,>=2.1.4 in /usr/local/lib/python3.12/dist-packages (from docling) (2.2.2)\n",
            "Collecting marko<3.0.0,>=2.1.2 (from docling)\n",
            "  Downloading marko-2.2.1-py3-none-any.whl.metadata (4.5 kB)\n",
            "Requirement already satisfied: openpyxl<4.0.0,>=3.1.5 in /usr/local/lib/python3.12/dist-packages (from docling) (3.1.5)\n",
            "Requirement already satisfied: lxml<6.0.0,>=4.0.0 in /usr/local/lib/python3.12/dist-packages (from docling) (5.4.0)\n",
            "Requirement already satisfied: pillow<12.0.0,>=10.0.0 in /usr/local/lib/python3.12/dist-packages (from docling) (11.3.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.65.0 in /usr/local/lib/python3.12/dist-packages (from docling) (4.67.1)\n",
            "Requirement already satisfied: pluggy<2.0.0,>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from docling) (1.6.0)\n",
            "Collecting pylatexenc<3.0,>=2.10 (from docling)\n",
            "  Downloading pylatexenc-2.10.tar.gz (162 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m162.6/162.6 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: scipy<2.0.0,>=1.6.0 in /usr/local/lib/python3.12/dist-packages (from docling) (1.16.2)\n",
            "Requirement already satisfied: accelerate<2,>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from docling) (1.11.0)\n",
            "Collecting polyfactory>=2.22.2 (from docling)\n",
            "  Downloading polyfactory-2.22.3-py3-none-any.whl.metadata (27 kB)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from accelerate<2,>=1.0.0->docling) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from accelerate<2,>=1.0.0->docling) (25.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.12/dist-packages (from accelerate<2,>=1.0.0->docling) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.12/dist-packages (from accelerate<2,>=1.0.0->docling) (6.0.3)\n",
            "Requirement already satisfied: torch>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from accelerate<2,>=1.0.0->docling) (2.8.0+cu126)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from accelerate<2,>=1.0.0->docling) (0.6.2)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.12/dist-packages (from beautifulsoup4<5.0.0,>=4.12.3->docling) (2.8)\n",
            "Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.12/dist-packages (from beautifulsoup4<5.0.0,>=4.12.3->docling) (4.15.0)\n",
            "Requirement already satisfied: jsonschema<5.0.0,>=4.16.0 in /usr/local/lib/python3.12/dist-packages (from docling-core<3.0.0,>=2.48.2->docling-core[chunking]<3.0.0,>=2.48.2->docling) (4.25.1)\n",
            "Collecting jsonref<2.0.0,>=1.1.0 (from docling-core<3.0.0,>=2.48.2->docling-core[chunking]<3.0.0,>=2.48.2->docling)\n",
            "  Downloading jsonref-1.1.0-py3-none-any.whl.metadata (2.7 kB)\n",
            "Requirement already satisfied: tabulate<0.10.0,>=0.9.0 in /usr/local/lib/python3.12/dist-packages (from docling-core<3.0.0,>=2.48.2->docling-core[chunking]<3.0.0,>=2.48.2->docling) (0.9.0)\n",
            "Collecting latex2mathml<4.0.0,>=3.77.0 (from docling-core<3.0.0,>=2.48.2->docling-core[chunking]<3.0.0,>=2.48.2->docling)\n",
            "  Downloading latex2mathml-3.78.1-py3-none-any.whl.metadata (15 kB)\n",
            "Collecting semchunk<3.0.0,>=2.2.0 (from docling-core[chunking]<3.0.0,>=2.48.2->docling)\n",
            "  Downloading semchunk-2.2.2-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: transformers<5.0.0,>=4.34.0 in /usr/local/lib/python3.12/dist-packages (from docling-core[chunking]<3.0.0,>=2.48.2->docling) (4.57.1)\n",
            "Requirement already satisfied: torchvision<1,>=0 in /usr/local/lib/python3.12/dist-packages (from docling-ibm-models<4,>=3.9.1->docling) (0.23.0+cu126)\n",
            "Collecting jsonlines<5.0.0,>=3.1.0 (from docling-ibm-models<4,>=3.9.1->docling)\n",
            "  Downloading jsonlines-4.0.0-py3-none-any.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from huggingface_hub<1,>=0.23->docling) (3.20.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub<1,>=0.23->docling) (2025.3.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub<1,>=0.23->docling) (1.1.10)\n",
            "Requirement already satisfied: et-xmlfile in /usr/local/lib/python3.12/dist-packages (from openpyxl<4.0.0,>=3.1.5->docling) (2.0.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas<3.0.0,>=2.1.4->docling) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas<3.0.0,>=2.1.4->docling) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas<3.0.0,>=2.1.4->docling) (2025.2)\n",
            "Collecting faker>=5.0.0 (from polyfactory>=2.22.2->docling)\n",
            "  Downloading faker-37.12.0-py3-none-any.whl.metadata (15 kB)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.0.0->docling) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.0.0->docling) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.0.0->docling) (0.4.2)\n",
            "Requirement already satisfied: python-dotenv>=0.21.0 in /usr/local/lib/python3.12/dist-packages (from pydantic-settings<3.0.0,>=2.3.0->docling) (1.1.1)\n",
            "Collecting XlsxWriter>=0.5.7 (from python-pptx<2.0.0,>=1.0.2->docling)\n",
            "  Downloading xlsxwriter-3.2.9-py3-none-any.whl.metadata (2.7 kB)\n",
            "Collecting pyclipper>=1.2.0 (from rapidocr<4.0.0,>=3.3->docling)\n",
            "  Downloading pyclipper-1.3.0.post6-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.0 kB)\n",
            "Requirement already satisfied: opencv-python>=4.5.1.48 in /usr/local/lib/python3.12/dist-packages (from rapidocr<4.0.0,>=3.3->docling) (4.12.0.88)\n",
            "Requirement already satisfied: six>=1.15.0 in /usr/local/lib/python3.12/dist-packages (from rapidocr<4.0.0,>=3.3->docling) (1.17.0)\n",
            "Requirement already satisfied: Shapely!=2.0.4,>=1.7.1 in /usr/local/lib/python3.12/dist-packages (from rapidocr<4.0.0,>=3.3->docling) (2.1.2)\n",
            "Requirement already satisfied: omegaconf in /usr/local/lib/python3.12/dist-packages (from rapidocr<4.0.0,>=3.3->docling) (2.3.0)\n",
            "Collecting colorlog (from rapidocr<4.0.0,>=3.3->docling)\n",
            "  Downloading colorlog-6.10.1-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.32.2->docling) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.32.2->docling) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.32.2->docling) (2.5.0)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.12/dist-packages (from typer<0.20.0,>=0.12.5->docling) (8.3.0)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.12/dist-packages (from typer<0.20.0,>=0.12.5->docling) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.12/dist-packages (from typer<0.20.0,>=0.12.5->docling) (13.9.4)\n",
            "Requirement already satisfied: attrs>=19.2.0 in /usr/local/lib/python3.12/dist-packages (from jsonlines<5.0.0,>=3.1.0->docling-ibm-models<4,>=3.9.1->docling) (25.4.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.12/dist-packages (from jsonschema<5.0.0,>=4.16.0->docling-core<3.0.0,>=2.48.2->docling-core[chunking]<3.0.0,>=2.48.2->docling) (2025.9.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.12/dist-packages (from jsonschema<5.0.0,>=4.16.0->docling-core<3.0.0,>=2.48.2->docling-core[chunking]<3.0.0,>=2.48.2->docling) (0.37.0)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.12/dist-packages (from jsonschema<5.0.0,>=4.16.0->docling-core<3.0.0,>=2.48.2->docling-core[chunking]<3.0.0,>=2.48.2->docling) (0.27.1)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from rich>=10.11.0->typer<0.20.0,>=0.12.5->docling) (4.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from rich>=10.11.0->typer<0.20.0,>=0.12.5->docling) (2.19.2)\n",
            "Collecting mpire[dill] (from semchunk<3.0.0,>=2.2.0->docling-core[chunking]<3.0.0,>=2.48.2->docling)\n",
            "  Downloading mpire-2.10.2-py3-none-any.whl.metadata (14 kB)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate<2,>=1.0.0->docling) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate<2,>=1.0.0->docling) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate<2,>=1.0.0->docling) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate<2,>=1.0.0->docling) (3.1.6)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate<2,>=1.0.0->docling) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate<2,>=1.0.0->docling) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate<2,>=1.0.0->docling) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate<2,>=1.0.0->docling) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate<2,>=1.0.0->docling) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate<2,>=1.0.0->docling) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate<2,>=1.0.0->docling) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate<2,>=1.0.0->docling) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate<2,>=1.0.0->docling) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate<2,>=1.0.0->docling) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate<2,>=1.0.0->docling) (2.27.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate<2,>=1.0.0->docling) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate<2,>=1.0.0->docling) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate<2,>=1.0.0->docling) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate<2,>=1.0.0->docling) (3.4.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers<5.0.0,>=4.34.0->docling-core[chunking]<3.0.0,>=2.48.2->docling) (2024.11.6)\n",
            "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /usr/local/lib/python3.12/dist-packages (from transformers<5.0.0,>=4.34.0->docling-core[chunking]<3.0.0,>=2.48.2->docling) (0.22.1)\n",
            "Requirement already satisfied: antlr4-python3-runtime==4.9.* in /usr/local/lib/python3.12/dist-packages (from omegaconf->rapidocr<4.0.0,>=3.3->docling) (4.9.3)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.12/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<0.20.0,>=0.12.5->docling) (0.1.2)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=2.0.0->accelerate<2,>=1.0.0->docling) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=2.0.0->accelerate<2,>=1.0.0->docling) (3.0.3)\n",
            "Requirement already satisfied: multiprocess>=0.70.15 in /usr/local/lib/python3.12/dist-packages (from mpire[dill]->semchunk<3.0.0,>=2.2.0->docling-core[chunking]<3.0.0,>=2.48.2->docling) (0.70.16)\n",
            "Requirement already satisfied: dill>=0.3.8 in /usr/local/lib/python3.12/dist-packages (from multiprocess>=0.70.15->mpire[dill]->semchunk<3.0.0,>=2.2.0->docling-core[chunking]<3.0.0,>=2.48.2->docling) (0.3.8)\n",
            "Downloading docling-2.58.0-py3-none-any.whl (251 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m251.4/251.4 kB\u001b[0m \u001b[31m17.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading docling_core-2.49.0-py3-none-any.whl (164 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m164.5/164.5 kB\u001b[0m \u001b[31m14.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading docling_ibm_models-3.10.1-py3-none-any.whl (87 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m87.2/87.2 kB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading docling_parse-4.7.0-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (15.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m15.1/15.1 MB\u001b[0m \u001b[31m95.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading filetype-1.2.0-py2.py3-none-any.whl (19 kB)\n",
            "Downloading marko-2.2.1-py3-none-any.whl (42 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.7/42.7 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading polyfactory-2.22.3-py3-none-any.whl (63 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.7/63.7 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pypdfium2-4.30.0-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.8/2.8 MB\u001b[0m \u001b[31m98.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading python_docx-1.2.0-py3-none-any.whl (252 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m253.0/253.0 kB\u001b[0m \u001b[31m19.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading python_pptx-1.0.2-py3-none-any.whl (472 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m472.8/472.8 kB\u001b[0m \u001b[31m35.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading rapidocr-3.4.2-py3-none-any.whl (15.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m15.1/15.1 MB\u001b[0m \u001b[31m94.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading rtree-1.4.1-py3-none-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl (507 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m507.6/507.6 kB\u001b[0m \u001b[31m37.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading typer-0.19.2-py3-none-any.whl (46 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.7/46.7 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading faker-37.12.0-py3-none-any.whl (2.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m68.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jsonlines-4.0.0-py3-none-any.whl (8.7 kB)\n",
            "Downloading jsonref-1.1.0-py3-none-any.whl (9.4 kB)\n",
            "Downloading latex2mathml-3.78.1-py3-none-any.whl (73 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m73.9/73.9 kB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pyclipper-1.3.0.post6-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (963 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m963.8/963.8 kB\u001b[0m \u001b[31m50.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading semchunk-2.2.2-py3-none-any.whl (10 kB)\n",
            "Downloading xlsxwriter-3.2.9-py3-none-any.whl (175 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m175.3/175.3 kB\u001b[0m \u001b[31m11.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading colorlog-6.10.1-py3-none-any.whl (11 kB)\n",
            "Downloading mpire-2.10.2-py3-none-any.whl (272 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m272.8/272.8 kB\u001b[0m \u001b[31m22.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: pylatexenc\n",
            "  Building wheel for pylatexenc (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pylatexenc: filename=pylatexenc-2.10-py3-none-any.whl size=136817 sha256=371e430c3451597085a6265975bd5e26a924b1b0ec3c4c9e51c089b4dc3d02f4\n",
            "  Stored in directory: /root/.cache/pip/wheels/06/3e/78/fa1588c1ae991bbfd814af2bcac6cef7a178beee1939180d46\n",
            "Successfully built pylatexenc\n",
            "Installing collected packages: pylatexenc, pyclipper, filetype, XlsxWriter, rtree, python-docx, pypdfium2, mpire, marko, latex2mathml, jsonref, jsonlines, faker, colorlog, rapidocr, python-pptx, polyfactory, typer, semchunk, docling-core, docling-parse, docling-ibm-models, docling\n",
            "  Attempting uninstall: typer\n",
            "    Found existing installation: typer 0.20.0\n",
            "    Uninstalling typer-0.20.0:\n",
            "      Successfully uninstalled typer-0.20.0\n",
            "Successfully installed XlsxWriter-3.2.9 colorlog-6.10.1 docling-2.58.0 docling-core-2.49.0 docling-ibm-models-3.10.1 docling-parse-4.7.0 faker-37.12.0 filetype-1.2.0 jsonlines-4.0.0 jsonref-1.1.0 latex2mathml-3.78.1 marko-2.2.1 mpire-2.10.2 polyfactory-2.22.3 pyclipper-1.3.0.post6 pylatexenc-2.10 pypdfium2-4.30.0 python-docx-1.2.0 python-pptx-1.0.2 rapidocr-3.4.2 rtree-1.4.1 semchunk-2.2.2 typer-0.19.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "be25683b"
      },
      "source": [
        "## Document Conversion"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "1a73cf2e",
        "outputId": "7484ad99-5736-49a6-a926-bc039d85f18b"
      },
      "source": [
        "from docling.document_converter import DocumentConverter\n",
        "from IPython.display import display\n",
        "import json\n",
        "\n",
        "source = \"https://arxiv.org/pdf/2501.17887\"\n",
        "# source = \"/content/sample_data/DocLing_2501.17887v1.pdf\"\n",
        "converter = DocumentConverter()\n",
        "doc = converter.convert(source).document\n",
        "\n",
        "print(doc.export)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[INFO] 2025-10-26 17:10:37,278 [RapidOCR] base.py:22: Using engine_name: torch\u001b[0m\n",
            "\u001b[32m[INFO] 2025-10-26 17:10:37,347 [RapidOCR] download_file.py:60: File exists and is valid: /usr/local/lib/python3.12/dist-packages/rapidocr/models/ch_PP-OCRv4_det_infer.pth\u001b[0m\n",
            "\u001b[32m[INFO] 2025-10-26 17:10:37,350 [RapidOCR] torch.py:54: Using /usr/local/lib/python3.12/dist-packages/rapidocr/models/ch_PP-OCRv4_det_infer.pth\u001b[0m\n",
            "\u001b[32m[INFO] 2025-10-26 17:10:37,633 [RapidOCR] base.py:22: Using engine_name: torch\u001b[0m\n",
            "\u001b[32m[INFO] 2025-10-26 17:10:37,640 [RapidOCR] download_file.py:60: File exists and is valid: /usr/local/lib/python3.12/dist-packages/rapidocr/models/ch_ptocr_mobile_v2.0_cls_infer.pth\u001b[0m\n",
            "\u001b[32m[INFO] 2025-10-26 17:10:37,641 [RapidOCR] torch.py:54: Using /usr/local/lib/python3.12/dist-packages/rapidocr/models/ch_ptocr_mobile_v2.0_cls_infer.pth\u001b[0m\n",
            "\u001b[32m[INFO] 2025-10-26 17:10:37,752 [RapidOCR] base.py:22: Using engine_name: torch\u001b[0m\n",
            "\u001b[32m[INFO] 2025-10-26 17:10:37,878 [RapidOCR] download_file.py:60: File exists and is valid: /usr/local/lib/python3.12/dist-packages/rapidocr/models/ch_PP-OCRv4_rec_infer.pth\u001b[0m\n",
            "\u001b[32m[INFO] 2025-10-26 17:10:37,879 [RapidOCR] torch.py:54: Using /usr/local/lib/python3.12/dist-packages/rapidocr/models/ch_PP-OCRv4_rec_infer.pth\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<bound method DoclingDocument.export_to_document_tokens of DoclingDocument(schema_name='DoclingDocument', version='1.7.0', name='2501.17887v1', origin=DocumentOrigin(mimetype='application/pdf', binary_hash=1554916940463874186, filename='2501.17887v1.pdf', uri=None), furniture=GroupItem(self_ref='#/furniture', parent=None, children=[], content_layer=<ContentLayer.FURNITURE: 'furniture'>, name='_root_', label=<GroupLabel.UNSPECIFIED: 'unspecified'>), body=GroupItem(self_ref='#/body', parent=None, children=[RefItem(cref='#/texts/0'), RefItem(cref='#/texts/1'), RefItem(cref='#/texts/2'), RefItem(cref='#/texts/3'), RefItem(cref='#/texts/4'), RefItem(cref='#/texts/5'), RefItem(cref='#/texts/6'), RefItem(cref='#/texts/7'), RefItem(cref='#/texts/8'), RefItem(cref='#/texts/9'), RefItem(cref='#/texts/10'), RefItem(cref='#/texts/11'), RefItem(cref='#/texts/12'), RefItem(cref='#/texts/13'), RefItem(cref='#/groups/0'), RefItem(cref='#/texts/20'), RefItem(cref='#/texts/21'), RefItem(cref='#/pictures/0'), RefItem(cref='#/texts/64'), RefItem(cref='#/texts/65'), RefItem(cref='#/texts/66'), RefItem(cref='#/texts/67'), RefItem(cref='#/texts/68'), RefItem(cref='#/texts/69'), RefItem(cref='#/texts/70'), RefItem(cref='#/texts/71'), RefItem(cref='#/texts/72'), RefItem(cref='#/groups/1'), RefItem(cref='#/texts/78'), RefItem(cref='#/texts/79'), RefItem(cref='#/texts/80'), RefItem(cref='#/texts/81'), RefItem(cref='#/texts/82'), RefItem(cref='#/groups/2'), RefItem(cref='#/texts/85'), RefItem(cref='#/texts/86'), RefItem(cref='#/texts/87'), RefItem(cref='#/texts/88'), RefItem(cref='#/texts/89'), RefItem(cref='#/texts/90'), RefItem(cref='#/texts/91'), RefItem(cref='#/texts/92'), RefItem(cref='#/texts/93'), RefItem(cref='#/texts/94'), RefItem(cref='#/texts/95'), RefItem(cref='#/texts/96'), RefItem(cref='#/texts/97'), RefItem(cref='#/texts/98'), RefItem(cref='#/texts/99'), RefItem(cref='#/texts/100'), RefItem(cref='#/texts/101'), RefItem(cref='#/texts/102'), RefItem(cref='#/texts/103'), RefItem(cref='#/texts/104'), RefItem(cref='#/texts/105'), RefItem(cref='#/texts/106'), RefItem(cref='#/texts/107'), RefItem(cref='#/texts/108'), RefItem(cref='#/groups/3'), RefItem(cref='#/texts/111'), RefItem(cref='#/tables/0'), RefItem(cref='#/pictures/1'), RefItem(cref='#/texts/152'), RefItem(cref='#/texts/153'), RefItem(cref='#/groups/4'), RefItem(cref='#/texts/157'), RefItem(cref='#/texts/158'), RefItem(cref='#/pictures/2'), RefItem(cref='#/texts/172'), RefItem(cref='#/texts/173'), RefItem(cref='#/texts/174'), RefItem(cref='#/texts/175'), RefItem(cref='#/texts/176'), RefItem(cref='#/texts/177'), RefItem(cref='#/texts/178'), RefItem(cref='#/texts/179'), RefItem(cref='#/texts/180'), RefItem(cref='#/texts/181'), RefItem(cref='#/texts/182'), RefItem(cref='#/texts/183'), RefItem(cref='#/texts/184'), RefItem(cref='#/texts/185'), RefItem(cref='#/texts/186'), RefItem(cref='#/texts/187'), RefItem(cref='#/texts/188'), RefItem(cref='#/pictures/3'), RefItem(cref='#/pictures/4'), RefItem(cref='#/texts/236'), RefItem(cref='#/texts/237'), RefItem(cref='#/pictures/5'), RefItem(cref='#/texts/253'), RefItem(cref='#/texts/254'), RefItem(cref='#/texts/255'), RefItem(cref='#/texts/256'), RefItem(cref='#/texts/257'), RefItem(cref='#/texts/258'), RefItem(cref='#/texts/259'), RefItem(cref='#/texts/260'), RefItem(cref='#/texts/261'), RefItem(cref='#/texts/262'), RefItem(cref='#/texts/263'), RefItem(cref='#/texts/264'), RefItem(cref='#/texts/265'), RefItem(cref='#/texts/266'), RefItem(cref='#/texts/267'), RefItem(cref='#/texts/268'), RefItem(cref='#/texts/269'), RefItem(cref='#/texts/270'), RefItem(cref='#/texts/271'), RefItem(cref='#/texts/272'), RefItem(cref='#/texts/273'), RefItem(cref='#/texts/274'), RefItem(cref='#/texts/275'), RefItem(cref='#/texts/276'), RefItem(cref='#/texts/277'), RefItem(cref='#/texts/278'), RefItem(cref='#/texts/279'), RefItem(cref='#/texts/280'), RefItem(cref='#/texts/281'), RefItem(cref='#/texts/282'), RefItem(cref='#/texts/283'), RefItem(cref='#/texts/284'), RefItem(cref='#/texts/285'), RefItem(cref='#/texts/286')], content_layer=<ContentLayer.BODY: 'body'>, name='_root_', label=<GroupLabel.UNSPECIFIED: 'unspecified'>), groups=[ListGroup(self_ref='#/groups/0', parent=RefItem(cref='#/body'), children=[RefItem(cref='#/texts/14'), RefItem(cref='#/texts/15'), RefItem(cref='#/texts/16'), RefItem(cref='#/texts/17'), RefItem(cref='#/texts/18'), RefItem(cref='#/texts/19')], content_layer=<ContentLayer.BODY: 'body'>, name='list', label=<GroupLabel.LIST: 'list'>), ListGroup(self_ref='#/groups/1', parent=RefItem(cref='#/body'), children=[RefItem(cref='#/texts/73'), RefItem(cref='#/texts/74'), RefItem(cref='#/texts/75'), RefItem(cref='#/texts/76'), RefItem(cref='#/texts/77')], content_layer=<ContentLayer.BODY: 'body'>, name='list', label=<GroupLabel.LIST: 'list'>), ListGroup(self_ref='#/groups/2', parent=RefItem(cref='#/body'), children=[RefItem(cref='#/texts/83'), RefItem(cref='#/texts/84')], content_layer=<ContentLayer.BODY: 'body'>, name='list', label=<GroupLabel.LIST: 'list'>), ListGroup(self_ref='#/groups/3', parent=RefItem(cref='#/body'), children=[RefItem(cref='#/texts/109'), RefItem(cref='#/texts/110')], content_layer=<ContentLayer.BODY: 'body'>, name='list', label=<GroupLabel.LIST: 'list'>), ListGroup(self_ref='#/groups/4', parent=RefItem(cref='#/body'), children=[RefItem(cref='#/texts/154'), RefItem(cref='#/texts/155'), RefItem(cref='#/texts/156')], content_layer=<ContentLayer.BODY: 'body'>, name='list', label=<GroupLabel.LIST: 'list'>)], texts=[TextItem(self_ref='#/texts/0', parent=RefItem(cref='#/body'), children=[], content_layer=<ContentLayer.FURNITURE: 'furniture'>, label=<DocItemLabel.PAGE_HEADER: 'page_header'>, prov=[ProvenanceItem(page_no=1, bbox=BoundingBox(l=18.34, t=632.0, r=36.34, b=232.0, coord_origin=<CoordOrigin.BOTTOMLEFT: 'BOTTOMLEFT'>), charspan=(0, 40))], orig='arXiv:2501.17887v1  [cs.CL]  27 Jan 2025', text='arXiv:2501.17887v1  [cs.CL]  27 Jan 2025', formatting=None, hyperlink=None), SectionHeaderItem(self_ref='#/texts/1', parent=RefItem(cref='#/body'), children=[], content_layer=<ContentLayer.BODY: 'body'>, label=<DocItemLabel.SECTION_HEADER: 'section_header'>, prov=[ProvenanceItem(page_no=1, bbox=BoundingBox(l=63.595, t=693.015, r=548.41, b=680.118, coord_origin=<CoordOrigin.BOTTOMLEFT: 'BOTTOMLEFT'>), charspan=(0, 75))], orig='Docling: An Efficient Open-Source Toolkit for AI-driven Document Conversion', text='Docling: An Efficient Open-Source Toolkit for AI-driven Document Conversion', formatting=None, hyperlink=None, level=1), TextItem(self_ref='#/texts/2', parent=RefItem(cref='#/body'), children=[], content_layer=<ContentLayer.BODY: 'body'>, label=<DocItemLabel.TEXT: 'text'>, prov=[ProvenanceItem(page_no=1, bbox=BoundingBox(l=83.779, t=667.68, r=529.449, b=615.089, coord_origin=<CoordOrigin.BOTTOMLEFT: 'BOTTOMLEFT'>), charspan=(0, 284))], orig='Nikolaos Livathinos * , Christoph Auer * , Maksym Lysak, Ahmed Nassar, Michele Dolfi, Panagiotis Vagenas, Cesar Berrospi, Matteo Omenetti, Kasper Dinkla, Yusik Kim, Shubham Gupta, Rafael Teixeira de Lima, Valery Weber, Lucas Morin, Ingmar Meijer, Viktor Kuropiatnyk, Peter W. J. Staar', text='Nikolaos Livathinos * , Christoph Auer * , Maksym Lysak, Ahmed Nassar, Michele Dolfi, Panagiotis Vagenas, Cesar Berrospi, Matteo Omenetti, Kasper Dinkla, Yusik Kim, Shubham Gupta, Rafael Teixeira de Lima, Valery Weber, Lucas Morin, Ingmar Meijer, Viktor Kuropiatnyk, Peter W. J. Staar', formatting=None, hyperlink=None), TextItem(self_ref='#/texts/3', parent=RefItem(cref='#/body'), children=[], content_layer=<ContentLayer.BODY: 'body'>, label=<DocItemLabel.TEXT: 'text'>, prov=[ProvenanceItem(page_no=1, bbox=BoundingBox(l=225.667, t=609.855, r=386.334, b=601.303, coord_origin=<CoordOrigin.BOTTOMLEFT: 'BOTTOMLEFT'>), charspan=(0, 39))], orig='IBM Research, R¨ uschlikon, Switzerland', text='IBM Research, R¨ uschlikon, Switzerland', formatting=None, hyperlink=None), TextItem(self_ref='#/texts/4', parent=RefItem(cref='#/body'), children=[], content_layer=<ContentLayer.BODY: 'body'>, label=<DocItemLabel.TEXT: 'text'>, prov=[ProvenanceItem(page_no=1, bbox=BoundingBox(l=152.98, t=598.896, r=459.02, b=590.344, coord_origin=<CoordOrigin.BOTTOMLEFT: 'BOTTOMLEFT'>), charspan=(0, 61))], orig='Please send correspondence to: deepsearch-core@zurich.ibm.com', text='Please send correspondence to: deepsearch-core@zurich.ibm.com', formatting=None, hyperlink=None), SectionHeaderItem(self_ref='#/texts/5', parent=RefItem(cref='#/body'), children=[], content_layer=<ContentLayer.BODY: 'body'>, label=<DocItemLabel.SECTION_HEADER: 'section_header'>, prov=[ProvenanceItem(page_no=1, bbox=BoundingBox(l=154.715, t=572.04, r=191.786, b=563.084, coord_origin=<CoordOrigin.BOTTOMLEFT: 'BOTTOMLEFT'>), charspan=(0, 8))], orig='Abstract', text='Abstract', formatting=None, hyperlink=None, level=1), TextItem(self_ref='#/texts/6', parent=RefItem(cref='#/body'), children=[], content_layer=<ContentLayer.BODY: 'body'>, label=<DocItemLabel.TEXT: 'text'>, prov=[ProvenanceItem(page_no=1, bbox=BoundingBox(l=63.963, t=555.628, r=282.54, b=368.451, coord_origin=<CoordOrigin.BOTTOMLEFT: 'BOTTOMLEFT'>), charspan=(0, 1117))], orig=\"We introduce Docling , an easy-to-use, self-contained, MITlicensed, open-source toolkit for document conversion, that can parse several types of popular document formats into a unified, richly structured representation. It is powered by state-of-the-art specialized AI models for layout analysis (DocLayNet) and table structure recognition (TableFormer), and runs efficiently on commodity hardware in a small resource budget. Docling is released as a Python package and can be used as a Python API or as a CLI tool. Docling's modular architecture and efficient document representation make it easy to implement extensions, new features, models, and customizations. Docling has been already integrated in other popular open-source frameworks (e.g., LangChain, LlamaIndex, spaCy), making it a natural fit for the processing of documents and the development of high-end applications. The open-source community has fully engaged in using, promoting, and developing for Docling, which gathered 10k stars on GitHub in less than a month and was reported as the No. 1 trending repository in GitHub worldwide in November 2024.\", text=\"We introduce Docling , an easy-to-use, self-contained, MITlicensed, open-source toolkit for document conversion, that can parse several types of popular document formats into a unified, richly structured representation. It is powered by state-of-the-art specialized AI models for layout analysis (DocLayNet) and table structure recognition (TableFormer), and runs efficiently on commodity hardware in a small resource budget. Docling is released as a Python package and can be used as a Python API or as a CLI tool. Docling's modular architecture and efficient document representation make it easy to implement extensions, new features, models, and customizations. Docling has been already integrated in other popular open-source frameworks (e.g., LangChain, LlamaIndex, spaCy), making it a natural fit for the processing of documents and the development of high-end applications. The open-source community has fully engaged in using, promoting, and developing for Docling, which gathered 10k stars on GitHub in less than a month and was reported as the No. 1 trending repository in GitHub worldwide in November 2024.\", formatting=None, hyperlink=None), TextItem(self_ref='#/texts/7', parent=RefItem(cref='#/body'), children=[], content_layer=<ContentLayer.BODY: 'body'>, label=<DocItemLabel.TEXT: 'text'>, prov=[ProvenanceItem(page_no=1, bbox=BoundingBox(l=54.0, t=357.588, r=253.7, b=348.632, coord_origin=<CoordOrigin.BOTTOMLEFT: 'BOTTOMLEFT'>), charspan=(0, 44))], orig='Repository -https://github.com/DS4SD/docling', text='Repository -https://github.com/DS4SD/docling', formatting=None, hyperlink=None), SectionHeaderItem(self_ref='#/texts/8', parent=RefItem(cref='#/body'), children=[], content_layer=<ContentLayer.BODY: 'body'>, label=<DocItemLabel.SECTION_HEADER: 'section_header'>, prov=[ProvenanceItem(page_no=1, bbox=BoundingBox(l=131.844, t=333.323, r=214.658, b=322.575, coord_origin=<CoordOrigin.BOTTOMLEFT: 'BOTTOMLEFT'>), charspan=(0, 14))], orig='1 Introduction', text='1 Introduction', formatting=None, hyperlink=None, level=1), TextItem(self_ref='#/texts/9', parent=RefItem(cref='#/body'), children=[], content_layer=<ContentLayer.BODY: 'body'>, label=<DocItemLabel.TEXT: 'text'>, prov=[ProvenanceItem(page_no=1, bbox=BoundingBox(l=54.0, t=318.275, r=292.505, b=123.42200000000003, coord_origin=<CoordOrigin.BOTTOMLEFT: 'BOTTOMLEFT'>), charspan=(0, 1033))], orig='Converting documents back into a unified machineprocessable format has been a major challenge for decades due to their huge variability in formats, weak standardization and printing-optimized characteristic, which often discards structural features and metadata. With the advent of LLMs and popular application patterns such as retrieval-augmented generation (RAG), leveraging the rich content embedded in PDFs, Office documents, and scanned document images has become ever more relevant. In the past decade, several powerful document understanding solutions have emerged on the market, most of which are commercial software, SaaS offerings on hyperscalers (Auer et al. 2022) and most recently, multimodal vision-language models. Typically, they incur a cost (e.g., for licensing or LLM inference) and cannot be run easily on local hardware. Meanwhile, only a handful of different open-source tools cover PDF, MS Word, MS PowerPoint, Images, or HTML conversion, leaving a significant feature and quality gap to proprietary solutions.', text='Converting documents back into a unified machineprocessable format has been a major challenge for decades due to their huge variability in formats, weak standardization and printing-optimized characteristic, which often discards structural features and metadata. With the advent of LLMs and popular application patterns such as retrieval-augmented generation (RAG), leveraging the rich content embedded in PDFs, Office documents, and scanned document images has become ever more relevant. In the past decade, several powerful document understanding solutions have emerged on the market, most of which are commercial software, SaaS offerings on hyperscalers (Auer et al. 2022) and most recently, multimodal vision-language models. Typically, they incur a cost (e.g., for licensing or LLM inference) and cannot be run easily on local hardware. Meanwhile, only a handful of different open-source tools cover PDF, MS Word, MS PowerPoint, Images, or HTML conversion, leaving a significant feature and quality gap to proprietary solutions.', formatting=None, hyperlink=None), TextItem(self_ref='#/texts/10', parent=RefItem(cref='#/body'), children=[], content_layer=<ContentLayer.BODY: 'body'>, label=<DocItemLabel.FOOTNOTE: 'footnote'>, prov=[ProvenanceItem(page_no=1, bbox=BoundingBox(l=66.653, t=115.44499999999994, r=193.392, b=107.20600000000002, coord_origin=<CoordOrigin.BOTTOMLEFT: 'BOTTOMLEFT'>), charspan=(0, 36))], orig='* These authors contributed equally.', text='* These authors contributed equally.', formatting=None, hyperlink=None), TextItem(self_ref='#/texts/11', parent=RefItem(cref='#/body'), children=[], content_layer=<ContentLayer.BODY: 'body'>, label=<DocItemLabel.FOOTNOTE: 'footnote'>, prov=[ProvenanceItem(page_no=1, bbox=BoundingBox(l=54.0, t=105.79999999999995, r=292.497, b=88.13999999999999, coord_origin=<CoordOrigin.BOTTOMLEFT: 'BOTTOMLEFT'>), charspan=(0, 113))], orig='Copyright © 2025, Association for the Advancement of Artificial Intelligence (www.aaai.org). All rights reserved.', text='Copyright © 2025, Association for the Advancement of Artificial Intelligence (www.aaai.org). All rights reserved.', formatting=None, hyperlink=None), TextItem(self_ref='#/texts/12', parent=RefItem(cref='#/body'), children=[], content_layer=<ContentLayer.BODY: 'body'>, label=<DocItemLabel.TEXT: 'text'>, prov=[ProvenanceItem(page_no=1, bbox=BoundingBox(l=319.5, t=571.821, r=558.005, b=376.798, coord_origin=<CoordOrigin.BOTTOMLEFT: 'BOTTOMLEFT'>), charspan=(0, 1059))], orig=\"With Docling , we recently open-sourced a very capable and efficient document conversion tool which builds on the powerful, specialized AI models and datasets for layout analysis and table structure recognition that we developed and presented in the recent past (Livathinos et al. 2021; Pfitzmann et al. 2022; Lysak et al. 2023). Docling is designed as a simple, self-contained Python library with permissive MIT license, running entirely locally on commodity hardware. Its code architecture allows for easy extensibility and addition of new features and models. Since its launch in July 2024, Docling has attracted considerable attention in the AI developer community and ranks top on GitHub's monthly trending repositories with more than 10,000 stars at the time of writing. On October 16, 2024, Docling reached a major milestone with version 2, introducing several new features and concepts, which we outline in this updated technical report, along with details on its architecture, conversion speed benchmarks, and comparisons to other open-source assets.\", text=\"With Docling , we recently open-sourced a very capable and efficient document conversion tool which builds on the powerful, specialized AI models and datasets for layout analysis and table structure recognition that we developed and presented in the recent past (Livathinos et al. 2021; Pfitzmann et al. 2022; Lysak et al. 2023). Docling is designed as a simple, self-contained Python library with permissive MIT license, running entirely locally on commodity hardware. Its code architecture allows for easy extensibility and addition of new features and models. Since its launch in July 2024, Docling has attracted considerable attention in the AI developer community and ranks top on GitHub's monthly trending repositories with more than 10,000 stars at the time of writing. On October 16, 2024, Docling reached a major milestone with version 2, introducing several new features and concepts, which we outline in this updated technical report, along with details on its architecture, conversion speed benchmarks, and comparisons to other open-source assets.\", formatting=None, hyperlink=None), TextItem(self_ref='#/texts/13', parent=RefItem(cref='#/body'), children=[], content_layer=<ContentLayer.BODY: 'body'>, label=<DocItemLabel.TEXT: 'text'>, prov=[ProvenanceItem(page_no=1, bbox=BoundingBox(l=319.5, t=373.902, r=557.995, b=354.391, coord_origin=<CoordOrigin.BOTTOMLEFT: 'BOTTOMLEFT'>), charspan=(0, 74))], orig='The following list summarizes the features currently available on Docling:', text='The following list summarizes the features currently available on Docling:', formatting=None, hyperlink=None), ListItem(self_ref='#/texts/14', parent=RefItem(cref='#/groups/0'), children=[], content_layer=<ContentLayer.BODY: 'body'>, label=<DocItemLabel.LIST_ITEM: 'list_item'>, prov=[ProvenanceItem(page_no=1, bbox=BoundingBox(l=323.983, t=345.778, r=558.004, b=315.308, coord_origin=<CoordOrigin.BOTTOMLEFT: 'BOTTOMLEFT'>), charspan=(0, 112))], orig='· Parses common document formats (PDF, Images, MS Office formats, HTML) and exports to Markdown, JSON, and HTML.', text='Parses common document formats (PDF, Images, MS Office formats, HTML) and exports to Markdown, JSON, and HTML.', formatting=None, hyperlink=None, enumerated=False, marker='·'), ListItem(self_ref='#/texts/15', parent=RefItem(cref='#/groups/0'), children=[], content_layer=<ContentLayer.BODY: 'body'>, label=<DocItemLabel.LIST_ITEM: 'list_item'>, prov=[ProvenanceItem(page_no=1, bbox=BoundingBox(l=323.983, t=309.431, r=558.004, b=278.961, coord_origin=<CoordOrigin.BOTTOMLEFT: 'BOTTOMLEFT'>), charspan=(0, 153))], orig='· Applies advanced AI for document understanding, including detailed page layout, OCR, reading order, figure extraction, and table structure recognition.', text='Applies advanced AI for document understanding, including detailed page layout, OCR, reading order, figure extraction, and table structure recognition.', formatting=None, hyperlink=None, enumerated=False, marker='·'), ListItem(self_ref='#/texts/16', parent=RefItem(cref='#/groups/0'), children=[], content_layer=<ContentLayer.BODY: 'body'>, label=<DocItemLabel.LIST_ITEM: 'list_item'>, prov=[ProvenanceItem(page_no=1, bbox=BoundingBox(l=323.983, t=273.08400000000006, r=557.997, b=253.57299999999998, coord_origin=<CoordOrigin.BOTTOMLEFT: 'BOTTOMLEFT'>), charspan=(0, 99))], orig='· Establishes a unified DoclingDocument data model for rich document representation and operations.', text='Establishes a unified DoclingDocument data model for rich document representation and operations.', formatting=None, hyperlink=None, enumerated=False, marker='·'), ListItem(self_ref='#/texts/17', parent=RefItem(cref='#/groups/0'), children=[], content_layer=<ContentLayer.BODY: 'body'>, label=<DocItemLabel.LIST_ITEM: 'list_item'>, prov=[ProvenanceItem(page_no=1, bbox=BoundingBox(l=323.983, t=247.69600000000003, r=558.004, b=228.18499999999995, coord_origin=<CoordOrigin.BOTTOMLEFT: 'BOTTOMLEFT'>), charspan=(0, 112))], orig='· Provides fully local execution capabilities making it suitable for sensitive data and air-gapped environments.', text='Provides fully local execution capabilities making it suitable for sensitive data and air-gapped environments.', formatting=None, hyperlink=None, enumerated=False, marker='·'), ListItem(self_ref='#/texts/18', parent=RefItem(cref='#/groups/0'), children=[], content_layer=<ContentLayer.BODY: 'body'>, label=<DocItemLabel.LIST_ITEM: 'list_item'>, prov=[ProvenanceItem(page_no=1, bbox=BoundingBox(l=323.983, t=222.308, r=558.004, b=191.83799999999997, coord_origin=<CoordOrigin.BOTTOMLEFT: 'BOTTOMLEFT'>), charspan=(0, 137))], orig='· Has an ecosystem of plug-and-play integrations with prominent generative AI development frameworks, including LangChain and LlamaIndex.', text='Has an ecosystem of plug-and-play integrations with prominent generative AI development frameworks, including LangChain and LlamaIndex.', formatting=None, hyperlink=None, enumerated=False, marker='·'), ListItem(self_ref='#/texts/19', parent=RefItem(cref='#/groups/0'), children=[], content_layer=<ContentLayer.BODY: 'body'>, label=<DocItemLabel.LIST_ITEM: 'list_item'>, prov=[ProvenanceItem(page_no=1, bbox=BoundingBox(l=323.983, t=185.961, r=534.174, b=177.409, coord_origin=<CoordOrigin.BOTTOMLEFT: 'BOTTOMLEFT'>), charspan=(0, 50))], orig='· Can leverage hardware accelerators such as GPUs.', text='Can leverage hardware accelerators such as GPUs.', formatting=None, hyperlink=None, enumerated=False, marker='·'), SectionHeaderItem(self_ref='#/texts/20', parent=RefItem(cref='#/body'), children=[], content_layer=<ContentLayer.BODY: 'body'>, label=<DocItemLabel.SECTION_HEADER: 'section_header'>, prov=[ProvenanceItem(page_no=1, bbox=BoundingBox(l=390.445, t=157.50199999999995, r=487.055, b=146.75400000000002, coord_origin=<CoordOrigin.BOTTOMLEFT: 'BOTTOMLEFT'>), charspan=(0, 18))], orig='2 State of the Art', text='2 State of the Art', formatting=None, hyperlink=None, level=1), TextItem(self_ref='#/texts/21', parent=RefItem(cref='#/body'), children=[], content_layer=<ContentLayer.BODY: 'body'>, label=<DocItemLabel.TEXT: 'text'>, prov=[ProvenanceItem(page_no=1, bbox=BoundingBox(l=319.5, t=140.322, r=558.005, b=87.93399999999997, coord_origin=<CoordOrigin.BOTTOMLEFT: 'BOTTOMLEFT'>), charspan=(0, 292))], orig='Document conversion is a well-established field with numerous solutions already available on the market. These solutions can be categorized along several key dimensions, including open vs. closed source, permissive vs. restrictive licensing, Web APIs vs. local code deployment, susceptibility', text='Document conversion is a well-established field with numerous solutions already available on the market. These solutions can be categorized along several key dimensions, including open vs. closed source, permissive vs. restrictive licensing, Web APIs vs. local code deployment, susceptibility', formatting=None, hyperlink=None), TextItem(self_ref='#/texts/22', parent=RefItem(cref='#/pictures/0'), children=[], content_layer=<ContentLayer.BODY: 'body'>, label=<DocItemLabel.CAPTION: 'caption'>, prov=[ProvenanceItem(page_no=2, bbox=BoundingBox(l=54.0, t=525.249, r=558.003, b=494.779, coord_origin=<CoordOrigin.BOTTOMLEFT: 'BOTTOMLEFT'>), charspan=(0, 282))], orig=\"Figure 1: Sketch of Docling's pipelines and usage model. Both PDF pipeline and simple pipeline build up a DoclingDocument representation, which can be further enriched. Downstream applications can utilize Docling's API to inspect, export, or chunk the document for various purposes.\", text=\"Figure 1: Sketch of Docling's pipelines and usage model. Both PDF pipeline and simple pipeline build up a DoclingDocument representation, which can be further enriched. Downstream applications can utilize Docling's API to inspect, export, or chunk the document for various purposes.\", formatting=None, hyperlink=None), TextItem(self_ref='#/texts/23', parent=RefItem(cref='#/pictures/0'), children=[], content_layer=<ContentLayer.BODY: 'body'>, label=<DocItemLabel.TEXT: 'text'>, prov=[ProvenanceItem(page_no=2, bbox=BoundingBox(l=231.331, t=618.266, r=245.41, b=609.849, coord_origin=<CoordOrigin.BOTTOMLEFT: 'BOTTOMLEFT'>), charspan=(0, 3))], orig='</>', text='</>', formatting=None, hyperlink=None), TextItem(self_ref='#/texts/24', parent=RefItem(cref='#/pictures/0'), children=[], content_layer=<ContentLayer.BODY: 'body'>, label=<DocItemLabel.TEXT: 'text'>, prov=[ProvenanceItem(page_no=2, bbox=BoundingBox(l=292.876, t=630.367, r=349.484, b=620.089, coord_origin=<CoordOrigin.BOTTOMLEFT: 'BOTTOMLEFT'>), charspan=(0, 15))], orig='Simple Pipeline', text='Simple Pipeline', formatting=None, hyperlink=None), TextItem(self_ref='#/texts/25', parent=RefItem(cref='#/pictures/0'), children=[], content_layer=<ContentLayer.BODY: 'body'>, label=<DocItemLabel.TEXT: 'text'>, prov=[ProvenanceItem(page_no=2, bbox=BoundingBox(l=296.327, t=571.87, r=339.114, b=565.387, coord_origin=<CoordOrigin.BOTTOMLEFT: 'BOTTOMLEFT'>), charspan=(0, 12))], orig='Parse Markup', text='Parse Markup', formatting=None, hyperlink=None), TextItem(self_ref='#/texts/26', parent=RefItem(cref='#/pictures/0'), children=[], content_layer=<ContentLayer.BODY: 'body'>, label=<DocItemLabel.TEXT: 'text'>, prov=[ProvenanceItem(page_no=2, bbox=BoundingBox(l=306.491, t=563.452, r=329.345, b=556.969, coord_origin=<CoordOrigin.BOTTOMLEFT: 'BOTTOMLEFT'>), charspan=(0, 6))], orig='Format', text='Format', formatting=None, hyperlink=None), TextItem(self_ref='#/texts/27', parent=RefItem(cref='#/pictures/0'), children=[], content_layer=<ContentLayer.BODY: 'body'>, label=<DocItemLabel.TEXT: 'text'>, prov=[ProvenanceItem(page_no=2, bbox=BoundingBox(l=332.09, t=550.356, r=350.971, b=540.078, coord_origin=<CoordOrigin.BOTTOMLEFT: 'BOTTOMLEFT'>), charspan=(0, 5))], orig='Build', text='Build', formatting=None, hyperlink=None), TextItem(self_ref='#/texts/28', parent=RefItem(cref='#/pictures/0'), children=[], content_layer=<ContentLayer.BODY: 'body'>, label=<DocItemLabel.TEXT: 'text'>, prov=[ProvenanceItem(page_no=2, bbox=BoundingBox(l=412.368, t=550.356, r=435.348, b=540.078, coord_origin=<CoordOrigin.BOTTOMLEFT: 'BOTTOMLEFT'>), charspan=(0, 6))], orig='Enrich', text='Enrich', formatting=None, hyperlink=None), TextItem(self_ref='#/texts/29', parent=RefItem(cref='#/pictures/0'), children=[], content_layer=<ContentLayer.BODY: 'body'>, label=<DocItemLabel.TEXT: 'text'>, prov=[ProvenanceItem(page_no=2, bbox=BoundingBox(l=134.289, t=733.334, r=180.361, b=723.035, coord_origin=<CoordOrigin.BOTTOMLEFT: 'BOTTOMLEFT'>), charspan=(0, 12))], orig='PDF Pipeline', text='PDF Pipeline', formatting=None, hyperlink=None), TextItem(self_ref='#/texts/30', parent=RefItem(cref='#/pictures/0'), children=[], content_layer=<ContentLayer.BODY: 'body'>, label=<DocItemLabel.TEXT: 'text'>, prov=[ProvenanceItem(page_no=2, bbox=BoundingBox(l=353.308, t=573.602, r=385.872, b=567.119, coord_origin=<CoordOrigin.BOTTOMLEFT: 'BOTTOMLEFT'>), charspan=(0, 8))], orig='Assemble', text='Assemble', formatting=None, hyperlink=None), TextItem(self_ref='#/texts/31', parent=RefItem(cref='#/pictures/0'), children=[], content_layer=<ContentLayer.BODY: 'body'>, label=<DocItemLabel.TEXT: 'text'>, prov=[ProvenanceItem(page_no=2, bbox=BoundingBox(l=353.427, t=565.167, r=385.806, b=558.684, coord_origin=<CoordOrigin.BOTTOMLEFT: 'BOTTOMLEFT'>), charspan=(0, 8))], orig='Document', text='Document', formatting=None, hyperlink=None), TextItem(self_ref='#/texts/32', parent=RefItem(cref='#/pictures/0'), children=[], content_layer=<ContentLayer.BODY: 'body'>, label=<DocItemLabel.TEXT: 'text'>, prov=[ProvenanceItem(page_no=2, bbox=BoundingBox(l=256.545, t=671.327, r=277.915, b=664.844, coord_origin=<CoordOrigin.BOTTOMLEFT: 'BOTTOMLEFT'>), charspan=(0, 6))], orig='Layout', text='Layout', formatting=None, hyperlink=None), TextItem(self_ref='#/texts/33', parent=RefItem(cref='#/pictures/0'), children=[], content_layer=<ContentLayer.BODY: 'body'>, label=<DocItemLabel.TEXT: 'text'>, prov=[ProvenanceItem(page_no=2, bbox=BoundingBox(l=254.011, t=662.906, r=279.89, b=656.423, coord_origin=<CoordOrigin.BOTTOMLEFT: 'BOTTOMLEFT'>), charspan=(0, 8))], orig='Analysis', text='Analysis', formatting=None, hyperlink=None), TextItem(self_ref='#/texts/34', parent=RefItem(cref='#/pictures/0'), children=[], content_layer=<ContentLayer.BODY: 'body'>, label=<DocItemLabel.TEXT: 'text'>, prov=[ProvenanceItem(page_no=2, bbox=BoundingBox(l=142.024, t=671.656, r=176.148, b=665.173, coord_origin=<CoordOrigin.BOTTOMLEFT: 'BOTTOMLEFT'>), charspan=(0, 9))], orig='Parse PDF', text='Parse PDF', formatting=None, hyperlink=None), TextItem(self_ref='#/texts/35', parent=RefItem(cref='#/pictures/0'), children=[], content_layer=<ContentLayer.BODY: 'body'>, label=<DocItemLabel.TEXT: 'text'>, prov=[ProvenanceItem(page_no=2, bbox=BoundingBox(l=149.654, t=663.242, r=168.19, b=656.759, coord_origin=<CoordOrigin.BOTTOMLEFT: 'BOTTOMLEFT'>), charspan=(0, 5))], orig='pages', text='pages', formatting=None, hyperlink=None), TextItem(self_ref='#/texts/36', parent=RefItem(cref='#/pictures/0'), children=[], content_layer=<ContentLayer.BODY: 'body'>, label=<DocItemLabel.TEXT: 'text'>, prov=[ProvenanceItem(page_no=2, bbox=BoundingBox(l=308.136, t=669.906, r=327.576, b=663.423, coord_origin=<CoordOrigin.BOTTOMLEFT: 'BOTTOMLEFT'>), charspan=(0, 5))], orig='Table', text='Table', formatting=None, hyperlink=None), TextItem(self_ref='#/texts/37', parent=RefItem(cref='#/pictures/0'), children=[], content_layer=<ContentLayer.BODY: 'body'>, label=<DocItemLabel.TEXT: 'text'>, prov=[ProvenanceItem(page_no=2, bbox=BoundingBox(l=303.131, t=661.471, r=332.123, b=654.988, coord_origin=<CoordOrigin.BOTTOMLEFT: 'BOTTOMLEFT'>), charspan=(0, 9))], orig='Structure', text='Structure', formatting=None, hyperlink=None), TextItem(self_ref='#/texts/38', parent=RefItem(cref='#/pictures/0'), children=[], content_layer=<ContentLayer.BODY: 'body'>, label=<DocItemLabel.TEXT: 'text'>, prov=[ProvenanceItem(page_no=2, bbox=BoundingBox(l=206.656, t=667.967, r=220.478, b=661.484, coord_origin=<CoordOrigin.BOTTOMLEFT: 'BOTTOMLEFT'>), charspan=(0, 3))], orig='OCR', text='OCR', formatting=None, hyperlink=None), TextItem(self_ref='#/texts/39', parent=RefItem(cref='#/pictures/0'), children=[], content_layer=<ContentLayer.BODY: 'body'>, label=<DocItemLabel.TEXT: 'text'>, prov=[ProvenanceItem(page_no=2, bbox=BoundingBox(l=476.383, t=550.688, r=490.791, b=540.388, coord_origin=<CoordOrigin.BOTTOMLEFT: 'BOTTOMLEFT'>), charspan=(0, 3))], orig='Use', text='Use', formatting=None, hyperlink=None), TextItem(self_ref='#/texts/40', parent=RefItem(cref='#/pictures/0'), children=[], content_layer=<ContentLayer.BODY: 'body'>, label=<DocItemLabel.TEXT: 'text'>, prov=[ProvenanceItem(page_no=2, bbox=BoundingBox(l=252.926, t=650.059, r=271.807, b=639.781, coord_origin=<CoordOrigin.BOTTOMLEFT: 'BOTTOMLEFT'>), charspan=(0, 5))], orig='Build', text='Build', formatting=None, hyperlink=None), TextItem(self_ref='#/texts/41', parent=RefItem(cref='#/pictures/0'), children=[], content_layer=<ContentLayer.BODY: 'body'>, label=<DocItemLabel.TEXT: 'text'>, prov=[ProvenanceItem(page_no=2, bbox=BoundingBox(l=354.862, t=670.991, r=385.893, b=664.508, coord_origin=<CoordOrigin.BOTTOMLEFT: 'BOTTOMLEFT'>), charspan=(0, 8))], orig='Assemble', text='Assemble', formatting=None, hyperlink=None), TextItem(self_ref='#/texts/42', parent=RefItem(cref='#/pictures/0'), children=[], content_layer=<ContentLayer.BODY: 'body'>, label=<DocItemLabel.TEXT: 'text'>, prov=[ProvenanceItem(page_no=2, bbox=BoundingBox(l=354.162, t=662.577, r=386.466, b=656.094, coord_origin=<CoordOrigin.BOTTOMLEFT: 'BOTTOMLEFT'>), charspan=(0, 8))], orig='Document', text='Document', formatting=None, hyperlink=None), TextItem(self_ref='#/texts/43', parent=RefItem(cref='#/pictures/0'), children=[], content_layer=<ContentLayer.BODY: 'body'>, label=<DocItemLabel.TEXT: 'text'>, prov=[ProvenanceItem(page_no=2, bbox=BoundingBox(l=460.794, t=690.227, r=504.361, b=683.745, coord_origin=<CoordOrigin.BOTTOMLEFT: 'BOTTOMLEFT'>), charspan=(0, 12))], orig='Export JSON,', text='Export JSON,', formatting=None, hyperlink=None), TextItem(self_ref='#/texts/44', parent=RefItem(cref='#/pictures/0'), children=[], content_layer=<ContentLayer.BODY: 'body'>, label=<DocItemLabel.TEXT: 'text'>, prov=[ProvenanceItem(page_no=2, bbox=BoundingBox(l=465.134, t=681.806, r=500.032, b=675.323, coord_origin=<CoordOrigin.BOTTOMLEFT: 'BOTTOMLEFT'>), charspan=(0, 9))], orig='Markdown,', text='Markdown,', formatting=None, hyperlink=None), TextItem(self_ref='#/texts/45', parent=RefItem(cref='#/pictures/0'), children=[], content_layer=<ContentLayer.BODY: 'body'>, label=<DocItemLabel.TEXT: 'text'>, prov=[ProvenanceItem(page_no=2, bbox=BoundingBox(l=472.484, t=673.392, r=492.697, b=666.909, coord_origin=<CoordOrigin.BOTTOMLEFT: 'BOTTOMLEFT'>), charspan=(0, 5))], orig='HTML,', text='HTML,', formatting=None, hyperlink=None), TextItem(self_ref='#/texts/46', parent=RefItem(cref='#/pictures/0'), children=[], content_layer=<ContentLayer.BODY: 'body'>, label=<DocItemLabel.TEXT: 'text'>, prov=[ProvenanceItem(page_no=2, bbox=BoundingBox(l=470.034, t=664.95, r=494.969, b=658.467, coord_origin=<CoordOrigin.BOTTOMLEFT: 'BOTTOMLEFT'>), charspan=(0, 8))], orig='Figures,', text='Figures,', formatting=None, hyperlink=None), TextItem(self_ref='#/texts/47', parent=RefItem(cref='#/pictures/0'), children=[], content_layer=<ContentLayer.BODY: 'body'>, label=<DocItemLabel.TEXT: 'text'>, prov=[ProvenanceItem(page_no=2, bbox=BoundingBox(l=479.758, t=656.536, r=485.252, b=650.053, coord_origin=<CoordOrigin.BOTTOMLEFT: 'BOTTOMLEFT'>), charspan=(0, 1))], orig='…', text='…', formatting=None, hyperlink=None), TextItem(self_ref='#/texts/48', parent=RefItem(cref='#/pictures/0'), children=[], content_layer=<ContentLayer.BODY: 'body'>, label=<DocItemLabel.TEXT: 'text'>, prov=[ProvenanceItem(page_no=2, bbox=BoundingBox(l=474.738, t=704.34, r=488.818, b=695.922, coord_origin=<CoordOrigin.BOTTOMLEFT: 'BOTTOMLEFT'>), charspan=(0, 3))], orig='{;}', text='{;}', formatting=None, hyperlink=None), TextItem(self_ref='#/texts/49', parent=RefItem(cref='#/pictures/0'), children=[], content_layer=<ContentLayer.BODY: 'body'>, label=<DocItemLabel.TEXT: 'text'>, prov=[ProvenanceItem(page_no=2, bbox=BoundingBox(l=470.972, t=717.43, r=480.345, b=709.012, coord_origin=<CoordOrigin.BOTTOMLEFT: 'BOTTOMLEFT'>), charspan=(0, 2))], orig='##', text='##', formatting=None, hyperlink=None), TextItem(self_ref='#/texts/50', parent=RefItem(cref='#/pictures/0'), children=[], content_layer=<ContentLayer.BODY: 'body'>, label=<DocItemLabel.TEXT: 'text'>, prov=[ProvenanceItem(page_no=2, bbox=BoundingBox(l=478.799, t=570.459, r=486.823, b=560.992, coord_origin=<CoordOrigin.BOTTOMLEFT: 'BOTTOMLEFT'>), charspan=(0, 1))], orig='…', text='…', formatting=None, hyperlink=None), TextItem(self_ref='#/texts/51', parent=RefItem(cref='#/pictures/0'), children=[], content_layer=<ContentLayer.BODY: 'body'>, label=<DocItemLabel.TEXT: 'text'>, prov=[ProvenanceItem(page_no=2, bbox=BoundingBox(l=467.633, t=593.36, r=496.947, b=586.877, coord_origin=<CoordOrigin.BOTTOMLEFT: 'BOTTOMLEFT'>), charspan=(0, 8))], orig='Chunking', text='Chunking', formatting=None, hyperlink=None), TextItem(self_ref='#/texts/52', parent=RefItem(cref='#/pictures/0'), children=[], content_layer=<ContentLayer.BODY: 'body'>, label=<DocItemLabel.TEXT: 'text'>, prov=[ProvenanceItem(page_no=2, bbox=BoundingBox(l=470.118, t=584.925, r=494.375, b=578.442, coord_origin=<CoordOrigin.BOTTOMLEFT: 'BOTTOMLEFT'>), charspan=(0, 7))], orig='for RAG', text='for RAG', formatting=None, hyperlink=None), TextItem(self_ref='#/texts/53', parent=RefItem(cref='#/pictures/0'), children=[], content_layer=<ContentLayer.BODY: 'body'>, label=<DocItemLabel.TEXT: 'text'>, prov=[ProvenanceItem(page_no=2, bbox=BoundingBox(l=414.153, t=622.179, r=437.787, b=615.697, coord_origin=<CoordOrigin.BOTTOMLEFT: 'BOTTOMLEFT'>), charspan=(0, 7))], orig='Docling', text='Docling', formatting=None, hyperlink=None), TextItem(self_ref='#/texts/54', parent=RefItem(cref='#/pictures/0'), children=[], content_layer=<ContentLayer.BODY: 'body'>, label=<DocItemLabel.TEXT: 'text'>, prov=[ProvenanceItem(page_no=2, bbox=BoundingBox(l=409.659, t=613.765, r=441.962, b=607.282, coord_origin=<CoordOrigin.BOTTOMLEFT: 'BOTTOMLEFT'>), charspan=(0, 8))], orig='Document', text='Document', formatting=None, hyperlink=None), TextItem(self_ref='#/texts/55', parent=RefItem(cref='#/pictures/0'), children=[], content_layer=<ContentLayer.BODY: 'body'>, label=<DocItemLabel.TEXT: 'text'>, prov=[ProvenanceItem(page_no=2, bbox=BoundingBox(l=257.385, t=619.312, r=272.649, b=613.519, coord_origin=<CoordOrigin.BOTTOMLEFT: 'BOTTOMLEFT'>), charspan=(0, 5))], orig='ascii', text='ascii', formatting=None, hyperlink=None), TextItem(self_ref='#/texts/56', parent=RefItem(cref='#/pictures/0'), children=[], content_layer=<ContentLayer.BODY: 'body'>, label=<DocItemLabel.TEXT: 'text'>, prov=[ProvenanceItem(page_no=2, bbox=BoundingBox(l=203.926, t=565.608, r=218.487, b=557.253, coord_origin=<CoordOrigin.BOTTOMLEFT: 'BOTTOMLEFT'>), charspan=(0, 4))], orig='docx', text='docx', formatting=None, hyperlink=None), TextItem(self_ref='#/texts/57', parent=RefItem(cref='#/pictures/0'), children=[], content_layer=<ContentLayer.BODY: 'body'>, label=<DocItemLabel.TEXT: 'text'>, prov=[ProvenanceItem(page_no=2, bbox=BoundingBox(l=231.156, t=565.608, r=244.15, b=557.253, coord_origin=<CoordOrigin.BOTTOMLEFT: 'BOTTOMLEFT'>), charspan=(0, 4))], orig='pptx', text='pptx', formatting=None, hyperlink=None), TextItem(self_ref='#/texts/58', parent=RefItem(cref='#/pictures/0'), children=[], content_layer=<ContentLayer.BODY: 'body'>, label=<DocItemLabel.TEXT: 'text'>, prov=[ProvenanceItem(page_no=2, bbox=BoundingBox(l=258.316, t=565.608, r=269.723, b=557.253, coord_origin=<CoordOrigin.BOTTOMLEFT: 'BOTTOMLEFT'>), charspan=(0, 4))], orig='xlsx', text='xlsx', formatting=None, hyperlink=None), TextItem(self_ref='#/texts/59', parent=RefItem(cref='#/pictures/0'), children=[], content_layer=<ContentLayer.BODY: 'body'>, label=<DocItemLabel.TEXT: 'text'>, prov=[ProvenanceItem(page_no=2, bbox=BoundingBox(l=206.075, t=604.738, r=215.688, b=596.383, coord_origin=<CoordOrigin.BOTTOMLEFT: 'BOTTOMLEFT'>), charspan=(0, 2))], orig='md', text='md', formatting=None, hyperlink=None), TextItem(self_ref='#/texts/60', parent=RefItem(cref='#/pictures/0'), children=[], content_layer=<ContentLayer.BODY: 'body'>, label=<DocItemLabel.TEXT: 'text'>, prov=[ProvenanceItem(page_no=2, bbox=BoundingBox(l=231.73, t=604.178, r=245.579, b=595.823, coord_origin=<CoordOrigin.BOTTOMLEFT: 'BOTTOMLEFT'>), charspan=(0, 4))], orig='html', text='html', formatting=None, hyperlink=None), TextItem(self_ref='#/texts/61', parent=RefItem(cref='#/pictures/0'), children=[], content_layer=<ContentLayer.BODY: 'body'>, label=<DocItemLabel.TEXT: 'text'>, prov=[ProvenanceItem(page_no=2, bbox=BoundingBox(l=253.325, t=603.682, r=274.775, b=596.609, coord_origin=<CoordOrigin.BOTTOMLEFT: 'BOTTOMLEFT'>), charspan=(0, 8))], orig='AsciiDoc', text='AsciiDoc', formatting=None, hyperlink=None), TextItem(self_ref='#/texts/62', parent=RefItem(cref='#/pictures/0'), children=[], content_layer=<ContentLayer.BODY: 'body'>, label=<DocItemLabel.TEXT: 'text'>, prov=[ProvenanceItem(page_no=2, bbox=BoundingBox(l=103.681, t=700.779, r=113.609, b=692.425, coord_origin=<CoordOrigin.BOTTOMLEFT: 'BOTTOMLEFT'>), charspan=(0, 3))], orig='pdf', text='pdf', formatting=None, hyperlink=None), TextItem(self_ref='#/texts/63', parent=RefItem(cref='#/pictures/0'), children=[], content_layer=<ContentLayer.BODY: 'body'>, label=<DocItemLabel.TEXT: 'text'>, prov=[ProvenanceItem(page_no=2, bbox=BoundingBox(l=98.938, t=661.194, r=120.711, b=652.839, coord_origin=<CoordOrigin.BOTTOMLEFT: 'BOTTOMLEFT'>), charspan=(0, 6))], orig='images', text='images', formatting=None, hyperlink=None), TextItem(self_ref='#/texts/64', parent=RefItem(cref='#/body'), children=[], content_layer=<ContentLayer.BODY: 'body'>, label=<DocItemLabel.TEXT: 'text'>, prov=[ProvenanceItem(page_no=2, bbox=BoundingBox(l=54.0, t=470.156, r=292.505, b=450.645, coord_origin=<CoordOrigin.BOTTOMLEFT: 'BOTTOMLEFT'>), charspan=(0, 91))], orig='to hallucinations, conversion quality, time-to-solution, and compute resource requirements.', text='to hallucinations, conversion quality, time-to-solution, and compute resource requirements.', formatting=None, hyperlink=None), TextItem(self_ref='#/texts/65', parent=RefItem(cref='#/body'), children=[], content_layer=<ContentLayer.BODY: 'body'>, label=<DocItemLabel.TEXT: 'text'>, prov=[ProvenanceItem(page_no=2, bbox=BoundingBox(l=54.0, t=447.882, r=292.505, b=274.947, coord_origin=<CoordOrigin.BOTTOMLEFT: 'BOTTOMLEFT'>), charspan=(0, 851))], orig='The most popular conversion tools today leverage visionlanguage models (VLMs), which process page images to text and markup directly. Among proprietary solutions, prominent examples include GPT-4o (OpenAI), Claude (Anthropic), and Gemini (Google). In the open-source domain, LLaVA-based models, such as LLaVA-next, are noteworthy. However, all generative AI-based models face two significant challenges. First, they are prone to hallucinations, i.e., their output may contain false information which is not present in the source document - a critical issue when faithful transcription of document content is required. Second, these models demand substantial computational resources, making the conversion process expensive. Consequently, VLM-based tools are typically offered as SaaS, with compute-intensive operations performed remotely in the cloud.', text='The most popular conversion tools today leverage visionlanguage models (VLMs), which process page images to text and markup directly. Among proprietary solutions, prominent examples include GPT-4o (OpenAI), Claude (Anthropic), and Gemini (Google). In the open-source domain, LLaVA-based models, such as LLaVA-next, are noteworthy. However, all generative AI-based models face two significant challenges. First, they are prone to hallucinations, i.e., their output may contain false information which is not present in the source document - a critical issue when faithful transcription of document content is required. Second, these models demand substantial computational resources, making the conversion process expensive. Consequently, VLM-based tools are typically offered as SaaS, with compute-intensive operations performed remotely in the cloud.', formatting=None, hyperlink=None), TextItem(self_ref='#/texts/66', parent=RefItem(cref='#/body'), children=[], content_layer=<ContentLayer.BODY: 'body'>, label=<DocItemLabel.TEXT: 'text'>, prov=[ProvenanceItem(page_no=2, bbox=BoundingBox(l=54.0, t=272.18399999999997, r=292.505, b=132.125, coord_origin=<CoordOrigin.BOTTOMLEFT: 'BOTTOMLEFT'>), charspan=(0, 731))], orig='A second category of solutions prioritizes on-premises deployment, either as Web APIs or as libraries. Examples include Adobe Acrobat, Grobid, Marker, MinerU, Unstructured, and others. These solutions often rely on multiple specialized models, such as OCR, layout analysis, and table recognition models. Docling falls into this category, leveraging modular, task-specific models which recover document structures and features only. All text content is taken from the programmatic PDF or transcribed through OCR methods. This design ensures faithful conversion, without the risk of generating false content. However, it necessitates maintaining a diverse set of models for different document components, such as formulas or figures.', text='A second category of solutions prioritizes on-premises deployment, either as Web APIs or as libraries. Examples include Adobe Acrobat, Grobid, Marker, MinerU, Unstructured, and others. These solutions often rely on multiple specialized models, such as OCR, layout analysis, and table recognition models. Docling falls into this category, leveraging modular, task-specific models which recover document structures and features only. All text content is taken from the programmatic PDF or transcribed through OCR methods. This design ensures faithful conversion, without the risk of generating false content. However, it necessitates maintaining a diverse set of models for different document components, such as formulas or figures.', formatting=None, hyperlink=None), TextItem(self_ref='#/texts/67', parent=RefItem(cref='#/body'), children=[], content_layer=<ContentLayer.BODY: 'body'>, label=<DocItemLabel.TEXT: 'text'>, prov=[ProvenanceItem(page_no=2, bbox=BoundingBox(l=54.0, t=129.36300000000006, r=292.505, b=87.93399999999997, coord_origin=<CoordOrigin.BOTTOMLEFT: 'BOTTOMLEFT'>), charspan=(0, 236)), ProvenanceItem(page_no=2, bbox=BoundingBox(l=319.5, t=470.156, r=558.005, b=439.686, coord_origin=<CoordOrigin.BOTTOMLEFT: 'BOTTOMLEFT'>), charspan=(237, 384))], orig='Within this category, Docling distinguishes itself through its permissive MIT license, allowing organizations to integrate Docling into their solutions without incurring licensing fees or adopting restrictive licenses (e.g., GPL). Addi- tionally, Docling offers highly accurate, resource-efficient, and fast models, making it well-suited for integration with many standard frameworks.', text='Within this category, Docling distinguishes itself through its permissive MIT license, allowing organizations to integrate Docling into their solutions without incurring licensing fees or adopting restrictive licenses (e.g., GPL). Addi- tionally, Docling offers highly accurate, resource-efficient, and fast models, making it well-suited for integration with many standard frameworks.', formatting=None, hyperlink=None), TextItem(self_ref='#/texts/68', parent=RefItem(cref='#/body'), children=[], content_layer=<ContentLayer.BODY: 'body'>, label=<DocItemLabel.TEXT: 'text'>, prov=[ProvenanceItem(page_no=2, bbox=BoundingBox(l=319.5, t=436.28, r=558.005, b=394.851, coord_origin=<CoordOrigin.BOTTOMLEFT: 'BOTTOMLEFT'>), charspan=(0, 190))], orig='In summary, Docling stands out as a cost-effective, accurate and transparent open-source library with a permissive license, offering a reliable and flexible solution for document conversion.', text='In summary, Docling stands out as a cost-effective, accurate and transparent open-source library with a permissive license, offering a reliable and flexible solution for document conversion.', formatting=None, hyperlink=None), SectionHeaderItem(self_ref='#/texts/69', parent=RefItem(cref='#/body'), children=[], content_layer=<ContentLayer.BODY: 'body'>, label=<DocItemLabel.SECTION_HEADER: 'section_header'>, prov=[ProvenanceItem(page_no=2, bbox=BoundingBox(l=367.576, t=379.005, r=509.927, b=368.257, coord_origin=<CoordOrigin.BOTTOMLEFT: 'BOTTOMLEFT'>), charspan=(0, 25))], orig='3 Design and Architecture', text='3 Design and Architecture', formatting=None, hyperlink=None, level=1), TextItem(self_ref='#/texts/70', parent=RefItem(cref='#/body'), children=[], content_layer=<ContentLayer.BODY: 'body'>, label=<DocItemLabel.TEXT: 'text'>, prov=[ProvenanceItem(page_no=2, bbox=BoundingBox(l=319.5, t=360.296, r=558.005, b=264.073, coord_origin=<CoordOrigin.BOTTOMLEFT: 'BOTTOMLEFT'>), charspan=(0, 492))], orig='Docling is designed in a modular fashion with extensibility in mind, and it builds on three main concepts: pipelines, parser backends, and the DoclingDocument data model as its centerpiece (see Figure 1). Pipelines and parser backends share the responsibility of constructing and enriching a DoclingDocument representation from any supported input format. The DoclingDocument data model with its APIs enable inspection, export, and downstream processing for various applications, such as RAG.', text='Docling is designed in a modular fashion with extensibility in mind, and it builds on three main concepts: pipelines, parser backends, and the DoclingDocument data model as its centerpiece (see Figure 1). Pipelines and parser backends share the responsibility of constructing and enriching a DoclingDocument representation from any supported input format. The DoclingDocument data model with its APIs enable inspection, export, and downstream processing for various applications, such as RAG.', formatting=None, hyperlink=None), SectionHeaderItem(self_ref='#/texts/71', parent=RefItem(cref='#/body'), children=[], content_layer=<ContentLayer.BODY: 'body'>, label=<DocItemLabel.SECTION_HEADER: 'section_header'>, prov=[ProvenanceItem(page_no=2, bbox=BoundingBox(l=319.5, t=249.49700000000007, r=430.402, b=239.69000000000005, coord_origin=<CoordOrigin.BOTTOMLEFT: 'BOTTOMLEFT'>), charspan=(0, 20))], orig='3.1 Docling Document', text='3.1 Docling Document', formatting=None, hyperlink=None, level=1), TextItem(self_ref='#/texts/72', parent=RefItem(cref='#/body'), children=[], content_layer=<ContentLayer.BODY: 'body'>, label=<DocItemLabel.TEXT: 'text'>, prov=[ProvenanceItem(page_no=2, bbox=BoundingBox(l=319.5, t=231.51099999999997, r=558.005, b=201.04099999999994, coord_origin=<CoordOrigin.BOTTOMLEFT: 'BOTTOMLEFT'>), charspan=(0, 159))], orig='Docling v2 introduces a unified document representation, DoclingDocument , as a Pydantic data model that can express various common document features, such as:', text='Docling v2 introduces a unified document representation, DoclingDocument , as a Pydantic data model that can express various common document features, such as:', formatting=None, hyperlink=None), ListItem(self_ref='#/texts/73', parent=RefItem(cref='#/groups/1'), children=[], content_layer=<ContentLayer.BODY: 'body'>, label=<DocItemLabel.LIST_ITEM: 'list_item'>, prov=[ProvenanceItem(page_no=2, bbox=BoundingBox(l=323.983, t=191.15499999999997, r=527.28, b=182.60300000000007, coord_origin=<CoordOrigin.BOTTOMLEFT: 'BOTTOMLEFT'>), charspan=(0, 52))], orig='· Text, Tables, Pictures, Captions, Lists, and more.', text='Text, Tables, Pictures, Captions, Lists, and more.', formatting=None, hyperlink=None, enumerated=False, marker='·'), ListItem(self_ref='#/texts/74', parent=RefItem(cref='#/groups/1'), children=[], content_layer=<ContentLayer.BODY: 'body'>, label=<DocItemLabel.LIST_ITEM: 'list_item'>, prov=[ProvenanceItem(page_no=2, bbox=BoundingBox(l=323.983, t=175.707, r=517.785, b=167.15499999999997, coord_origin=<CoordOrigin.BOTTOMLEFT: 'BOTTOMLEFT'>), charspan=(0, 46))], orig='· Document hierarchy with sections and groups.', text='Document hierarchy with sections and groups.', formatting=None, hyperlink=None, enumerated=False, marker='·'), ListItem(self_ref='#/texts/75', parent=RefItem(cref='#/groups/1'), children=[], content_layer=<ContentLayer.BODY: 'body'>, label=<DocItemLabel.LIST_ITEM: 'list_item'>, prov=[ProvenanceItem(page_no=2, bbox=BoundingBox(l=323.983, t=160.25900000000001, r=558.004, b=140.74800000000005, coord_origin=<CoordOrigin.BOTTOMLEFT: 'BOTTOMLEFT'>), charspan=(0, 68))], orig='· Disambiguation between main body and headers, footers (furniture).', text='Disambiguation between main body and headers, footers (furniture).', formatting=None, hyperlink=None, enumerated=False, marker='·'), ListItem(self_ref='#/texts/76', parent=RefItem(cref='#/groups/1'), children=[], content_layer=<ContentLayer.BODY: 'body'>, label=<DocItemLabel.LIST_ITEM: 'list_item'>, prov=[ProvenanceItem(page_no=2, bbox=BoundingBox(l=323.983, t=133.85199999999998, r=558.004, b=114.34100000000001, coord_origin=<CoordOrigin.BOTTOMLEFT: 'BOTTOMLEFT'>), charspan=(0, 72))], orig='· Layout information (i.e., bounding boxes) for all items, if available.', text='Layout information (i.e., bounding boxes) for all items, if available.', formatting=None, hyperlink=None, enumerated=False, marker='·'), ListItem(self_ref='#/texts/77', parent=RefItem(cref='#/groups/1'), children=[], content_layer=<ContentLayer.BODY: 'body'>, label=<DocItemLabel.LIST_ITEM: 'list_item'>, prov=[ProvenanceItem(page_no=2, bbox=BoundingBox(l=323.983, t=107.44499999999994, r=558.004, b=87.93399999999997, coord_origin=<CoordOrigin.BOTTOMLEFT: 'BOTTOMLEFT'>), charspan=(0, 63))], orig='· Provenance information (i.e., page numbers, document origin).', text='Provenance information (i.e., page numbers, document origin).', formatting=None, hyperlink=None, enumerated=False, marker='·'), TextItem(self_ref='#/texts/78', parent=RefItem(cref='#/body'), children=[], content_layer=<ContentLayer.BODY: 'body'>, label=<DocItemLabel.TEXT: 'text'>, prov=[ProvenanceItem(page_no=3, bbox=BoundingBox(l=54.0, t=734.523, r=292.505, b=704.054, coord_origin=<CoordOrigin.BOTTOMLEFT: 'BOTTOMLEFT'>), charspan=(0, 136))], orig='With this data model, Docling enables representing document content in a unified manner, i.e., regardless of the source document format.', text='With this data model, Docling enables representing document content in a unified manner, i.e., regardless of the source document format.', formatting=None, hyperlink=None), TextItem(self_ref='#/texts/79', parent=RefItem(cref='#/body'), children=[], content_layer=<ContentLayer.BODY: 'body'>, label=<DocItemLabel.TEXT: 'text'>, prov=[ProvenanceItem(page_no=3, bbox=BoundingBox(l=54.0, t=700.669, r=292.505, b=593.487, coord_origin=<CoordOrigin.BOTTOMLEFT: 'BOTTOMLEFT'>), charspan=(0, 483))], orig='Besides specifying the data model, the DoclingDocument class defines APIs encompassing document construction, inspection, and export. Using the respective methods, users can incrementally build a DoclingDocument , traverse its contents in reading order, or export to commonly used formats. Docling supports lossless serialization to (and deserialization from) JSON, and lossy export formats such as Markdown and HTML, which, unlike JSON, cannot retain all available meta information.', text='Besides specifying the data model, the DoclingDocument class defines APIs encompassing document construction, inspection, and export. Using the respective methods, users can incrementally build a DoclingDocument , traverse its contents in reading order, or export to commonly used formats. Docling supports lossless serialization to (and deserialization from) JSON, and lossy export formats such as Markdown and HTML, which, unlike JSON, cannot retain all available meta information.', formatting=None, hyperlink=None), TextItem(self_ref='#/texts/80', parent=RefItem(cref='#/body'), children=[], content_layer=<ContentLayer.BODY: 'body'>, label=<DocItemLabel.TEXT: 'text'>, prov=[ProvenanceItem(page_no=3, bbox=BoundingBox(l=54.0, t=590.102, r=292.505, b=461.002, coord_origin=<CoordOrigin.BOTTOMLEFT: 'BOTTOMLEFT'>), charspan=(0, 671))], orig='A DoclingDocument can additionally be passed to a chunker class, an abstraction that returns a stream of chunks, each of which captures some part of the document as a string accompanied by respective metadata. To enable both flexibility for downstream applications and out-of-the-box utility, Docling defines a chunker class hierarchy, providing a base type as well as specific subclasses. By using the base chunker type, downstream applications can leverage popular frameworks like LangChain or LlamaIndex, which provide a high degree of flexibility in the chunking approach. Users can therefore plug in any built-in, self-defined, or third-party chunker implementation.', text='A DoclingDocument can additionally be passed to a chunker class, an abstraction that returns a stream of chunks, each of which captures some part of the document as a string accompanied by respective metadata. To enable both flexibility for downstream applications and out-of-the-box utility, Docling defines a chunker class hierarchy, providing a base type as well as specific subclasses. By using the base chunker type, downstream applications can leverage popular frameworks like LangChain or LlamaIndex, which provide a high degree of flexibility in the chunking approach. Users can therefore plug in any built-in, self-defined, or third-party chunker implementation.', formatting=None, hyperlink=None), SectionHeaderItem(self_ref='#/texts/81', parent=RefItem(cref='#/body'), children=[], content_layer=<ContentLayer.BODY: 'body'>, label=<DocItemLabel.SECTION_HEADER: 'section_header'>, prov=[ProvenanceItem(page_no=3, bbox=BoundingBox(l=54.0, t=446.496, r=156.807, b=436.689, coord_origin=<CoordOrigin.BOTTOMLEFT: 'BOTTOMLEFT'>), charspan=(0, 19))], orig='3.2 Parser Backends', text='3.2 Parser Backends', formatting=None, hyperlink=None, level=1), TextItem(self_ref='#/texts/82', parent=RefItem(cref='#/body'), children=[], content_layer=<ContentLayer.BODY: 'body'>, label=<DocItemLabel.TEXT: 'text'>, prov=[ProvenanceItem(page_no=3, bbox=BoundingBox(l=54.0, t=428.574, r=292.505, b=409.063, coord_origin=<CoordOrigin.BOTTOMLEFT: 'BOTTOMLEFT'>), charspan=(0, 59))], orig='Document formats can be broadly categorized into two types:', text='Document formats can be broadly categorized into two types:', formatting=None, hyperlink=None), ListItem(self_ref='#/texts/83', parent=RefItem(cref='#/groups/2'), children=[], content_layer=<ContentLayer.BODY: 'body'>, label=<DocItemLabel.LIST_ITEM: 'list_item'>, prov=[ProvenanceItem(page_no=3, bbox=BoundingBox(l=54.498, t=401.103, r=292.504, b=326.41, coord_origin=<CoordOrigin.BOTTOMLEFT: 'BOTTOMLEFT'>), charspan=(0, 395))], orig='1. Low-level formats , like PDF files or scanned images. These formats primarily encode the visual representation of the document, containing instructions for rendering text cells and lines or defining image pixels. Most semantics of the represented content are typically lost and need to be recovered through specialized AI methods, such as OCR, layout analysis, or table structure recognition.', text='Low-level formats , like PDF files or scanned images. These formats primarily encode the visual representation of the document, containing instructions for rendering text cells and lines or defining image pixels. Most semantics of the represented content are typically lost and need to be recovered through specialized AI methods, such as OCR, layout analysis, or table structure recognition.', formatting=None, hyperlink=None, enumerated=True, marker='1.'), ListItem(self_ref='#/texts/84', parent=RefItem(cref='#/groups/2'), children=[], content_layer=<ContentLayer.BODY: 'body'>, label=<DocItemLabel.LIST_ITEM: 'list_item'>, prov=[ProvenanceItem(page_no=3, bbox=BoundingBox(l=54.498, t=319.945, r=292.504, b=278.12799999999993, coord_origin=<CoordOrigin.BOTTOMLEFT: 'BOTTOMLEFT'>), charspan=(0, 215))], orig='2. Markup-based formats , including MS Office, HTML, Markdown, and others. These formats preserve the semantics of the content (e.g., sections, lists, tables, and figures) and are comparatively inexpensive to parse.', text='Markup-based formats , including MS Office, HTML, Markdown, and others. These formats preserve the semantics of the content (e.g., sections, lists, tables, and figures) and are comparatively inexpensive to parse.', formatting=None, hyperlink=None, enumerated=True, marker='2.'), TextItem(self_ref='#/texts/85', parent=RefItem(cref='#/body'), children=[], content_layer=<ContentLayer.BODY: 'body'>, label=<DocItemLabel.TEXT: 'text'>, prov=[ProvenanceItem(page_no=3, bbox=BoundingBox(l=54.0, t=269.78099999999995, r=292.505, b=129.72199999999998, coord_origin=<CoordOrigin.BOTTOMLEFT: 'BOTTOMLEFT'>), charspan=(0, 742))], orig='Docling implements several parser backends to read and interpret different formats and it routes their output to a fitting processing pipeline. For PDFs Docling provides backends which: a) retrieve all text content and their geometric properties, b) render the visual representation of each page as it would appear in a PDF viewer. For markup-based formats, the respective backends carry the responsibility of creating a DoclingDocument representation directly. For some formats, such as PowerPoint slides, element locations and page provenance are available, whereas in other formats (for example, MS Word or HTML), this information is unknown unless rendered in a Word viewer or a browser. The DoclingDocument data model handles both cases.', text='Docling implements several parser backends to read and interpret different formats and it routes their output to a fitting processing pipeline. For PDFs Docling provides backends which: a) retrieve all text content and their geometric properties, b) render the visual representation of each page as it would appear in a PDF viewer. For markup-based formats, the respective backends carry the responsibility of creating a DoclingDocument representation directly. For some formats, such as PowerPoint slides, element locations and page provenance are available, whereas in other formats (for example, MS Word or HTML), this information is unknown unless rendered in a Word viewer or a browser. The DoclingDocument data model handles both cases.', formatting=None, hyperlink=None), TextItem(self_ref='#/texts/86', parent=RefItem(cref='#/body'), children=[], content_layer=<ContentLayer.BODY: 'body'>, label=<DocItemLabel.TEXT: 'text'>, prov=[ProvenanceItem(page_no=3, bbox=BoundingBox(l=54.0, t=118.79200000000003, r=292.505, b=87.93399999999997, coord_origin=<CoordOrigin.BOTTOMLEFT: 'BOTTOMLEFT'>), charspan=(0, 172)), ProvenanceItem(page_no=3, bbox=BoundingBox(l=319.5, t=734.523, r=558.005, b=693.095, coord_origin=<CoordOrigin.BOTTOMLEFT: 'BOTTOMLEFT'>), charspan=(173, 374))], orig='PDF Backends While several open-source PDF parsing Python libraries are available, in practice we ran into various limitations, among which are restrictive licensing (e.g., pymupdf (pym 2024)), poor speed, or unrecoverable quality issues, such as merged text cells across far-apart text tokens or table columns (pypdfium, PyPDF) (PyPDFium Team 2024; pypdf Maintainers 2024).', text='PDF Backends While several open-source PDF parsing Python libraries are available, in practice we ran into various limitations, among which are restrictive licensing (e.g., pymupdf (pym 2024)), poor speed, or unrecoverable quality issues, such as merged text cells across far-apart text tokens or table columns (pypdfium, PyPDF) (PyPDFium Team 2024; pypdf Maintainers 2024).', formatting=None, hyperlink=None), TextItem(self_ref='#/texts/87', parent=RefItem(cref='#/body'), children=[], content_layer=<ContentLayer.BODY: 'body'>, label=<DocItemLabel.TEXT: 'text'>, prov=[ProvenanceItem(page_no=3, bbox=BoundingBox(l=319.5, t=690.615, r=558.005, b=627.268, coord_origin=<CoordOrigin.BOTTOMLEFT: 'BOTTOMLEFT'>), charspan=(0, 322))], orig='We therefore developed a custom-built PDF parser, which is based on the low-level library qpdf (Berkenbilt 2024). Our PDF parser is made available in a separate package named docling-parse and acts as the default PDF backend in Docling. As an alternative, we provide a PDF backend relying on pypdfium (PyPDFium Team 2024).', text='We therefore developed a custom-built PDF parser, which is based on the low-level library qpdf (Berkenbilt 2024). Our PDF parser is made available in a separate package named docling-parse and acts as the default PDF backend in Docling. As an alternative, we provide a PDF backend relying on pypdfium (PyPDFium Team 2024).', formatting=None, hyperlink=None), TextItem(self_ref='#/texts/88', parent=RefItem(cref='#/body'), children=[], content_layer=<ContentLayer.BODY: 'body'>, label=<DocItemLabel.TEXT: 'text'>, prov=[ProvenanceItem(page_no=3, bbox=BoundingBox(l=319.5, t=619.053, r=558.005, b=445.729, coord_origin=<CoordOrigin.BOTTOMLEFT: 'BOTTOMLEFT'>), charspan=(0, 843))], orig='Other Backends Markup-based formats like HTML, Markdown, or Microsoft Office (Word, PowerPoint, Excel) as well as plain formats like AsciiDoc can be transformed directly to a DoclingDocument representation with the help of several third-party format parsing libraries. For HTML documents we utilize BeautifulSoup (Richardson 2004-2024), for Markdown we use the Marko library (Ming 2019-2024), and for Office XML-based formats (Word, PowerPoint, Excel) we implement custom extensions on top of the python-docx (Canny and contributors 2013-2024a), python-pptx (Canny and contributors 20132024b), and openpyxl (Eric Gazoni 2010-2024) libraries, respectively. During parsing, we identify and extract common document elements (e.g., title, headings, paragraphs, tables, lists, figures, and code) and reflect the correct hierarchy level if possible.', text='Other Backends Markup-based formats like HTML, Markdown, or Microsoft Office (Word, PowerPoint, Excel) as well as plain formats like AsciiDoc can be transformed directly to a DoclingDocument representation with the help of several third-party format parsing libraries. For HTML documents we utilize BeautifulSoup (Richardson 2004-2024), for Markdown we use the Marko library (Ming 2019-2024), and for Office XML-based formats (Word, PowerPoint, Excel) we implement custom extensions on top of the python-docx (Canny and contributors 2013-2024a), python-pptx (Canny and contributors 20132024b), and openpyxl (Eric Gazoni 2010-2024) libraries, respectively. During parsing, we identify and extract common document elements (e.g., title, headings, paragraphs, tables, lists, figures, and code) and reflect the correct hierarchy level if possible.', formatting=None, hyperlink=None), SectionHeaderItem(self_ref='#/texts/89', parent=RefItem(cref='#/body'), children=[], content_layer=<ContentLayer.BODY: 'body'>, label=<DocItemLabel.SECTION_HEADER: 'section_header'>, prov=[ProvenanceItem(page_no=3, bbox=BoundingBox(l=319.5, t=434.163, r=385.871, b=424.356, coord_origin=<CoordOrigin.BOTTOMLEFT: 'BOTTOMLEFT'>), charspan=(0, 13))], orig='3.3 Pipelines', text='3.3 Pipelines', formatting=None, hyperlink=None, level=1), TextItem(self_ref='#/texts/90', parent=RefItem(cref='#/body'), children=[], content_layer=<ContentLayer.BODY: 'body'>, label=<DocItemLabel.TEXT: 'text'>, prov=[ProvenanceItem(page_no=3, bbox=BoundingBox(l=319.5, t=418.955, r=558.005, b=366.568, coord_origin=<CoordOrigin.BOTTOMLEFT: 'BOTTOMLEFT'>), charspan=(0, 284))], orig='Pipelines in Docling serve as an orchestration layer which iterates through documents, gathers the extracted data from a parser backend, and applies a chain of models to: a) build up the DoclingDocument representation and b) enrich this representation further (e.g., classify images).', text='Pipelines in Docling serve as an orchestration layer which iterates through documents, gathers the extracted data from a parser backend, and applies a chain of models to: a) build up the DoclingDocument representation and b) enrich this representation further (e.g., classify images).', formatting=None, hyperlink=None), TextItem(self_ref='#/texts/91', parent=RefItem(cref='#/body'), children=[], content_layer=<ContentLayer.BODY: 'body'>, label=<DocItemLabel.TEXT: 'text'>, prov=[ProvenanceItem(page_no=3, bbox=BoundingBox(l=319.5, t=364.257, r=558.005, b=289.782, coord_origin=<CoordOrigin.BOTTOMLEFT: 'BOTTOMLEFT'>), charspan=(0, 348))], orig='Docling provides two standard pipelines. The StandardPdfPipeline leverages several state-of-the-art AI models to reconstruct a high-quality DoclingDocument representation from PDF or image input, as described in section 4. The SimplePipeline handles all markup-based formats (Office, HTML, AsciiDoc) and may apply further enrichment models as well.', text='Docling provides two standard pipelines. The StandardPdfPipeline leverages several state-of-the-art AI models to reconstruct a high-quality DoclingDocument representation from PDF or image input, as described in section 4. The SimplePipeline handles all markup-based formats (Office, HTML, AsciiDoc) and may apply further enrichment models as well.', formatting=None, hyperlink=None), TextItem(self_ref='#/texts/92', parent=RefItem(cref='#/body'), children=[], content_layer=<ContentLayer.BODY: 'body'>, label=<DocItemLabel.TEXT: 'text'>, prov=[ProvenanceItem(page_no=3, bbox=BoundingBox(l=319.5, t=287.302, r=558.005, b=212.99700000000007, coord_origin=<CoordOrigin.BOTTOMLEFT: 'BOTTOMLEFT'>), charspan=(0, 398))], orig='Pipelines can be fully customized by sub-classing from an abstract base class or cloning the default model pipeline. This effectively allows to fully customize the chain of models, add or replace models, and introduce additional pipeline configuration parameters. To create and use a custom model pipeline, you can provide a custom pipeline class as an argument to the main document conversion API.', text='Pipelines can be fully customized by sub-classing from an abstract base class or cloning the default model pipeline. This effectively allows to fully customize the chain of models, add or replace models, and introduce additional pipeline configuration parameters. To create and use a custom model pipeline, you can provide a custom pipeline class as an argument to the main document conversion API.', formatting=None, hyperlink=None), SectionHeaderItem(self_ref='#/texts/93', parent=RefItem(cref='#/body'), children=[], content_layer=<ContentLayer.BODY: 'body'>, label=<DocItemLabel.SECTION_HEADER: 'section_header'>, prov=[ProvenanceItem(page_no=3, bbox=BoundingBox(l=365.657, t=200.15999999999997, r=511.845, b=189.41200000000003, coord_origin=<CoordOrigin.BOTTOMLEFT: 'BOTTOMLEFT'>), charspan=(0, 25))], orig='4 PDF Conversion Pipeline', text='4 PDF Conversion Pipeline', formatting=None, hyperlink=None, level=1), TextItem(self_ref='#/texts/94', parent=RefItem(cref='#/body'), children=[], content_layer=<ContentLayer.BODY: 'body'>, label=<DocItemLabel.TEXT: 'text'>, prov=[ProvenanceItem(page_no=3, bbox=BoundingBox(l=319.5, t=184.231, r=558.005, b=142.80200000000002, coord_origin=<CoordOrigin.BOTTOMLEFT: 'BOTTOMLEFT'>), charspan=(0, 205))], orig=\"The capability to recover detailed structure and content from PDF and image files is one of Docling's defining features. In this section, we outline the underlying methods and models that drive the system.\", text=\"The capability to recover detailed structure and content from PDF and image files is one of Docling's defining features. In this section, we outline the underlying methods and models that drive the system.\", formatting=None, hyperlink=None), TextItem(self_ref='#/texts/95', parent=RefItem(cref='#/body'), children=[], content_layer=<ContentLayer.BODY: 'body'>, label=<DocItemLabel.TEXT: 'text'>, prov=[ProvenanceItem(page_no=3, bbox=BoundingBox(l=319.5, t=140.322, r=558.005, b=87.93399999999997, coord_origin=<CoordOrigin.BOTTOMLEFT: 'BOTTOMLEFT'>), charspan=(0, 287)), ProvenanceItem(page_no=4, bbox=BoundingBox(l=54.0, t=734.523, r=292.505, b=649.259, coord_origin=<CoordOrigin.BOTTOMLEFT: 'BOTTOMLEFT'>), charspan=(288, 696))], orig='Each document is first parsed by a PDF backend, which retrieves the programmatic text tokens, consisting of string content and its coordinates on the page, and also renders a bitmap image of each page to support downstream operations. Any image format input is wrapped in a PDF container on the fly, and proceeds through the pipeline as a scanned PDF document. Then, the standard PDF pipeline applies a sequence of AI models independently on every page of the document to extract features and content, such as layout and table structures. Finally, the results from all pages are aggregated and passed through a post-processing stage, which eventually assembles the DoclingDocument representation.', text='Each document is first parsed by a PDF backend, which retrieves the programmatic text tokens, consisting of string content and its coordinates on the page, and also renders a bitmap image of each page to support downstream operations. Any image format input is wrapped in a PDF container on the fly, and proceeds through the pipeline as a scanned PDF document. Then, the standard PDF pipeline applies a sequence of AI models independently on every page of the document to extract features and content, such as layout and table structures. Finally, the results from all pages are aggregated and passed through a post-processing stage, which eventually assembles the DoclingDocument representation.', formatting=None, hyperlink=None), SectionHeaderItem(self_ref='#/texts/96', parent=RefItem(cref='#/body'), children=[], content_layer=<ContentLayer.BODY: 'body'>, label=<DocItemLabel.SECTION_HEADER: 'section_header'>, prov=[ProvenanceItem(page_no=4, bbox=BoundingBox(l=54.0, t=632.266, r=127.331, b=622.459, coord_origin=<CoordOrigin.BOTTOMLEFT: 'BOTTOMLEFT'>), charspan=(0, 13))], orig='4.1 AI Models', text='4.1 AI Models', formatting=None, hyperlink=None, level=1), TextItem(self_ref='#/texts/97', parent=RefItem(cref='#/body'), children=[], content_layer=<ContentLayer.BODY: 'body'>, label=<DocItemLabel.TEXT: 'text'>, prov=[ProvenanceItem(page_no=4, bbox=BoundingBox(l=54.0, t=612.049, r=292.505, b=504.867, coord_origin=<CoordOrigin.BOTTOMLEFT: 'BOTTOMLEFT'>), charspan=(0, 529))], orig='As part of Docling, we release two highly capable AI models to the open-source community, which have been developed and published recently by our team. The first model is a layout analysis model, an accurate object detector for page elements (Pfitzmann et al. 2022). The second model is TableFormer (Nassar et al. 2022; Lysak et al. 2023), a state-of-the-art table structure recognition model. We provide the pre-trained weights (hosted on Hugging Face) and a separate Python package for the inference code ( doclingibm-models ).', text='As part of Docling, we release two highly capable AI models to the open-source community, which have been developed and published recently by our team. The first model is a layout analysis model, an accurate object detector for page elements (Pfitzmann et al. 2022). The second model is TableFormer (Nassar et al. 2022; Lysak et al. 2023), a state-of-the-art table structure recognition model. We provide the pre-trained weights (hosted on Hugging Face) and a separate Python package for the inference code ( doclingibm-models ).', formatting=None, hyperlink=None), TextItem(self_ref='#/texts/98', parent=RefItem(cref='#/body'), children=[], content_layer=<ContentLayer.BODY: 'body'>, label=<DocItemLabel.TEXT: 'text'>, prov=[ProvenanceItem(page_no=4, bbox=BoundingBox(l=54.0, t=491.642, r=292.505, b=329.277, coord_origin=<CoordOrigin.BOTTOMLEFT: 'BOTTOMLEFT'>), charspan=(0, 832))], orig='Layout Analysis Model Our layout analysis model is an object detector which predicts the bounding-boxes and classes of various elements on the image of a given page. Its architecture is derived from RT-DETR (Zhao et al. 2023) and re-trained on DocLayNet (Pfitzmann et al. 2022), our popular human-annotated dataset for document-layout analysis, among other proprietary datasets. For inference, our implementation relies on the Hugging Face transformers (Wolf et al. 2020) library and the Safetensors file format. All predicted bounding-box proposals for document elements are post-processed to remove overlapping proposals based on confidence and size, and then intersected with the text tokens in the PDF to group them into meaningful and complete units such as paragraphs, section titles, list items, captions, figures, or tables.', text='Layout Analysis Model Our layout analysis model is an object detector which predicts the bounding-boxes and classes of various elements on the image of a given page. Its architecture is derived from RT-DETR (Zhao et al. 2023) and re-trained on DocLayNet (Pfitzmann et al. 2022), our popular human-annotated dataset for document-layout analysis, among other proprietary datasets. For inference, our implementation relies on the Hugging Face transformers (Wolf et al. 2020) library and the Safetensors file format. All predicted bounding-box proposals for document elements are post-processed to remove overlapping proposals based on confidence and size, and then intersected with the text tokens in the PDF to group them into meaningful and complete units such as paragraphs, section titles, list items, captions, figures, or tables.', formatting=None, hyperlink=None), TextItem(self_ref='#/texts/99', parent=RefItem(cref='#/body'), children=[], content_layer=<ContentLayer.BODY: 'body'>, label=<DocItemLabel.TEXT: 'text'>, prov=[ProvenanceItem(page_no=4, bbox=BoundingBox(l=54.0, t=316.052, r=292.505, b=87.93399999999997, coord_origin=<CoordOrigin.BOTTOMLEFT: 'BOTTOMLEFT'>), charspan=(0, 1165))], orig='Table Structure Recognition The TableFormer model (Nassar et al. 2022), first published in 2022 and since refined with a custom structure token language (Lysak et al. 2023), is a vision-transformer model for table structure recovery. It can predict the logical row and column structure of a given table based on an input image, and determine which table cells belong to column headers, row headers or the table body. Compared to earlier approaches, TableFormer handles many characteristics of tables like partial or no borderlines, empty cells, rows or columns, cell spans and hierarchy on both column-heading and row-heading level, tables with inconsistent indentation or alignment and other complexities. For inference, our implementation relies on PyTorch (Ansel et al. 2024). The PDF pipeline feeds all table objects detected in the layout analysis to the TableFormer model, by providing an image-crop of the table and the included text cells. TableFormer structure predictions are matched back to the PDF cells during a post-processing step, to avoid expensive re-transcription of the table image-crop, which also makes the TableFormer model language agnostic.', text='Table Structure Recognition The TableFormer model (Nassar et al. 2022), first published in 2022 and since refined with a custom structure token language (Lysak et al. 2023), is a vision-transformer model for table structure recovery. It can predict the logical row and column structure of a given table based on an input image, and determine which table cells belong to column headers, row headers or the table body. Compared to earlier approaches, TableFormer handles many characteristics of tables like partial or no borderlines, empty cells, rows or columns, cell spans and hierarchy on both column-heading and row-heading level, tables with inconsistent indentation or alignment and other complexities. For inference, our implementation relies on PyTorch (Ansel et al. 2024). The PDF pipeline feeds all table objects detected in the layout analysis to the TableFormer model, by providing an image-crop of the table and the included text cells. TableFormer structure predictions are matched back to the PDF cells during a post-processing step, to avoid expensive re-transcription of the table image-crop, which also makes the TableFormer model language agnostic.', formatting=None, hyperlink=None), TextItem(self_ref='#/texts/100', parent=RefItem(cref='#/body'), children=[], content_layer=<ContentLayer.BODY: 'body'>, label=<DocItemLabel.TEXT: 'text'>, prov=[ProvenanceItem(page_no=4, bbox=BoundingBox(l=319.5, t=734.911, r=558.005, b=649.259, coord_origin=<CoordOrigin.BOTTOMLEFT: 'BOTTOMLEFT'>), charspan=(0, 455))], orig='OCR Docling utilizes OCR to convert scanned PDFs and extract content from bitmaps images embedded in a page. Currently, we provide integration with EasyOCR (eas 2024), a popular third-party OCR library with support for many languages, and Tesseract as a widely available alternative. While EasyOCR delivers reasonable transcription quality, we observe that it runs fairly slow on CPU (see section 5), making it the biggest compute expense in the pipeline.', text='OCR Docling utilizes OCR to convert scanned PDFs and extract content from bitmaps images embedded in a page. Currently, we provide integration with EasyOCR (eas 2024), a popular third-party OCR library with support for many languages, and Tesseract as a widely available alternative. While EasyOCR delivers reasonable transcription quality, we observe that it runs fairly slow on CPU (see section 5), making it the biggest compute expense in the pipeline.', formatting=None, hyperlink=None), TextItem(self_ref='#/texts/101', parent=RefItem(cref='#/body'), children=[], content_layer=<ContentLayer.BODY: 'body'>, label=<DocItemLabel.TEXT: 'text'>, prov=[ProvenanceItem(page_no=4, bbox=BoundingBox(l=319.5, t=640.126, r=558.005, b=565.433, coord_origin=<CoordOrigin.BOTTOMLEFT: 'BOTTOMLEFT'>), charspan=(0, 399))], orig='Assembly In the final pipeline stage, Docling assembles all prediction results produced on each page into the DoclingDocument representation, as defined in the auxiliary Python package docling-core . The generated document object is passed through a post-processing model which leverages several algorithms to augment features, such as correcting the reading order or matching figures with captions.', text='Assembly In the final pipeline stage, Docling assembles all prediction results produced on each page into the DoclingDocument representation, as defined in the auxiliary Python package docling-core . The generated document object is passed through a post-processing model which leverages several algorithms to augment features, such as correcting the reading order or matching figures with captions.', formatting=None, hyperlink=None), SectionHeaderItem(self_ref='#/texts/102', parent=RefItem(cref='#/body'), children=[], content_layer=<ContentLayer.BODY: 'body'>, label=<DocItemLabel.SECTION_HEADER: 'section_header'>, prov=[ProvenanceItem(page_no=4, bbox=BoundingBox(l=396.859, t=551.603, r=480.641, b=540.855, coord_origin=<CoordOrigin.BOTTOMLEFT: 'BOTTOMLEFT'>), charspan=(0, 13))], orig='5 Performance', text='5 Performance', formatting=None, hyperlink=None, level=1), TextItem(self_ref='#/texts/103', parent=RefItem(cref='#/body'), children=[], content_layer=<ContentLayer.BODY: 'body'>, label=<DocItemLabel.TEXT: 'text'>, prov=[ProvenanceItem(page_no=4, bbox=BoundingBox(l=319.5, t=534.756, r=558.005, b=504.286, coord_origin=<CoordOrigin.BOTTOMLEFT: 'BOTTOMLEFT'>), charspan=(0, 167))], orig='In this section, we characterize the conversion speed of PDF documents with Docling in a given resource budget for different scenarios and establish reference numbers.', text='In this section, we characterize the conversion speed of PDF documents with Docling in a given resource budget for different scenarios and establish reference numbers.', formatting=None, hyperlink=None), TextItem(self_ref='#/texts/104', parent=RefItem(cref='#/body'), children=[], content_layer=<ContentLayer.BODY: 'body'>, label=<DocItemLabel.TEXT: 'text'>, prov=[ProvenanceItem(page_no=4, bbox=BoundingBox(l=319.5, t=501.501, r=558.005, b=383.36, coord_origin=<CoordOrigin.BOTTOMLEFT: 'BOTTOMLEFT'>), charspan=(0, 618))], orig='Further, we compare the conversion speed to three popular contenders in the open-source space, namely unstructured.io (Unstructured.io Team 2024), Marker (Paruchuri 2024), and MinerU (Wang et al. 2024). All aforementioned solutions can universally convert PDF documents to Markdown or similar representations and offer a library-style interface to run the document processing entirely locally. We exclude SaaS offerings and remote services for document conversion from this comparison, since the latter do not provide any possibility to control the system resources they run on, rendering any speed comparison invalid.', text='Further, we compare the conversion speed to three popular contenders in the open-source space, namely unstructured.io (Unstructured.io Team 2024), Marker (Paruchuri 2024), and MinerU (Wang et al. 2024). All aforementioned solutions can universally convert PDF documents to Markdown or similar representations and offer a library-style interface to run the document processing entirely locally. We exclude SaaS offerings and remote services for document conversion from this comparison, since the latter do not provide any possibility to control the system resources they run on, rendering any speed comparison invalid.', formatting=None, hyperlink=None), SectionHeaderItem(self_ref='#/texts/105', parent=RefItem(cref='#/body'), children=[], content_layer=<ContentLayer.BODY: 'body'>, label=<DocItemLabel.SECTION_HEADER: 'section_header'>, prov=[ProvenanceItem(page_no=4, bbox=BoundingBox(l=319.5, t=370.8, r=436.456, b=360.993, coord_origin=<CoordOrigin.BOTTOMLEFT: 'BOTTOMLEFT'>), charspan=(0, 21))], orig='5.1 Benchmark Dataset', text='5.1 Benchmark Dataset', formatting=None, hyperlink=None, level=1), TextItem(self_ref='#/texts/106', parent=RefItem(cref='#/body'), children=[], content_layer=<ContentLayer.BODY: 'body'>, label=<DocItemLabel.TEXT: 'text'>, prov=[ProvenanceItem(page_no=4, bbox=BoundingBox(l=319.5, t=354.675, r=558.005, b=258.452, coord_origin=<CoordOrigin.BOTTOMLEFT: 'BOTTOMLEFT'>), charspan=(0, 522))], orig='To enable a meaningful benchmark, we composed a test set of 89 PDF files covering a large variety of styles, features, content, and length (see Figure 2). This dataset is based to a large extend on our DocLayNet (Pfitzmann et al. 2022) dataset and augmented with additional samples from CCpdf (Turski et al. 2023) to increase the variety. Overall, it includes 4008 pages, 56246 text items, 1842 tables and 4676 pictures. As such, it is large enough to provide variety without requiring excessively long benchmarking times.', text='To enable a meaningful benchmark, we composed a test set of 89 PDF files covering a large variety of styles, features, content, and length (see Figure 2). This dataset is based to a large extend on our DocLayNet (Pfitzmann et al. 2022) dataset and augmented with additional samples from CCpdf (Turski et al. 2023) to increase the variety. Overall, it includes 4008 pages, 56246 text items, 1842 tables and 4676 pictures. As such, it is large enough to provide variety without requiring excessively long benchmarking times.', formatting=None, hyperlink=None), SectionHeaderItem(self_ref='#/texts/107', parent=RefItem(cref='#/body'), children=[], content_layer=<ContentLayer.BODY: 'body'>, label=<DocItemLabel.SECTION_HEADER: 'section_header'>, prov=[ProvenanceItem(page_no=4, bbox=BoundingBox(l=319.5, t=245.89200000000005, r=449.809, b=236.08500000000004, coord_origin=<CoordOrigin.BOTTOMLEFT: 'BOTTOMLEFT'>), charspan=(0, 25))], orig='5.2 System Configurations', text='5.2 System Configurations', formatting=None, hyperlink=None, level=1), TextItem(self_ref='#/texts/108', parent=RefItem(cref='#/body'), children=[], content_layer=<ContentLayer.BODY: 'body'>, label=<DocItemLabel.TEXT: 'text'>, prov=[ProvenanceItem(page_no=4, bbox=BoundingBox(l=319.5, t=229.76700000000005, r=558.005, b=210.25700000000006, coord_origin=<CoordOrigin.BOTTOMLEFT: 'BOTTOMLEFT'>), charspan=(0, 96))], orig='We schedule our benchmark experiments each on two different systems to create reference numbers:', text='We schedule our benchmark experiments each on two different systems to create reference numbers:', formatting=None, hyperlink=None), ListItem(self_ref='#/texts/109', parent=RefItem(cref='#/groups/3'), children=[], content_layer=<ContentLayer.BODY: 'body'>, label=<DocItemLabel.LIST_ITEM: 'list_item'>, prov=[ProvenanceItem(page_no=4, bbox=BoundingBox(l=323.983, t=203.10699999999997, r=558.004, b=161.678, coord_origin=<CoordOrigin.BOTTOMLEFT: 'BOTTOMLEFT'>), charspan=(0, 148))], orig='· AWS EC2 VM (g6.xlarge), 8 virtual cores (AMD EPYC 7R13, x86), 32 GB RAM, Nvidia L4 GPU (24 GB VRAM), on Ubuntu 22.04 with Nvidia CUDA 12.4 drivers', text='AWS EC2 VM (g6.xlarge), 8 virtual cores (AMD EPYC 7R13, x86), 32 GB RAM, Nvidia L4 GPU (24 GB VRAM), on Ubuntu 22.04 with Nvidia CUDA 12.4 drivers', formatting=None, hyperlink=None, enumerated=False, marker='·'), ListItem(self_ref='#/texts/110', parent=RefItem(cref='#/groups/3'), children=[], content_layer=<ContentLayer.BODY: 'body'>, label=<DocItemLabel.LIST_ITEM: 'list_item'>, prov=[ProvenanceItem(page_no=4, bbox=BoundingBox(l=323.983, t=156.02300000000002, r=558.004, b=136.51199999999994, coord_origin=<CoordOrigin.BOTTOMLEFT: 'BOTTOMLEFT'>), charspan=(0, 51))], orig='· MacBook Pro M3 Max (ARM), 64GB RAM, on macOS 14.7', text='MacBook Pro M3 Max (ARM), 64GB RAM, on macOS 14.7', formatting=None, hyperlink=None, enumerated=False, marker='·'), TextItem(self_ref='#/texts/111', parent=RefItem(cref='#/body'), children=[], content_layer=<ContentLayer.BODY: 'body'>, label=<DocItemLabel.TEXT: 'text'>, prov=[ProvenanceItem(page_no=4, bbox=BoundingBox(l=319.5, t=129.36300000000006, r=558.005, b=87.93399999999997, coord_origin=<CoordOrigin.BOTTOMLEFT: 'BOTTOMLEFT'>), charspan=(0, 217))], orig='All experiments on the AWS EC2 VM are carried out once with GPU acceleration enabled and once purely on the x86 CPU, resulting in three total system configurations which we refer to as M3 Max SoC, L4 GPU, and x86 CPU.', text='All experiments on the AWS EC2 VM are carried out once with GPU acceleration enabled and once purely on the x86 CPU, resulting in three total system configurations which we refer to as M3 Max SoC, L4 GPU, and x86 CPU.', formatting=None, hyperlink=None), TextItem(self_ref='#/texts/112', parent=RefItem(cref='#/tables/0'), children=[], content_layer=<ContentLayer.BODY: 'body'>, label=<DocItemLabel.CAPTION: 'caption'>, prov=[ProvenanceItem(page_no=5, bbox=BoundingBox(l=96.244, t=737.784, r=515.757, b=727.563, coord_origin=<CoordOrigin.BOTTOMLEFT: 'BOTTOMLEFT'>), charspan=(0, 108))], orig='Table 1: Versions and configuration options considered for each tested asset. * denotes the default setting.', text='Table 1: Versions and configuration options considered for each tested asset. * denotes the default setting.', formatting=None, hyperlink=None), TextItem(self_ref='#/texts/113', parent=RefItem(cref='#/pictures/1'), children=[], content_layer=<ContentLayer.BODY: 'body'>, label=<DocItemLabel.CAPTION: 'caption'>, prov=[ProvenanceItem(page_no=5, bbox=BoundingBox(l=54.0, t=311.938, r=292.505, b=292.428, coord_origin=<CoordOrigin.BOTTOMLEFT: 'BOTTOMLEFT'>), charspan=(0, 71))], orig='Figure 2: Dataset categories and sample counts for documents and pages.', text='Figure 2: Dataset categories and sample counts for documents and pages.', formatting=None, hyperlink=None), TextItem(self_ref='#/texts/114', parent=RefItem(cref='#/pictures/1'), children=[], content_layer=<ContentLayer.BODY: 'body'>, label=<DocItemLabel.TEXT: 'text'>, prov=[ProvenanceItem(page_no=5, bbox=BoundingBox(l=72.644, t=551.301, r=119.507, b=544.148, coord_origin=<CoordOrigin.BOTTOMLEFT: 'BOTTOMLEFT'>), charspan=(0, 14))], orig='Annual Reports', text='Annual Reports', formatting=None, hyperlink=None), TextItem(self_ref='#/texts/115', parent=RefItem(cref='#/pictures/1'), children=[], content_layer=<ContentLayer.BODY: 'body'>, label=<DocItemLabel.TEXT: 'text'>, prov=[ProvenanceItem(page_no=5, bbox=BoundingBox(l=138.163, t=551.478, r=145.973, b=544.326, coord_origin=<CoordOrigin.BOTTOMLEFT: 'BOTTOMLEFT'>), charspan=(0, 2))], orig='20', text='20', formatting=None, hyperlink=None), TextItem(self_ref='#/texts/116', parent=RefItem(cref='#/pictures/1'), children=[], content_layer=<ContentLayer.BODY: 'body'>, label=<DocItemLabel.TEXT: 'text'>, prov=[ProvenanceItem(page_no=5, bbox=BoundingBox(l=193.822, t=508.587, r=233.16, b=501.434, coord_origin=<CoordOrigin.BOTTOMLEFT: 'BOTTOMLEFT'>), charspan=(0, 12))], orig='CCPdf (misc)', text='CCPdf (misc)', formatting=None, hyperlink=None), TextItem(self_ref='#/texts/117', parent=RefItem(cref='#/pictures/1'), children=[], content_layer=<ContentLayer.BODY: 'body'>, label=<DocItemLabel.TEXT: 'text'>, prov=[ProvenanceItem(page_no=5, bbox=BoundingBox(l=178.701, t=528.18, r=186.51, b=521.027, coord_origin=<CoordOrigin.BOTTOMLEFT: 'BOTTOMLEFT'>), charspan=(0, 2))], orig='39', text='39', formatting=None, hyperlink=None), TextItem(self_ref='#/texts/118', parent=RefItem(cref='#/pictures/1'), children=[], content_layer=<ContentLayer.BODY: 'body'>, label=<DocItemLabel.TEXT: 'text'>, prov=[ProvenanceItem(page_no=5, bbox=BoundingBox(l=213.51, t=574.036, r=277.177, b=566.883, coord_origin=<CoordOrigin.BOTTOMLEFT: 'BOTTOMLEFT'>), charspan=(0, 19))], orig='Law and Regulations', text='Law and Regulations', formatting=None, hyperlink=None), TextItem(self_ref='#/texts/119', parent=RefItem(cref='#/pictures/1'), children=[], content_layer=<ContentLayer.BODY: 'body'>, label=<DocItemLabel.TEXT: 'text'>, prov=[ProvenanceItem(page_no=5, bbox=BoundingBox(l=191.395, t=563.879, r=195.3, b=556.726, coord_origin=<CoordOrigin.BOTTOMLEFT: 'BOTTOMLEFT'>), charspan=(0, 1))], orig='4', text='4', formatting=None, hyperlink=None), TextItem(self_ref='#/texts/120', parent=RefItem(cref='#/pictures/1'), children=[], content_layer=<ContentLayer.BODY: 'body'>, label=<DocItemLabel.TEXT: 'text'>, prov=[ProvenanceItem(page_no=5, bbox=BoundingBox(l=200.406, t=590.29, r=225.923, b=583.137, coord_origin=<CoordOrigin.BOTTOMLEFT: 'BOTTOMLEFT'>), charspan=(0, 7))], orig='Manuals', text='Manuals', formatting=None, hyperlink=None), TextItem(self_ref='#/texts/121', parent=RefItem(cref='#/pictures/1'), children=[], content_layer=<ContentLayer.BODY: 'body'>, label=<DocItemLabel.TEXT: 'text'>, prov=[ProvenanceItem(page_no=5, bbox=BoundingBox(l=184.248, t=572.745, r=188.152, b=565.592, coord_origin=<CoordOrigin.BOTTOMLEFT: 'BOTTOMLEFT'>), charspan=(0, 1))], orig='8', text='8', formatting=None, hyperlink=None), TextItem(self_ref='#/texts/122', parent=RefItem(cref='#/pictures/1'), children=[], content_layer=<ContentLayer.BODY: 'body'>, label=<DocItemLabel.TEXT: 'text'>, prov=[ProvenanceItem(page_no=5, bbox=BoundingBox(l=180.076, t=600.136, r=202.956, b=592.983, coord_origin=<CoordOrigin.BOTTOMLEFT: 'BOTTOMLEFT'>), charspan=(0, 7))], orig='Patents', text='Patents', formatting=None, hyperlink=None), TextItem(self_ref='#/texts/123', parent=RefItem(cref='#/pictures/1'), children=[], content_layer=<ContentLayer.BODY: 'body'>, label=<DocItemLabel.TEXT: 'text'>, prov=[ProvenanceItem(page_no=5, bbox=BoundingBox(l=173.159, t=578.116, r=177.064, b=570.963, coord_origin=<CoordOrigin.BOTTOMLEFT: 'BOTTOMLEFT'>), charspan=(0, 1))], orig='5', text='5', formatting=None, hyperlink=None), TextItem(self_ref='#/texts/124', parent=RefItem(cref='#/pictures/1'), children=[], content_layer=<ContentLayer.BODY: 'body'>, label=<DocItemLabel.TEXT: 'text'>, prov=[ProvenanceItem(page_no=5, bbox=BoundingBox(l=131.989, t=599.517, r=155.793, b=592.364, coord_origin=<CoordOrigin.BOTTOMLEFT: 'BOTTOMLEFT'>), charspan=(0, 7))], orig='Science', text='Science', formatting=None, hyperlink=None), TextItem(self_ref='#/texts/125', parent=RefItem(cref='#/pictures/1'), children=[], content_layer=<ContentLayer.BODY: 'body'>, label=<DocItemLabel.TEXT: 'text'>, prov=[ProvenanceItem(page_no=5, bbox=BoundingBox(l=159.913, t=577.778, r=163.818, b=570.625, coord_origin=<CoordOrigin.BOTTOMLEFT: 'BOTTOMLEFT'>), charspan=(0, 1))], orig='9', text='9', formatting=None, hyperlink=None), TextItem(self_ref='#/texts/126', parent=RefItem(cref='#/pictures/1'), children=[], content_layer=<ContentLayer.BODY: 'body'>, label=<DocItemLabel.TEXT: 'text'>, prov=[ProvenanceItem(page_no=5, bbox=BoundingBox(l=98.842, t=588.647, r=135.994, b=581.495, coord_origin=<CoordOrigin.BOTTOMLEFT: 'BOTTOMLEFT'>), charspan=(0, 11))], orig='Spec sheets', text='Spec sheets', formatting=None, hyperlink=None), TextItem(self_ref='#/texts/127', parent=RefItem(cref='#/pictures/1'), children=[], content_layer=<ContentLayer.BODY: 'body'>, label=<DocItemLabel.TEXT: 'text'>, prov=[ProvenanceItem(page_no=5, bbox=BoundingBox(l=149.112, t=571.849, r=153.017, b=564.696, coord_origin=<CoordOrigin.BOTTOMLEFT: 'BOTTOMLEFT'>), charspan=(0, 1))], orig='4', text='4', formatting=None, hyperlink=None), TextItem(self_ref='#/texts/128', parent=RefItem(cref='#/pictures/1'), children=[], content_layer=<ContentLayer.BODY: 'body'>, label=<DocItemLabel.TEXT: 'text'>, prov=[ProvenanceItem(page_no=5, bbox=BoundingBox(l=117.708, t=615.812, r=220.587, b=606.275, coord_origin=<CoordOrigin.BOTTOMLEFT: 'BOTTOMLEFT'>), charspan=(0, 22))], orig='Documents per Category', text='Documents per Category', formatting=None, hyperlink=None), TextItem(self_ref='#/texts/129', parent=RefItem(cref='#/pictures/1'), children=[], content_layer=<ContentLayer.BODY: 'body'>, label=<DocItemLabel.TEXT: 'text'>, prov=[ProvenanceItem(page_no=5, bbox=BoundingBox(l=79.205, t=405.166, r=126.068, b=398.013, coord_origin=<CoordOrigin.BOTTOMLEFT: 'BOTTOMLEFT'>), charspan=(0, 14))], orig='Annual Reports', text='Annual Reports', formatting=None, hyperlink=None), TextItem(self_ref='#/texts/130', parent=RefItem(cref='#/pictures/1'), children=[], content_layer=<ContentLayer.BODY: 'body'>, label=<DocItemLabel.TEXT: 'text'>, prov=[ProvenanceItem(page_no=5, bbox=BoundingBox(l=137.83, t=416.381, r=153.449, b=409.228, coord_origin=<CoordOrigin.BOTTOMLEFT: 'BOTTOMLEFT'>), charspan=(0, 4))], orig='1554', text='1554', formatting=None, hyperlink=None), TextItem(self_ref='#/texts/131', parent=RefItem(cref='#/pictures/1'), children=[], content_layer=<ContentLayer.BODY: 'body'>, label=<DocItemLabel.TEXT: 'text'>, prov=[ProvenanceItem(page_no=5, bbox=BoundingBox(l=211.518, t=403.915, r=250.856, b=396.763, coord_origin=<CoordOrigin.BOTTOMLEFT: 'BOTTOMLEFT'>), charspan=(0, 12))], orig='CCPdf (misc)', text='CCPdf (misc)', formatting=None, hyperlink=None), TextItem(self_ref='#/texts/132', parent=RefItem(cref='#/pictures/1'), children=[], content_layer=<ContentLayer.BODY: 'body'>, label=<DocItemLabel.TEXT: 'text'>, prov=[ProvenanceItem(page_no=5, bbox=BoundingBox(l=184.441, t=415.699, r=200.061, b=408.546, coord_origin=<CoordOrigin.BOTTOMLEFT: 'BOTTOMLEFT'>), charspan=(0, 4))], orig='1090', text='1090', formatting=None, hyperlink=None), TextItem(self_ref='#/texts/133', parent=RefItem(cref='#/pictures/1'), children=[], content_layer=<ContentLayer.BODY: 'body'>, label=<DocItemLabel.TEXT: 'text'>, prov=[ProvenanceItem(page_no=5, bbox=BoundingBox(l=215.664, t=447.261, r=279.332, b=440.108, coord_origin=<CoordOrigin.BOTTOMLEFT: 'BOTTOMLEFT'>), charspan=(0, 19))], orig='Law and Regulations', text='Law and Regulations', formatting=None, hyperlink=None), TextItem(self_ref='#/texts/134', parent=RefItem(cref='#/pictures/1'), children=[], content_layer=<ContentLayer.BODY: 'body'>, label=<DocItemLabel.TEXT: 'text'>, prov=[ProvenanceItem(page_no=5, bbox=BoundingBox(l=190.615, t=439.342, r=198.424, b=432.189, coord_origin=<CoordOrigin.BOTTOMLEFT: 'BOTTOMLEFT'>), charspan=(0, 2))], orig='68', text='68', formatting=None, hyperlink=None), TextItem(self_ref='#/texts/135', parent=RefItem(cref='#/pictures/1'), children=[], content_layer=<ContentLayer.BODY: 'body'>, label=<DocItemLabel.TEXT: 'text'>, prov=[ProvenanceItem(page_no=5, bbox=BoundingBox(l=187.757, t=475.885, r=213.274, b=468.732, coord_origin=<CoordOrigin.BOTTOMLEFT: 'BOTTOMLEFT'>), charspan=(0, 7))], orig='Manuals', text='Manuals', formatting=None, hyperlink=None), TextItem(self_ref='#/texts/136', parent=RefItem(cref='#/pictures/1'), children=[], content_layer=<ContentLayer.BODY: 'body'>, label=<DocItemLabel.TEXT: 'text'>, prov=[ProvenanceItem(page_no=5, bbox=BoundingBox(l=173.436, t=454.955, r=185.151, b=447.802, coord_origin=<CoordOrigin.BOTTOMLEFT: 'BOTTOMLEFT'>), charspan=(0, 3))], orig='989', text='989', formatting=None, hyperlink=None), TextItem(self_ref='#/texts/137', parent=RefItem(cref='#/pictures/1'), children=[], content_layer=<ContentLayer.BODY: 'body'>, label=<DocItemLabel.TEXT: 'text'>, prov=[ProvenanceItem(page_no=5, bbox=BoundingBox(l=122.044, t=473.185, r=144.924, b=466.032, coord_origin=<CoordOrigin.BOTTOMLEFT: 'BOTTOMLEFT'>), charspan=(0, 7))], orig='Patents', text='Patents', formatting=None, hyperlink=None), TextItem(self_ref='#/texts/138', parent=RefItem(cref='#/pictures/1'), children=[], content_layer=<ContentLayer.BODY: 'body'>, label=<DocItemLabel.TEXT: 'text'>, prov=[ProvenanceItem(page_no=5, bbox=BoundingBox(l=150.076, t=453.482, r=161.79, b=446.329, coord_origin=<CoordOrigin.BOTTOMLEFT: 'BOTTOMLEFT'>), charspan=(0, 3))], orig='151', text='151', formatting=None, hyperlink=None), TextItem(self_ref='#/texts/139', parent=RefItem(cref='#/pictures/1'), children=[], content_layer=<ContentLayer.BODY: 'body'>, label=<DocItemLabel.TEXT: 'text'>, prov=[ProvenanceItem(page_no=5, bbox=BoundingBox(l=112.184, t=466.791, r=135.988, b=459.638, coord_origin=<CoordOrigin.BOTTOMLEFT: 'BOTTOMLEFT'>), charspan=(0, 7))], orig='Science', text='Science', formatting=None, hyperlink=None), TextItem(self_ref='#/texts/140', parent=RefItem(cref='#/pictures/1'), children=[], content_layer=<ContentLayer.BODY: 'body'>, label=<DocItemLabel.TEXT: 'text'>, prov=[ProvenanceItem(page_no=5, bbox=BoundingBox(l=145.198, t=449.994, r=156.913, b=442.842, coord_origin=<CoordOrigin.BOTTOMLEFT: 'BOTTOMLEFT'>), charspan=(0, 3))], orig='132', text='132', formatting=None, hyperlink=None), TextItem(self_ref='#/texts/141', parent=RefItem(cref='#/pictures/1'), children=[], content_layer=<ContentLayer.BODY: 'body'>, label=<DocItemLabel.TEXT: 'text'>, prov=[ProvenanceItem(page_no=5, bbox=BoundingBox(l=94.579, t=462.469, r=131.731, b=455.316, coord_origin=<CoordOrigin.BOTTOMLEFT: 'BOTTOMLEFT'>), charspan=(0, 11))], orig='Spec sheets', text='Spec sheets', formatting=None, hyperlink=None), TextItem(self_ref='#/texts/142', parent=RefItem(cref='#/pictures/1'), children=[], content_layer=<ContentLayer.BODY: 'body'>, label=<DocItemLabel.TEXT: 'text'>, prov=[ProvenanceItem(page_no=5, bbox=BoundingBox(l=144.83, t=447.637, r=152.64, b=440.484, coord_origin=<CoordOrigin.BOTTOMLEFT: 'BOTTOMLEFT'>), charspan=(0, 2))], orig='24', text='24', formatting=None, hyperlink=None), TextItem(self_ref='#/texts/143', parent=RefItem(cref='#/pictures/1'), children=[], content_layer=<ContentLayer.BODY: 'body'>, label=<DocItemLabel.TEXT: 'text'>, prov=[ProvenanceItem(page_no=5, bbox=BoundingBox(l=128.986, t=493.959, r=209.276, b=484.422, coord_origin=<CoordOrigin.BOTTOMLEFT: 'BOTTOMLEFT'>), charspan=(0, 18))], orig='Pages per Category', text='Pages per Category', formatting=None, hyperlink=None), TextItem(self_ref='#/texts/144', parent=RefItem(cref='#/pictures/1'), children=[], content_layer=<ContentLayer.BODY: 'body'>, label=<DocItemLabel.TEXT: 'text'>, prov=[ProvenanceItem(page_no=5, bbox=BoundingBox(l=154.857, t=377.018, r=191.628, b=369.07, coord_origin=<CoordOrigin.BOTTOMLEFT: 'BOTTOMLEFT'>), charspan=(0, 10))], orig='Categories', text='Categories', formatting=None, hyperlink=None), TextItem(self_ref='#/texts/145', parent=RefItem(cref='#/pictures/1'), children=[], content_layer=<ContentLayer.BODY: 'body'>, label=<DocItemLabel.TEXT: 'text'>, prov=[ProvenanceItem(page_no=5, bbox=BoundingBox(l=110.413, t=367.009, r=162.48, b=359.061, coord_origin=<CoordOrigin.BOTTOMLEFT: 'BOTTOMLEFT'>), charspan=(0, 14))], orig='Annual Reports', text='Annual Reports', formatting=None, hyperlink=None), TextItem(self_ref='#/texts/146', parent=RefItem(cref='#/pictures/1'), children=[], content_layer=<ContentLayer.BODY: 'body'>, label=<DocItemLabel.TEXT: 'text'>, prov=[ProvenanceItem(page_no=5, bbox=BoundingBox(l=110.413, t=356.999, r=154.121, b=349.052, coord_origin=<CoordOrigin.BOTTOMLEFT: 'BOTTOMLEFT'>), charspan=(0, 12))], orig='CCPdf (misc)', text='CCPdf (misc)', formatting=None, hyperlink=None), TextItem(self_ref='#/texts/147', parent=RefItem(cref='#/pictures/1'), children=[], content_layer=<ContentLayer.BODY: 'body'>, label=<DocItemLabel.TEXT: 'text'>, prov=[ProvenanceItem(page_no=5, bbox=BoundingBox(l=110.413, t=346.99, r=181.152, b=339.043, coord_origin=<CoordOrigin.BOTTOMLEFT: 'BOTTOMLEFT'>), charspan=(0, 19))], orig='Law and Regulations', text='Law and Regulations', formatting=None, hyperlink=None), TextItem(self_ref='#/texts/148', parent=RefItem(cref='#/pictures/1'), children=[], content_layer=<ContentLayer.BODY: 'body'>, label=<DocItemLabel.TEXT: 'text'>, prov=[ProvenanceItem(page_no=5, bbox=BoundingBox(l=110.413, t=336.981, r=138.765, b=329.034, coord_origin=<CoordOrigin.BOTTOMLEFT: 'BOTTOMLEFT'>), charspan=(0, 7))], orig='Manuals', text='Manuals', formatting=None, hyperlink=None), TextItem(self_ref='#/texts/149', parent=RefItem(cref='#/pictures/1'), children=[], content_layer=<ContentLayer.BODY: 'body'>, label=<DocItemLabel.TEXT: 'text'>, prov=[ProvenanceItem(page_no=5, bbox=BoundingBox(l=213.883, t=367.009, r=239.304, b=359.061, coord_origin=<CoordOrigin.BOTTOMLEFT: 'BOTTOMLEFT'>), charspan=(0, 7))], orig='Patents', text='Patents', formatting=None, hyperlink=None), TextItem(self_ref='#/texts/150', parent=RefItem(cref='#/pictures/1'), children=[], content_layer=<ContentLayer.BODY: 'body'>, label=<DocItemLabel.TEXT: 'text'>, prov=[ProvenanceItem(page_no=5, bbox=BoundingBox(l=213.883, t=356.999, r=240.332, b=349.052, coord_origin=<CoordOrigin.BOTTOMLEFT: 'BOTTOMLEFT'>), charspan=(0, 7))], orig='Science', text='Science', formatting=None, hyperlink=None), TextItem(self_ref='#/texts/151', parent=RefItem(cref='#/pictures/1'), children=[], content_layer=<ContentLayer.BODY: 'body'>, label=<DocItemLabel.TEXT: 'text'>, prov=[ProvenanceItem(page_no=5, bbox=BoundingBox(l=213.883, t=346.99, r=255.163, b=339.043, coord_origin=<CoordOrigin.BOTTOMLEFT: 'BOTTOMLEFT'>), charspan=(0, 11))], orig='Spec sheets', text='Spec sheets', formatting=None, hyperlink=None), SectionHeaderItem(self_ref='#/texts/152', parent=RefItem(cref='#/body'), children=[], content_layer=<ContentLayer.BODY: 'body'>, label=<DocItemLabel.SECTION_HEADER: 'section_header'>, prov=[ProvenanceItem(page_no=5, bbox=BoundingBox(l=54.0, t=266.972, r=211.582, b=257.16499999999996, coord_origin=<CoordOrigin.BOTTOMLEFT: 'BOTTOMLEFT'>), charspan=(0, 28))], orig='5.3 Benchmarking Methodology', text='5.3 Benchmarking Methodology', formatting=None, hyperlink=None, level=1), TextItem(self_ref='#/texts/153', parent=RefItem(cref='#/body'), children=[], content_layer=<ContentLayer.BODY: 'body'>, label=<DocItemLabel.TEXT: 'text'>, prov=[ProvenanceItem(page_no=5, bbox=BoundingBox(l=54.0, t=249.17399999999998, r=292.505, b=218.70399999999995, coord_origin=<CoordOrigin.BOTTOMLEFT: 'BOTTOMLEFT'>), charspan=(0, 174))], orig='We implemented several measures to enable a fair and reproducible benchmark across all tested assets. Specifically, the experimental setup accounts for the following factors:', text='We implemented several measures to enable a fair and reproducible benchmark across all tested assets. Specifically, the experimental setup accounts for the following factors:', formatting=None, hyperlink=None), ListItem(self_ref='#/texts/154', parent=RefItem(cref='#/groups/4'), children=[], content_layer=<ContentLayer.BODY: 'body'>, label=<DocItemLabel.LIST_ITEM: 'list_item'>, prov=[ProvenanceItem(page_no=5, bbox=BoundingBox(l=58.483, t=210.43899999999996, r=292.504, b=147.09199999999998, coord_origin=<CoordOrigin.BOTTOMLEFT: 'BOTTOMLEFT'>), charspan=(0, 304))], orig='· All assets are installed in the latest available versions, in a clean Python environment, and configured to use the state-of-the-art processing options and models, where applicable. We selectively disabled non-essential functionalities to achieve a compatible feature-set across all compared libraries.', text='All assets are installed in the latest available versions, in a clean Python environment, and configured to use the state-of-the-art processing options and models, where applicable. We selectively disabled non-essential functionalities to achieve a compatible feature-set across all compared libraries.', formatting=None, hyperlink=None, enumerated=False, marker='·'), ListItem(self_ref='#/texts/155', parent=RefItem(cref='#/groups/4'), children=[], content_layer=<ContentLayer.BODY: 'body'>, label=<DocItemLabel.LIST_ITEM: 'list_item'>, prov=[ProvenanceItem(page_no=5, bbox=BoundingBox(l=58.483, t=140.322, r=292.504, b=87.93399999999997, coord_origin=<CoordOrigin.BOTTOMLEFT: 'BOTTOMLEFT'>), charspan=(0, 227))], orig='· When running experiments on CPU, we inform all assets of the desired CPU thread budget of 8 threads, via the OMP NUM THREADS environment variable and any accepted configuration options. The L4 GPU on our AWS EC2 VM is hidden.', text='When running experiments on CPU, we inform all assets of the desired CPU thread budget of 8 threads, via the OMP NUM THREADS environment variable and any accepted configuration options. The L4 GPU on our AWS EC2 VM is hidden.', formatting=None, hyperlink=None, enumerated=False, marker='·'), ListItem(self_ref='#/texts/156', parent=RefItem(cref='#/groups/4'), children=[], content_layer=<ContentLayer.BODY: 'body'>, label=<DocItemLabel.LIST_ITEM: 'list_item'>, prov=[ProvenanceItem(page_no=5, bbox=BoundingBox(l=323.983, t=614.322, r=558.004, b=572.893, coord_origin=<CoordOrigin.BOTTOMLEFT: 'BOTTOMLEFT'>), charspan=(0, 209))], orig='· When running experiments on the L4 GPU, we enable CUDAacceleration in all accepted configuration options, ensure the GPU is visible and all required runtimes for AI inference are installed with CUDA support.', text='When running experiments on the L4 GPU, we enable CUDAacceleration in all accepted configuration options, ensure the GPU is visible and all required runtimes for AI inference are installed with CUDA support.', formatting=None, hyperlink=None, enumerated=False, marker='·'), TextItem(self_ref='#/texts/157', parent=RefItem(cref='#/body'), children=[], content_layer=<ContentLayer.BODY: 'body'>, label=<DocItemLabel.TEXT: 'text'>, prov=[ProvenanceItem(page_no=5, bbox=BoundingBox(l=319.5, t=565.817, r=557.995, b=546.306, coord_origin=<CoordOrigin.BOTTOMLEFT: 'BOTTOMLEFT'>), charspan=(0, 100))], orig='Table 1 provides an overview of the versions and configuration options we considered for each asset.', text='Table 1 provides an overview of the versions and configuration options we considered for each asset.', formatting=None, hyperlink=None), SectionHeaderItem(self_ref='#/texts/158', parent=RefItem(cref='#/body'), children=[], content_layer=<ContentLayer.BODY: 'body'>, label=<DocItemLabel.SECTION_HEADER: 'section_header'>, prov=[ProvenanceItem(page_no=5, bbox=BoundingBox(l=319.5, t=533.867, r=377.984, b=524.06, coord_origin=<CoordOrigin.BOTTOMLEFT: 'BOTTOMLEFT'>), charspan=(0, 11))], orig='5.4 Results', text='5.4 Results', formatting=None, hyperlink=None, level=1), TextItem(self_ref='#/texts/159', parent=RefItem(cref='#/pictures/2'), children=[], content_layer=<ContentLayer.BODY: 'body'>, label=<DocItemLabel.CAPTION: 'caption'>, prov=[ProvenanceItem(page_no=5, bbox=BoundingBox(l=319.5, t=331.78, r=558.005, b=279.39200000000005, coord_origin=<CoordOrigin.BOTTOMLEFT: 'BOTTOMLEFT'>), charspan=(0, 289))], orig='Figure 3: Distribution of conversion times for all documents, ordered by number of pages in a document, on all system configurations. Every dot represents one document. Log/log scale is used to even the spacing, since both number of pages and conversion times have long-tail distributions.', text='Figure 3: Distribution of conversion times for all documents, ordered by number of pages in a document, on all system configurations. Every dot represents one document. Log/log scale is used to even the spacing, since both number of pages and conversion times have long-tail distributions.', formatting=None, hyperlink=None), TextItem(self_ref='#/texts/160', parent=RefItem(cref='#/pictures/2'), children=[], content_layer=<ContentLayer.BODY: 'body'>, label=<DocItemLabel.TEXT: 'text'>, prov=[ProvenanceItem(page_no=5, bbox=BoundingBox(l=380.626, t=360.352, r=390.638, b=352.995, coord_origin=<CoordOrigin.BOTTOMLEFT: 'BOTTOMLEFT'>), charspan=(0, 4))], orig='10 0', text='10 0', formatting=None, hyperlink=None), TextItem(self_ref='#/texts/161', parent=RefItem(cref='#/pictures/2'), children=[], content_layer=<ContentLayer.BODY: 'body'>, label=<DocItemLabel.TEXT: 'text'>, prov=[ProvenanceItem(page_no=5, bbox=BoundingBox(l=425.716, t=360.403, r=435.728, b=353.046, coord_origin=<CoordOrigin.BOTTOMLEFT: 'BOTTOMLEFT'>), charspan=(0, 4))], orig='10 1', text='10 1', formatting=None, hyperlink=None), TextItem(self_ref='#/texts/162', parent=RefItem(cref='#/pictures/2'), children=[], content_layer=<ContentLayer.BODY: 'body'>, label=<DocItemLabel.TEXT: 'text'>, prov=[ProvenanceItem(page_no=5, bbox=BoundingBox(l=470.806, t=360.352, r=480.818, b=352.995, coord_origin=<CoordOrigin.BOTTOMLEFT: 'BOTTOMLEFT'>), charspan=(0, 4))], orig='10 2', text='10 2', formatting=None, hyperlink=None), TextItem(self_ref='#/texts/163', parent=RefItem(cref='#/pictures/2'), children=[], content_layer=<ContentLayer.BODY: 'body'>, label=<DocItemLabel.TEXT: 'text'>, prov=[ProvenanceItem(page_no=5, bbox=BoundingBox(l=424.918, t=351.257, r=474.979, b=344.504, coord_origin=<CoordOrigin.BOTTOMLEFT: 'BOTTOMLEFT'>), charspan=(0, 15))], orig='Number of pages', text='Number of pages', formatting=None, hyperlink=None), TextItem(self_ref='#/texts/164', parent=RefItem(cref='#/pictures/2'), children=[], content_layer=<ContentLayer.BODY: 'body'>, label=<DocItemLabel.TEXT: 'text'>, prov=[ProvenanceItem(page_no=5, bbox=BoundingBox(l=364.939, t=396.043, r=374.952, b=388.686, coord_origin=<CoordOrigin.BOTTOMLEFT: 'BOTTOMLEFT'>), charspan=(0, 4))], orig='10 0', text='10 0', formatting=None, hyperlink=None), TextItem(self_ref='#/texts/165', parent=RefItem(cref='#/pictures/2'), children=[], content_layer=<ContentLayer.BODY: 'body'>, label=<DocItemLabel.TEXT: 'text'>, prov=[ProvenanceItem(page_no=5, bbox=BoundingBox(l=364.939, t=430.779, r=374.952, b=423.422, coord_origin=<CoordOrigin.BOTTOMLEFT: 'BOTTOMLEFT'>), charspan=(0, 4))], orig='10 1', text='10 1', formatting=None, hyperlink=None), TextItem(self_ref='#/texts/166', parent=RefItem(cref='#/pictures/2'), children=[], content_layer=<ContentLayer.BODY: 'body'>, label=<DocItemLabel.TEXT: 'text'>, prov=[ProvenanceItem(page_no=5, bbox=BoundingBox(l=364.939, t=465.994, r=374.952, b=458.637, coord_origin=<CoordOrigin.BOTTOMLEFT: 'BOTTOMLEFT'>), charspan=(0, 4))], orig='10 2', text='10 2', formatting=None, hyperlink=None), TextItem(self_ref='#/texts/167', parent=RefItem(cref='#/pictures/2'), children=[], content_layer=<ContentLayer.BODY: 'body'>, label=<DocItemLabel.TEXT: 'text'>, prov=[ProvenanceItem(page_no=5, bbox=BoundingBox(l=364.939, t=500.969, r=374.952, b=493.612, coord_origin=<CoordOrigin.BOTTOMLEFT: 'BOTTOMLEFT'>), charspan=(0, 4))], orig='10 3', text='10 3', formatting=None, hyperlink=None), TextItem(self_ref='#/texts/168', parent=RefItem(cref='#/pictures/2'), children=[], content_layer=<ContentLayer.BODY: 'body'>, label=<DocItemLabel.TEXT: 'text'>, prov=[ProvenanceItem(page_no=5, bbox=BoundingBox(l=356.031, t=440.464, r=362.784, b=430.691, coord_origin=<CoordOrigin.BOTTOMLEFT: 'BOTTOMLEFT'>), charspan=(0, 3))], orig='sec', text='sec', formatting=None, hyperlink=None), TextItem(self_ref='#/texts/169', parent=RefItem(cref='#/pictures/2'), children=[], content_layer=<ContentLayer.BODY: 'body'>, label=<DocItemLabel.TEXT: 'text'>, prov=[ProvenanceItem(page_no=5, bbox=BoundingBox(l=400.88, t=503.903, r=425.313, b=497.15, coord_origin=<CoordOrigin.BOTTOMLEFT: 'BOTTOMLEFT'>), charspan=(0, 7))], orig='x86 CPU', text='x86 CPU', formatting=None, hyperlink=None), TextItem(self_ref='#/texts/170', parent=RefItem(cref='#/pictures/2'), children=[], content_layer=<ContentLayer.BODY: 'body'>, label=<DocItemLabel.TEXT: 'text'>, prov=[ProvenanceItem(page_no=5, bbox=BoundingBox(l=400.88, t=495.398, r=423.4, b=488.645, coord_origin=<CoordOrigin.BOTTOMLEFT: 'BOTTOMLEFT'>), charspan=(0, 6))], orig='M3 Max', text='M3 Max', formatting=None, hyperlink=None), TextItem(self_ref='#/texts/171', parent=RefItem(cref='#/pictures/2'), children=[], content_layer=<ContentLayer.BODY: 'body'>, label=<DocItemLabel.TEXT: 'text'>, prov=[ProvenanceItem(page_no=5, bbox=BoundingBox(l=400.88, t=486.893, r=421.87, b=480.14, coord_origin=<CoordOrigin.BOTTOMLEFT: 'BOTTOMLEFT'>), charspan=(0, 6))], orig='L4 GPU', text='L4 GPU', formatting=None, hyperlink=None), TextItem(self_ref='#/texts/172', parent=RefItem(cref='#/body'), children=[], content_layer=<ContentLayer.BODY: 'body'>, label=<DocItemLabel.TEXT: 'text'>, prov=[ProvenanceItem(page_no=5, bbox=BoundingBox(l=319.5, t=261.59899999999993, r=558.005, b=175.947, coord_origin=<CoordOrigin.BOTTOMLEFT: 'BOTTOMLEFT'>), charspan=(0, 449))], orig=\"Runtime Characteristics To analyze Docling's runtime characteristics, we begin by exploring the relationship between document length (in pages) and conversion time. As shown in Figure 3, this relationship is not strictly linear, as documents differ in their frequency of tables and bitmap elements (i.e., scanned content). This requires OCR or table structure recognition models to engage dynamically when layout analysis has detected such elements.\", text=\"Runtime Characteristics To analyze Docling's runtime characteristics, we begin by exploring the relationship between document length (in pages) and conversion time. As shown in Figure 3, this relationship is not strictly linear, as documents differ in their frequency of tables and bitmap elements (i.e., scanned content). This requires OCR or table structure recognition models to engage dynamically when layout analysis has detected such elements.\", formatting=None, hyperlink=None), TextItem(self_ref='#/texts/173', parent=RefItem(cref='#/body'), children=[], content_layer=<ContentLayer.BODY: 'body'>, label=<DocItemLabel.TEXT: 'text'>, prov=[ProvenanceItem(page_no=5, bbox=BoundingBox(l=319.5, t=173.19799999999998, r=558.005, b=87.93399999999997, coord_origin=<CoordOrigin.BOTTOMLEFT: 'BOTTOMLEFT'>), charspan=(0, 463)), ProvenanceItem(page_no=6, bbox=BoundingBox(l=54.0, t=734.523, r=292.505, b=704.054, coord_origin=<CoordOrigin.BOTTOMLEFT: 'BOTTOMLEFT'>), charspan=(464, 622))], orig='By breaking down the runtimes to a page level, we receive a more intuitive measure for the conversion speed (see also Figure 4). Processing a page in our benchmark dataset requires between 0.6 sec (5 th percentile) and 16.3 sec (95 th percentile), with a median of 0.79 sec on the x86 CPU. On the M3 Max SoC, it achieves 0.26/0.32/6.48 seconds per page (.05/median/.95), and on the Nvidia L4 GPU it achieves 57/114/2081 milliseconds per page (.05/median/.95). The large range between 5 and 95 percentiles results from the highly different complexity of content across pages (i.e., almost empty pages vs. full-page tables).', text='By breaking down the runtimes to a page level, we receive a more intuitive measure for the conversion speed (see also Figure 4). Processing a page in our benchmark dataset requires between 0.6 sec (5 th percentile) and 16.3 sec (95 th percentile), with a median of 0.79 sec on the x86 CPU. On the M3 Max SoC, it achieves 0.26/0.32/6.48 seconds per page (.05/median/.95), and on the Nvidia L4 GPU it achieves 57/114/2081 milliseconds per page (.05/median/.95). The large range between 5 and 95 percentiles results from the highly different complexity of content across pages (i.e., almost empty pages vs. full-page tables).', formatting=None, hyperlink=None), TextItem(self_ref='#/texts/174', parent=RefItem(cref='#/body'), children=[], content_layer=<ContentLayer.BODY: 'body'>, label=<DocItemLabel.TEXT: 'text'>, prov=[ProvenanceItem(page_no=6, bbox=BoundingBox(l=54.0, t=699.525, r=292.505, b=636.178, coord_origin=<CoordOrigin.BOTTOMLEFT: 'BOTTOMLEFT'>), charspan=(0, 320))], orig='Disabling OCR saves 60% of runtime on the x86 CPU and the M3 Max SoC, and 50% on the L4 GPU. Turning off table structure recognition saves 16% of runtime on the x86 CPU and the M3 Max SoC, and 24% on the L4 GPU. Disabling both OCR and table structure recognition saves around 75% of runtime on all system configurations.', text='Disabling OCR saves 60% of runtime on the x86 CPU and the M3 Max SoC, and 50% on the L4 GPU. Turning off table structure recognition saves 16% of runtime on the x86 CPU and the M3 Max SoC, and 24% on the L4 GPU. Disabling both OCR and table structure recognition saves around 75% of runtime on all system configurations.', formatting=None, hyperlink=None), TextItem(self_ref='#/texts/175', parent=RefItem(cref='#/body'), children=[], content_layer=<ContentLayer.BODY: 'body'>, label=<DocItemLabel.TEXT: 'text'>, prov=[ProvenanceItem(page_no=6, bbox=BoundingBox(l=54.0, t=621.815, r=292.505, b=558.081, coord_origin=<CoordOrigin.BOTTOMLEFT: 'BOTTOMLEFT'>), charspan=(0, 297))], orig=\"Profiling Docling's AI Pipeline We analyzed the contributions of Docling's PDF backend and all AI models in the PDF pipeline to the total conversion time. The results are shown in Figure 4. On average, processing a page took 481 ms on the L4 GPU, 3.1 s on the x86 CPU and 1.26 s on the M3 Max SoC.\", text=\"Profiling Docling's AI Pipeline We analyzed the contributions of Docling's PDF backend and all AI models in the PDF pipeline to the total conversion time. The results are shown in Figure 4. On average, processing a page took 481 ms on the L4 GPU, 3.1 s on the x86 CPU and 1.26 s on the M3 Max SoC.\", formatting=None, hyperlink=None), TextItem(self_ref='#/texts/176', parent=RefItem(cref='#/body'), children=[], content_layer=<ContentLayer.BODY: 'body'>, label=<DocItemLabel.TEXT: 'text'>, prov=[ProvenanceItem(page_no=6, bbox=BoundingBox(l=54.0, t=553.552, r=292.505, b=413.493, coord_origin=<CoordOrigin.BOTTOMLEFT: 'BOTTOMLEFT'>), charspan=(0, 708))], orig='It is evident that applying OCR is the most expensive operation. In our benchmark dataset, OCR engages in 578 pages. On average, transcribing a page with EasyOCR took 1.6 s on the L4 GPU, 13 s on the x86 CPU and 5 s on the M3 Max SoC. The layout model spent 44 ms on the L4 GPU, 633 ms on the x86 CPU and 271 ms on the M3 Max SoC on average for each page, making it the cheapest of the AI models, while TableFormer (fast flavour) spent 400 ms on the L4 GPU, 1.74 s on the x86 CPU and 704 ms on the M3 Max SoC on average per table. Regarding the total time spent converting our benchmark dataset, TableFormer had less impact than other AI models, since tables appeared on only 28% of all pages (see Figure 4).', text='It is evident that applying OCR is the most expensive operation. In our benchmark dataset, OCR engages in 578 pages. On average, transcribing a page with EasyOCR took 1.6 s on the L4 GPU, 13 s on the x86 CPU and 5 s on the M3 Max SoC. The layout model spent 44 ms on the L4 GPU, 633 ms on the x86 CPU and 271 ms on the M3 Max SoC on average for each page, making it the cheapest of the AI models, while TableFormer (fast flavour) spent 400 ms on the L4 GPU, 1.74 s on the x86 CPU and 704 ms on the M3 Max SoC on average per table. Regarding the total time spent converting our benchmark dataset, TableFormer had less impact than other AI models, since tables appeared on only 28% of all pages (see Figure 4).', formatting=None, hyperlink=None), TextItem(self_ref='#/texts/177', parent=RefItem(cref='#/body'), children=[], content_layer=<ContentLayer.BODY: 'body'>, label=<DocItemLabel.TEXT: 'text'>, prov=[ProvenanceItem(page_no=6, bbox=BoundingBox(l=54.0, t=408.964, r=292.505, b=334.659, coord_origin=<CoordOrigin.BOTTOMLEFT: 'BOTTOMLEFT'>), charspan=(0, 370))], orig='On the L4 GPU, we observe a speedup of 8x (OCR), 14x (Layout model) and 4.3x (Table structure) compared to the x86 CPU and a speedup of 3x (OCR), 6x (Layout model) and 1.7x (Table structure) compared to the M3 Max CPU of our MacBook Pro. This shows that there is no equal benefit for all AI models from the GPU acceleration and there might be potential for optimization.', text='On the L4 GPU, we observe a speedup of 8x (OCR), 14x (Layout model) and 4.3x (Table structure) compared to the x86 CPU and a speedup of 3x (OCR), 6x (Layout model) and 1.7x (Table structure) compared to the M3 Max CPU of our MacBook Pro. This shows that there is no equal benefit for all AI models from the GPU acceleration and there might be potential for optimization.', formatting=None, hyperlink=None), TextItem(self_ref='#/texts/178', parent=RefItem(cref='#/body'), children=[], content_layer=<ContentLayer.BODY: 'body'>, label=<DocItemLabel.TEXT: 'text'>, prov=[ProvenanceItem(page_no=6, bbox=BoundingBox(l=54.0, t=330.13, r=292.505, b=277.74199999999996, coord_origin=<CoordOrigin.BOTTOMLEFT: 'BOTTOMLEFT'>), charspan=(0, 237))], orig='The time spent in parsing a PDF page through our docling-parse backend is substantially lower in comparison to the AI models. On average, parsing a PDF page took 81 ms on the x86 CPU and 44 ms on the M3 Max SoC (there is no GPU support).', text='The time spent in parsing a PDF page through our docling-parse backend is substantially lower in comparison to the AI models. On average, parsing a PDF page took 81 ms on the x86 CPU and 44 ms on the M3 Max SoC (there is no GPU support).', formatting=None, hyperlink=None), TextItem(self_ref='#/texts/179', parent=RefItem(cref='#/body'), children=[], content_layer=<ContentLayer.BODY: 'body'>, label=<DocItemLabel.TEXT: 'text'>, prov=[ProvenanceItem(page_no=6, bbox=BoundingBox(l=54.0, t=263.38, r=292.505, b=221.563, coord_origin=<CoordOrigin.BOTTOMLEFT: 'BOTTOMLEFT'>), charspan=(0, 207))], orig='Comparison to Other Tools We compare the average times to convert a page between Docling, Marker, MinerU, and Unstructured on the system configurations outlined in section 5.2. Results are shown in Figure 5.', text='Comparison to Other Tools We compare the average times to convert a page between Docling, Marker, MinerU, and Unstructured on the system configurations outlined in section 5.2. Results are shown in Figure 5.', formatting=None, hyperlink=None), TextItem(self_ref='#/texts/180', parent=RefItem(cref='#/body'), children=[], content_layer=<ContentLayer.BODY: 'body'>, label=<DocItemLabel.TEXT: 'text'>, prov=[ProvenanceItem(page_no=6, bbox=BoundingBox(l=54.0, t=217.034, r=292.505, b=87.93399999999997, coord_origin=<CoordOrigin.BOTTOMLEFT: 'BOTTOMLEFT'>), charspan=(0, 661))], orig='Without GPU support, Docling leads with 3.1 sec/page (x86 CPU) and 1.27 sec/page (M3 Max SoC), followed closely by MinerU (3.3 sec/page on x86 CPU) and Unstructured (4.2 sec/page on x86 CPU, 2.7 sec/page on M3 Max SoC), while Marker needs over 16 sec/page (x86 CPU) and 4.2 sec/page (M3 Mac SoC). MinerU, despite several efforts to configure its environment, did not finish any run on our MacBook Pro M3 Max. With CUDA acceleration on the Nvidia L4 GPU, the picture changes and MinerU takes the lead over the contenders with 0.21 sec/page, compared to 0.49 sec/page with Docling and 0.86 sec/page with Marker. Unstructured does not profit from GPU acceleration.', text='Without GPU support, Docling leads with 3.1 sec/page (x86 CPU) and 1.27 sec/page (M3 Max SoC), followed closely by MinerU (3.3 sec/page on x86 CPU) and Unstructured (4.2 sec/page on x86 CPU, 2.7 sec/page on M3 Max SoC), while Marker needs over 16 sec/page (x86 CPU) and 4.2 sec/page (M3 Mac SoC). MinerU, despite several efforts to configure its environment, did not finish any run on our MacBook Pro M3 Max. With CUDA acceleration on the Nvidia L4 GPU, the picture changes and MinerU takes the lead over the contenders with 0.21 sec/page, compared to 0.49 sec/page with Docling and 0.86 sec/page with Marker. Unstructured does not profit from GPU acceleration.', formatting=None, hyperlink=None), SectionHeaderItem(self_ref='#/texts/181', parent=RefItem(cref='#/body'), children=[], content_layer=<ContentLayer.BODY: 'body'>, label=<DocItemLabel.SECTION_HEADER: 'section_header'>, prov=[ProvenanceItem(page_no=6, bbox=BoundingBox(l=397.714, t=736.286, r=479.786, b=725.538, coord_origin=<CoordOrigin.BOTTOMLEFT: 'BOTTOMLEFT'>), charspan=(0, 14))], orig='6 Applications', text='6 Applications', formatting=None, hyperlink=None, level=1), TextItem(self_ref='#/texts/182', parent=RefItem(cref='#/body'), children=[], content_layer=<ContentLayer.BODY: 'body'>, label=<DocItemLabel.TEXT: 'text'>, prov=[ProvenanceItem(page_no=6, bbox=BoundingBox(l=319.5, t=719.125, r=558.005, b=677.697, coord_origin=<CoordOrigin.BOTTOMLEFT: 'BOTTOMLEFT'>), charspan=(0, 228))], orig=\"Docling's document extraction capabilities make it naturally suitable for workflows like generative AI applications (e.g., RAG), data preparation for foundation model training, and fine-tuning, as well as information extraction.\", text=\"Docling's document extraction capabilities make it naturally suitable for workflows like generative AI applications (e.g., RAG), data preparation for foundation model training, and fine-tuning, as well as information extraction.\", formatting=None, hyperlink=None), TextItem(self_ref='#/texts/183', parent=RefItem(cref='#/body'), children=[], content_layer=<ContentLayer.BODY: 'body'>, label=<DocItemLabel.TEXT: 'text'>, prov=[ProvenanceItem(page_no=6, bbox=BoundingBox(l=319.5, t=674.806, r=558.005, b=458.035, coord_origin=<CoordOrigin.BOTTOMLEFT: 'BOTTOMLEFT'>), charspan=(0, 1104))], orig='As far as RAG is concerned, users can leverage existing Docling extensions for popular frameworks like LlamaIndex and then harness framework capabilities for RAG components like embedding models, vector stores, etc. These Docling extensions typically provide two modes of operation: one using a lossy export, e.g., to Markdown, and one using lossless serialization via JSON. The former provides a simple starting point, upon which any text-based chunking method may be applied (e.g., also drawing from the framework library), while the latter, which uses a swappable Docling chunker type, can be the more powerful one, as it can provide document-native RAG grounding via rich metadata such as the page number and the bounding box of the supporting context. For usage outside of these frameworks, users can still employ Docling chunkers to accelerate and simplify the development of their custom pipelines. Besides strict RAG pipelines for Q&A, Docling can naturally be utilized in the context of broader agentic workflows for which it can provide document-based knowledge for agents to decide and act on.', text='As far as RAG is concerned, users can leverage existing Docling extensions for popular frameworks like LlamaIndex and then harness framework capabilities for RAG components like embedding models, vector stores, etc. These Docling extensions typically provide two modes of operation: one using a lossy export, e.g., to Markdown, and one using lossless serialization via JSON. The former provides a simple starting point, upon which any text-based chunking method may be applied (e.g., also drawing from the framework library), while the latter, which uses a swappable Docling chunker type, can be the more powerful one, as it can provide document-native RAG grounding via rich metadata such as the page number and the bounding box of the supporting context. For usage outside of these frameworks, users can still employ Docling chunkers to accelerate and simplify the development of their custom pipelines. Besides strict RAG pipelines for Q&A, Docling can naturally be utilized in the context of broader agentic workflows for which it can provide document-based knowledge for agents to decide and act on.', formatting=None, hyperlink=None), TextItem(self_ref='#/texts/184', parent=RefItem(cref='#/body'), children=[], content_layer=<ContentLayer.BODY: 'body'>, label=<DocItemLabel.TEXT: 'text'>, prov=[ProvenanceItem(page_no=6, bbox=BoundingBox(l=319.5, t=455.145, r=558.005, b=413.716, coord_origin=<CoordOrigin.BOTTOMLEFT: 'BOTTOMLEFT'>), charspan=(0, 202))], orig='Moreover, Docling-enabled pipelines can generate ground truth data out of documents. Such domain-specific knowledge can make significant impact when infused to foundation model training and fine-tuning.', text='Moreover, Docling-enabled pipelines can generate ground truth data out of documents. Such domain-specific knowledge can make significant impact when infused to foundation model training and fine-tuning.', formatting=None, hyperlink=None), TextItem(self_ref='#/texts/185', parent=RefItem(cref='#/body'), children=[], content_layer=<ContentLayer.BODY: 'body'>, label=<DocItemLabel.TEXT: 'text'>, prov=[ProvenanceItem(page_no=6, bbox=BoundingBox(l=319.5, t=410.826, r=558.005, b=336.52, coord_origin=<CoordOrigin.BOTTOMLEFT: 'BOTTOMLEFT'>), charspan=(0, 382))], orig='Last but not least, Docling can be used as a backbone for information extraction tasks. Users who seek to create structured representations out of unstructured documents can leverage Docling, which maps various document formats to the unified DoclingDocument format, as well as its strong table understanding capabilities that can help better analyze semi-structured document parts.', text='Last but not least, Docling can be used as a backbone for information extraction tasks. Users who seek to create structured representations out of unstructured documents can leverage Docling, which maps various document formats to the unified DoclingDocument format, as well as its strong table understanding capabilities that can help better analyze semi-structured document parts.', formatting=None, hyperlink=None), SectionHeaderItem(self_ref='#/texts/186', parent=RefItem(cref='#/body'), children=[], content_layer=<ContentLayer.BODY: 'body'>, label=<DocItemLabel.SECTION_HEADER: 'section_header'>, prov=[ProvenanceItem(page_no=6, bbox=BoundingBox(l=402.891, t=322.35, r=474.61, b=311.602, coord_origin=<CoordOrigin.BOTTOMLEFT: 'BOTTOMLEFT'>), charspan=(0, 11))], orig='7 Ecosystem', text='7 Ecosystem', formatting=None, hyperlink=None, level=1), TextItem(self_ref='#/texts/187', parent=RefItem(cref='#/body'), children=[], content_layer=<ContentLayer.BODY: 'body'>, label=<DocItemLabel.TEXT: 'text'>, prov=[ProvenanceItem(page_no=6, bbox=BoundingBox(l=319.5, t=305.189, r=558.005, b=219.92499999999995, coord_origin=<CoordOrigin.BOTTOMLEFT: 'BOTTOMLEFT'>), charspan=(0, 414))], orig='Docling is quickly evolving into a mainstream package for document conversion. The support for PDF, MS Office formats, Images, HTML, and more makes it a universal choice for downstream applications. Users appreciate the intuitiveness of the library, the high-quality, richly structured conversion output, as well as the permissive MIT license, and the possibility of running entirely locally on commodity hardware.', text='Docling is quickly evolving into a mainstream package for document conversion. The support for PDF, MS Office formats, Images, HTML, and more makes it a universal choice for downstream applications. Users appreciate the intuitiveness of the library, the high-quality, richly structured conversion output, as well as the permissive MIT license, and the possibility of running entirely locally on commodity hardware.', formatting=None, hyperlink=None), TextItem(self_ref='#/texts/188', parent=RefItem(cref='#/body'), children=[], content_layer=<ContentLayer.BODY: 'body'>, label=<DocItemLabel.TEXT: 'text'>, prov=[ProvenanceItem(page_no=6, bbox=BoundingBox(l=319.5, t=217.034, r=558.005, b=87.93399999999997, coord_origin=<CoordOrigin.BOTTOMLEFT: 'BOTTOMLEFT'>), charspan=(0, 676))], orig='Among the integrations created by the Docling team and the growing community, a few are worth mentioning as depicted in Figure 6. For popular generative AI application patterns, we provide native integration within LangChain (Chase 2022) and LlamaIndex (Liu 2022) for reading documents and chunking. Processing and transforming documents at scale for building large-scale multi-modal training datasets are enabled by the integration in the open IBM data-prep-kit (Wood et al. 2024). Agentic workloads can leverage the integration with the Bee framework (IBM Research 2024). For the fine-tuning of language models, Docling is integrated in InstructLab (Sudalairaj et al. 2024),', text='Among the integrations created by the Docling team and the growing community, a few are worth mentioning as depicted in Figure 6. For popular generative AI application patterns, we provide native integration within LangChain (Chase 2022) and LlamaIndex (Liu 2022) for reading documents and chunking. Processing and transforming documents at scale for building large-scale multi-modal training datasets are enabled by the integration in the open IBM data-prep-kit (Wood et al. 2024). Agentic workloads can leverage the integration with the Bee framework (IBM Research 2024). For the fine-tuning of language models, Docling is integrated in InstructLab (Sudalairaj et al. 2024),', formatting=None, hyperlink=None), TextItem(self_ref='#/texts/189', parent=RefItem(cref='#/pictures/3'), children=[], content_layer=<ContentLayer.BODY: 'body'>, label=<DocItemLabel.CAPTION: 'caption'>, prov=[ProvenanceItem(page_no=7, bbox=BoundingBox(l=54.0, t=525.254, r=557.998, b=483.825, coord_origin=<CoordOrigin.BOTTOMLEFT: 'BOTTOMLEFT'>), charspan=(0, 487))], orig='Figure 4: Contributions of PDF backend and AI models to the conversion time of a page (in seconds per page). Lower is better. Left: Ranges of time contributions for each model to pages it was applied on (i.e., OCR was applied only on pages with bitmaps, table structure was applied only on pages with tables). Right: Average time contribution to a page in the benchmark dataset (factoring in zero-time contribution for OCR and table structure models on pages without bitmaps or tables) .', text='Figure 4: Contributions of PDF backend and AI models to the conversion time of a page (in seconds per page). Lower is better. Left: Ranges of time contributions for each model to pages it was applied on (i.e., OCR was applied only on pages with bitmaps, table structure was applied only on pages with tables). Right: Average time contribution to a page in the benchmark dataset (factoring in zero-time contribution for OCR and table structure models on pages without bitmaps or tables) .', formatting=None, hyperlink=None), TextItem(self_ref='#/texts/190', parent=RefItem(cref='#/pictures/3'), children=[], content_layer=<ContentLayer.BODY: 'body'>, label=<DocItemLabel.TEXT: 'text'>, prov=[ProvenanceItem(page_no=7, bbox=BoundingBox(l=123.034, t=578.628, r=153.088, b=551.56, coord_origin=<CoordOrigin.BOTTOMLEFT: 'BOTTOMLEFT'>), charspan=(0, 9))], orig='Pdf Parse', text='Pdf Parse', formatting=None, hyperlink=None), TextItem(self_ref='#/texts/191', parent=RefItem(cref='#/pictures/3'), children=[], content_layer=<ContentLayer.BODY: 'body'>, label=<DocItemLabel.TEXT: 'text'>, prov=[ProvenanceItem(page_no=7, bbox=BoundingBox(l=170.78, t=578.598, r=187.712, b=562.542, coord_origin=<CoordOrigin.BOTTOMLEFT: 'BOTTOMLEFT'>), charspan=(0, 3))], orig='OCR', text='OCR', formatting=None, hyperlink=None), TextItem(self_ref='#/texts/192', parent=RefItem(cref='#/pictures/3'), children=[], content_layer=<ContentLayer.BODY: 'body'>, label=<DocItemLabel.TEXT: 'text'>, prov=[ProvenanceItem(page_no=7, bbox=BoundingBox(l=198.895, t=578.597, r=222.369, b=557.051, coord_origin=<CoordOrigin.BOTTOMLEFT: 'BOTTOMLEFT'>), charspan=(0, 6))], orig='Layout', text='Layout', formatting=None, hyperlink=None), TextItem(self_ref='#/texts/193', parent=RefItem(cref='#/pictures/3'), children=[], content_layer=<ContentLayer.BODY: 'body'>, label=<DocItemLabel.TEXT: 'text'>, prov=[ProvenanceItem(page_no=7, bbox=BoundingBox(l=211.267, t=578.598, r=257.029, b=538.35, coord_origin=<CoordOrigin.BOTTOMLEFT: 'BOTTOMLEFT'>), charspan=(0, 15))], orig='Table Structure', text='Table Structure', formatting=None, hyperlink=None), TextItem(self_ref='#/texts/194', parent=RefItem(cref='#/pictures/3'), children=[], content_layer=<ContentLayer.BODY: 'body'>, label=<DocItemLabel.TEXT: 'text'>, prov=[ProvenanceItem(page_no=7, bbox=BoundingBox(l=259.29, t=578.657, r=291.759, b=549.564, coord_origin=<CoordOrigin.BOTTOMLEFT: 'BOTTOMLEFT'>), charspan=(0, 10))], orig='Page Total', text='Page Total', formatting=None, hyperlink=None), TextItem(self_ref='#/texts/195', parent=RefItem(cref='#/pictures/3'), children=[], content_layer=<ContentLayer.BODY: 'body'>, label=<DocItemLabel.TEXT: 'text'>, prov=[ProvenanceItem(page_no=7, bbox=BoundingBox(l=116.069, t=589.29, r=124.975, b=581.135, coord_origin=<CoordOrigin.BOTTOMLEFT: 'BOTTOMLEFT'>), charspan=(0, 2))], orig='10', text='10', formatting=None, hyperlink=None), TextItem(self_ref='#/texts/196', parent=RefItem(cref='#/pictures/3'), children=[], content_layer=<ContentLayer.BODY: 'body'>, label=<DocItemLabel.TEXT: 'text'>, prov=[ProvenanceItem(page_no=7, bbox=BoundingBox(l=129.149, t=590.019, r=132.266, b=584.311, coord_origin=<CoordOrigin.BOTTOMLEFT: 'BOTTOMLEFT'>), charspan=(0, 1))], orig='2', text='2', formatting=None, hyperlink=None), TextItem(self_ref='#/texts/197', parent=RefItem(cref='#/pictures/3'), children=[], content_layer=<ContentLayer.BODY: 'body'>, label=<DocItemLabel.TEXT: 'text'>, prov=[ProvenanceItem(page_no=7, bbox=BoundingBox(l=116.069, t=632.362, r=124.975, b=624.207, coord_origin=<CoordOrigin.BOTTOMLEFT: 'BOTTOMLEFT'>), charspan=(0, 2))], orig='10', text='10', formatting=None, hyperlink=None), TextItem(self_ref='#/texts/198', parent=RefItem(cref='#/pictures/3'), children=[], content_layer=<ContentLayer.BODY: 'body'>, label=<DocItemLabel.TEXT: 'text'>, prov=[ProvenanceItem(page_no=7, bbox=BoundingBox(l=129.149, t=633.091, r=132.266, b=627.382, coord_origin=<CoordOrigin.BOTTOMLEFT: 'BOTTOMLEFT'>), charspan=(0, 1))], orig='1', text='1', formatting=None, hyperlink=None), TextItem(self_ref='#/texts/199', parent=RefItem(cref='#/pictures/3'), children=[], content_layer=<ContentLayer.BODY: 'body'>, label=<DocItemLabel.TEXT: 'text'>, prov=[ProvenanceItem(page_no=7, bbox=BoundingBox(l=120.269, t=676.74, r=132.36, b=667.856, coord_origin=<CoordOrigin.BOTTOMLEFT: 'BOTTOMLEFT'>), charspan=(0, 4))], orig='10 0', text='10 0', formatting=None, hyperlink=None), TextItem(self_ref='#/texts/200', parent=RefItem(cref='#/pictures/3'), children=[], content_layer=<ContentLayer.BODY: 'body'>, label=<DocItemLabel.TEXT: 'text'>, prov=[ProvenanceItem(page_no=7, bbox=BoundingBox(l=120.269, t=719.811, r=132.36, b=710.927, coord_origin=<CoordOrigin.BOTTOMLEFT: 'BOTTOMLEFT'>), charspan=(0, 4))], orig='10 1', text='10 1', formatting=None, hyperlink=None), TextItem(self_ref='#/texts/201', parent=RefItem(cref='#/pictures/3'), children=[], content_layer=<ContentLayer.BODY: 'body'>, label=<DocItemLabel.TEXT: 'text'>, prov=[ProvenanceItem(page_no=7, bbox=BoundingBox(l=105.312, t=675.068, r=113.467, b=643.421, coord_origin=<CoordOrigin.BOTTOMLEFT: 'BOTTOMLEFT'>), charspan=(0, 8))], orig='sec/page', text='sec/page', formatting=None, hyperlink=None), TextItem(self_ref='#/texts/202', parent=RefItem(cref='#/pictures/3'), children=[], content_layer=<ContentLayer.BODY: 'body'>, label=<DocItemLabel.TEXT: 'text'>, prov=[ProvenanceItem(page_no=7, bbox=BoundingBox(l=326.444, t=578.628, r=356.499, b=551.56, coord_origin=<CoordOrigin.BOTTOMLEFT: 'BOTTOMLEFT'>), charspan=(0, 9))], orig='Pdf Parse', text='Pdf Parse', formatting=None, hyperlink=None), TextItem(self_ref='#/texts/203', parent=RefItem(cref='#/pictures/3'), children=[], content_layer=<ContentLayer.BODY: 'body'>, label=<DocItemLabel.TEXT: 'text'>, prov=[ProvenanceItem(page_no=7, bbox=BoundingBox(l=371.869, t=578.598, r=388.801, b=562.542, coord_origin=<CoordOrigin.BOTTOMLEFT: 'BOTTOMLEFT'>), charspan=(0, 3))], orig='OCR', text='OCR', formatting=None, hyperlink=None), TextItem(self_ref='#/texts/204', parent=RefItem(cref='#/pictures/3'), children=[], content_layer=<ContentLayer.BODY: 'body'>, label=<DocItemLabel.TEXT: 'text'>, prov=[ProvenanceItem(page_no=7, bbox=BoundingBox(l=397.662, t=578.597, r=421.136, b=557.051, coord_origin=<CoordOrigin.BOTTOMLEFT: 'BOTTOMLEFT'>), charspan=(0, 6))], orig='Layout', text='Layout', formatting=None, hyperlink=None), TextItem(self_ref='#/texts/205', parent=RefItem(cref='#/pictures/3'), children=[], content_layer=<ContentLayer.BODY: 'body'>, label=<DocItemLabel.TEXT: 'text'>, prov=[ProvenanceItem(page_no=7, bbox=BoundingBox(l=407.713, t=578.598, r=453.475, b=538.35, coord_origin=<CoordOrigin.BOTTOMLEFT: 'BOTTOMLEFT'>), charspan=(0, 15))], orig='Table Structure', text='Table Structure', formatting=None, hyperlink=None), TextItem(self_ref='#/texts/206', parent=RefItem(cref='#/pictures/3'), children=[], content_layer=<ContentLayer.BODY: 'body'>, label=<DocItemLabel.TEXT: 'text'>, prov=[ProvenanceItem(page_no=7, bbox=BoundingBox(l=453.414, t=578.657, r=485.883, b=549.564, coord_origin=<CoordOrigin.BOTTOMLEFT: 'BOTTOMLEFT'>), charspan=(0, 10))], orig='Page Total', text='Page Total', formatting=None, hyperlink=None), TextItem(self_ref='#/texts/207', parent=RefItem(cref='#/pictures/3'), children=[], content_layer=<ContentLayer.BODY: 'body'>, label=<DocItemLabel.TEXT: 'text'>, prov=[ProvenanceItem(page_no=7, bbox=BoundingBox(l=320.502, t=586.439, r=331.632, b=578.284, coord_origin=<CoordOrigin.BOTTOMLEFT: 'BOTTOMLEFT'>), charspan=(0, 3))], orig='0.0', text='0.0', formatting=None, hyperlink=None), TextItem(self_ref='#/texts/208', parent=RefItem(cref='#/pictures/3'), children=[], content_layer=<ContentLayer.BODY: 'body'>, label=<DocItemLabel.TEXT: 'text'>, prov=[ProvenanceItem(page_no=7, bbox=BoundingBox(l=320.502, t=610.023, r=331.632, b=601.868, coord_origin=<CoordOrigin.BOTTOMLEFT: 'BOTTOMLEFT'>), charspan=(0, 3))], orig='0.5', text='0.5', formatting=None, hyperlink=None), TextItem(self_ref='#/texts/209', parent=RefItem(cref='#/pictures/3'), children=[], content_layer=<ContentLayer.BODY: 'body'>, label=<DocItemLabel.TEXT: 'text'>, prov=[ProvenanceItem(page_no=7, bbox=BoundingBox(l=320.502, t=633.606, r=331.632, b=625.451, coord_origin=<CoordOrigin.BOTTOMLEFT: 'BOTTOMLEFT'>), charspan=(0, 3))], orig='1.0', text='1.0', formatting=None, hyperlink=None), TextItem(self_ref='#/texts/210', parent=RefItem(cref='#/pictures/3'), children=[], content_layer=<ContentLayer.BODY: 'body'>, label=<DocItemLabel.TEXT: 'text'>, prov=[ProvenanceItem(page_no=7, bbox=BoundingBox(l=320.502, t=657.19, r=331.632, b=649.035, coord_origin=<CoordOrigin.BOTTOMLEFT: 'BOTTOMLEFT'>), charspan=(0, 3))], orig='1.5', text='1.5', formatting=None, hyperlink=None), TextItem(self_ref='#/texts/211', parent=RefItem(cref='#/pictures/3'), children=[], content_layer=<ContentLayer.BODY: 'body'>, label=<DocItemLabel.TEXT: 'text'>, prov=[ProvenanceItem(page_no=7, bbox=BoundingBox(l=320.502, t=680.773, r=331.632, b=672.618, coord_origin=<CoordOrigin.BOTTOMLEFT: 'BOTTOMLEFT'>), charspan=(0, 3))], orig='2.0', text='2.0', formatting=None, hyperlink=None), TextItem(self_ref='#/texts/212', parent=RefItem(cref='#/pictures/3'), children=[], content_layer=<ContentLayer.BODY: 'body'>, label=<DocItemLabel.TEXT: 'text'>, prov=[ProvenanceItem(page_no=7, bbox=BoundingBox(l=320.502, t=704.357, r=331.632, b=696.202, coord_origin=<CoordOrigin.BOTTOMLEFT: 'BOTTOMLEFT'>), charspan=(0, 3))], orig='2.5', text='2.5', formatting=None, hyperlink=None), TextItem(self_ref='#/texts/213', parent=RefItem(cref='#/pictures/3'), children=[], content_layer=<ContentLayer.BODY: 'body'>, label=<DocItemLabel.TEXT: 'text'>, prov=[ProvenanceItem(page_no=7, bbox=BoundingBox(l=320.502, t=727.94, r=331.632, b=719.785, coord_origin=<CoordOrigin.BOTTOMLEFT: 'BOTTOMLEFT'>), charspan=(0, 3))], orig='3.0', text='3.0', formatting=None, hyperlink=None), TextItem(self_ref='#/texts/214', parent=RefItem(cref='#/pictures/3'), children=[], content_layer=<ContentLayer.BODY: 'body'>, label=<DocItemLabel.TEXT: 'text'>, prov=[ProvenanceItem(page_no=7, bbox=BoundingBox(l=309.745, t=675.068, r=317.9, b=643.421, coord_origin=<CoordOrigin.BOTTOMLEFT: 'BOTTOMLEFT'>), charspan=(0, 8))], orig='sec/page', text='sec/page', formatting=None, hyperlink=None), TextItem(self_ref='#/texts/215', parent=RefItem(cref='#/pictures/3'), children=[], content_layer=<ContentLayer.BODY: 'body'>, label=<DocItemLabel.TEXT: 'text'>, prov=[ProvenanceItem(page_no=7, bbox=BoundingBox(l=370.979, t=722.808, r=400.484, b=714.653, coord_origin=<CoordOrigin.BOTTOMLEFT: 'BOTTOMLEFT'>), charspan=(0, 7))], orig='x86 CPU', text='x86 CPU', formatting=None, hyperlink=None), TextItem(self_ref='#/texts/216', parent=RefItem(cref='#/pictures/3'), children=[], content_layer=<ContentLayer.BODY: 'body'>, label=<DocItemLabel.TEXT: 'text'>, prov=[ProvenanceItem(page_no=7, bbox=BoundingBox(l=370.979, t=712.538, r=398.174, b=704.383, coord_origin=<CoordOrigin.BOTTOMLEFT: 'BOTTOMLEFT'>), charspan=(0, 6))], orig='M3 Max', text='M3 Max', formatting=None, hyperlink=None), TextItem(self_ref='#/texts/217', parent=RefItem(cref='#/pictures/3'), children=[], content_layer=<ContentLayer.BODY: 'body'>, label=<DocItemLabel.TEXT: 'text'>, prov=[ProvenanceItem(page_no=7, bbox=BoundingBox(l=370.979, t=702.268, r=396.326, b=694.113, coord_origin=<CoordOrigin.BOTTOMLEFT: 'BOTTOMLEFT'>), charspan=(0, 6))], orig='L4 GPU', text='L4 GPU', formatting=None, hyperlink=None), TextItem(self_ref='#/texts/218', parent=RefItem(cref='#/pictures/4'), children=[], content_layer=<ContentLayer.BODY: 'body'>, label=<DocItemLabel.CAPTION: 'caption'>, prov=[ProvenanceItem(page_no=7, bbox=BoundingBox(l=54.0, t=260.72900000000004, r=292.505, b=197.38200000000006, coord_origin=<CoordOrigin.BOTTOMLEFT: 'BOTTOMLEFT'>), charspan=(0, 300))], orig='Figure 5: Conversion time in seconds per page on our dataset in three scenarios, across all assets and system configurations. Lower bars are better. The configuration includes OCR and table structure recognition ( fast table option on Docling and MinerU, hi res in unstructured, as shown in table 1).', text='Figure 5: Conversion time in seconds per page on our dataset in three scenarios, across all assets and system configurations. Lower bars are better. The configuration includes OCR and table structure recognition ( fast table option on Docling and MinerU, hi res in unstructured, as shown in table 1).', formatting=None, hyperlink=None), TextItem(self_ref='#/texts/219', parent=RefItem(cref='#/pictures/4'), children=[], content_layer=<ContentLayer.BODY: 'body'>, label=<DocItemLabel.TEXT: 'text'>, prov=[ProvenanceItem(page_no=7, bbox=BoundingBox(l=100.506, t=307.477, r=124.534, b=285.565, coord_origin=<CoordOrigin.BOTTOMLEFT: 'BOTTOMLEFT'>), charspan=(0, 7))], orig='Docling', text='Docling', formatting=None, hyperlink=None), TextItem(self_ref='#/texts/220', parent=RefItem(cref='#/pictures/4'), children=[], content_layer=<ContentLayer.BODY: 'body'>, label=<DocItemLabel.TEXT: 'text'>, prov=[ProvenanceItem(page_no=7, bbox=BoundingBox(l=141.973, t=307.493, r=164.482, b=286.856, coord_origin=<CoordOrigin.BOTTOMLEFT: 'BOTTOMLEFT'>), charspan=(0, 6))], orig='Marker', text='Marker', formatting=None, hyperlink=None), TextItem(self_ref='#/texts/221', parent=RefItem(cref='#/pictures/4'), children=[], content_layer=<ContentLayer.BODY: 'body'>, label=<DocItemLabel.TEXT: 'text'>, prov=[ProvenanceItem(page_no=7, bbox=BoundingBox(l=181.996, t=307.476, r=204.39, b=286.936, coord_origin=<CoordOrigin.BOTTOMLEFT: 'BOTTOMLEFT'>), charspan=(0, 6))], orig='Mineru', text='Mineru', formatting=None, hyperlink=None), TextItem(self_ref='#/texts/222', parent=RefItem(cref='#/pictures/4'), children=[], content_layer=<ContentLayer.BODY: 'body'>, label=<DocItemLabel.TEXT: 'text'>, prov=[ProvenanceItem(page_no=7, bbox=BoundingBox(l=206.176, t=307.481, r=244.323, b=273.722, coord_origin=<CoordOrigin.BOTTOMLEFT: 'BOTTOMLEFT'>), charspan=(0, 12))], orig='Unstructured', text='Unstructured', formatting=None, hyperlink=None), TextItem(self_ref='#/texts/223', parent=RefItem(cref='#/pictures/4'), children=[], content_layer=<ContentLayer.BODY: 'body'>, label=<DocItemLabel.TEXT: 'text'>, prov=[ProvenanceItem(page_no=7, bbox=BoundingBox(l=93.108, t=314.896, r=97.322, b=307.178, coord_origin=<CoordOrigin.BOTTOMLEFT: 'BOTTOMLEFT'>), charspan=(0, 1))], orig='0', text='0', formatting=None, hyperlink=None), TextItem(self_ref='#/texts/224', parent=RefItem(cref='#/pictures/4'), children=[], content_layer=<ContentLayer.BODY: 'body'>, label=<DocItemLabel.TEXT: 'text'>, prov=[ProvenanceItem(page_no=7, bbox=BoundingBox(l=93.108, t=332.324, r=97.322, b=324.605, coord_origin=<CoordOrigin.BOTTOMLEFT: 'BOTTOMLEFT'>), charspan=(0, 1))], orig='2', text='2', formatting=None, hyperlink=None), TextItem(self_ref='#/texts/225', parent=RefItem(cref='#/pictures/4'), children=[], content_layer=<ContentLayer.BODY: 'body'>, label=<DocItemLabel.TEXT: 'text'>, prov=[ProvenanceItem(page_no=7, bbox=BoundingBox(l=93.108, t=349.751, r=97.322, b=342.033, coord_origin=<CoordOrigin.BOTTOMLEFT: 'BOTTOMLEFT'>), charspan=(0, 1))], orig='4', text='4', formatting=None, hyperlink=None), TextItem(self_ref='#/texts/226', parent=RefItem(cref='#/pictures/4'), children=[], content_layer=<ContentLayer.BODY: 'body'>, label=<DocItemLabel.TEXT: 'text'>, prov=[ProvenanceItem(page_no=7, bbox=BoundingBox(l=93.108, t=367.178, r=97.322, b=359.46, coord_origin=<CoordOrigin.BOTTOMLEFT: 'BOTTOMLEFT'>), charspan=(0, 1))], orig='6', text='6', formatting=None, hyperlink=None), TextItem(self_ref='#/texts/227', parent=RefItem(cref='#/pictures/4'), children=[], content_layer=<ContentLayer.BODY: 'body'>, label=<DocItemLabel.TEXT: 'text'>, prov=[ProvenanceItem(page_no=7, bbox=BoundingBox(l=93.108, t=384.606, r=97.322, b=376.887, coord_origin=<CoordOrigin.BOTTOMLEFT: 'BOTTOMLEFT'>), charspan=(0, 1))], orig='8', text='8', formatting=None, hyperlink=None), TextItem(self_ref='#/texts/228', parent=RefItem(cref='#/pictures/4'), children=[], content_layer=<ContentLayer.BODY: 'body'>, label=<DocItemLabel.TEXT: 'text'>, prov=[ProvenanceItem(page_no=7, bbox=BoundingBox(l=88.895, t=402.033, r=97.322, b=394.315, coord_origin=<CoordOrigin.BOTTOMLEFT: 'BOTTOMLEFT'>), charspan=(0, 2))], orig='10', text='10', formatting=None, hyperlink=None), TextItem(self_ref='#/texts/229', parent=RefItem(cref='#/pictures/4'), children=[], content_layer=<ContentLayer.BODY: 'body'>, label=<DocItemLabel.TEXT: 'text'>, prov=[ProvenanceItem(page_no=7, bbox=BoundingBox(l=88.895, t=419.46, r=97.322, b=411.742, coord_origin=<CoordOrigin.BOTTOMLEFT: 'BOTTOMLEFT'>), charspan=(0, 2))], orig='12', text='12', formatting=None, hyperlink=None), TextItem(self_ref='#/texts/230', parent=RefItem(cref='#/pictures/4'), children=[], content_layer=<ContentLayer.BODY: 'body'>, label=<DocItemLabel.TEXT: 'text'>, prov=[ProvenanceItem(page_no=7, bbox=BoundingBox(l=88.895, t=436.887, r=97.322, b=429.169, coord_origin=<CoordOrigin.BOTTOMLEFT: 'BOTTOMLEFT'>), charspan=(0, 2))], orig='14', text='14', formatting=None, hyperlink=None), TextItem(self_ref='#/texts/231', parent=RefItem(cref='#/pictures/4'), children=[], content_layer=<ContentLayer.BODY: 'body'>, label=<DocItemLabel.TEXT: 'text'>, prov=[ProvenanceItem(page_no=7, bbox=BoundingBox(l=88.895, t=454.315, r=97.322, b=446.597, coord_origin=<CoordOrigin.BOTTOMLEFT: 'BOTTOMLEFT'>), charspan=(0, 2))], orig='16', text='16', formatting=None, hyperlink=None), TextItem(self_ref='#/texts/232', parent=RefItem(cref='#/pictures/4'), children=[], content_layer=<ContentLayer.BODY: 'body'>, label=<DocItemLabel.TEXT: 'text'>, prov=[ProvenanceItem(page_no=7, bbox=BoundingBox(l=78.714, t=400.946, r=86.432, b=370.994, coord_origin=<CoordOrigin.BOTTOMLEFT: 'BOTTOMLEFT'>), charspan=(0, 8))], orig='sec/page', text='sec/page', formatting=None, hyperlink=None), TextItem(self_ref='#/texts/233', parent=RefItem(cref='#/pictures/4'), children=[], content_layer=<ContentLayer.BODY: 'body'>, label=<DocItemLabel.TEXT: 'text'>, prov=[ProvenanceItem(page_no=7, bbox=BoundingBox(l=232.761, t=455.851, r=260.685, b=448.132, coord_origin=<CoordOrigin.BOTTOMLEFT: 'BOTTOMLEFT'>), charspan=(0, 7))], orig='x86 CPU', text='x86 CPU', formatting=None, hyperlink=None), TextItem(self_ref='#/texts/234', parent=RefItem(cref='#/pictures/4'), children=[], content_layer=<ContentLayer.BODY: 'body'>, label=<DocItemLabel.TEXT: 'text'>, prov=[ProvenanceItem(page_no=7, bbox=BoundingBox(l=232.761, t=446.13, r=258.499, b=438.412, coord_origin=<CoordOrigin.BOTTOMLEFT: 'BOTTOMLEFT'>), charspan=(0, 6))], orig='M3 Max', text='M3 Max', formatting=None, hyperlink=None), TextItem(self_ref='#/texts/235', parent=RefItem(cref='#/pictures/4'), children=[], content_layer=<ContentLayer.BODY: 'body'>, label=<DocItemLabel.TEXT: 'text'>, prov=[ProvenanceItem(page_no=7, bbox=BoundingBox(l=232.761, t=436.41, r=256.75, b=428.692, coord_origin=<CoordOrigin.BOTTOMLEFT: 'BOTTOMLEFT'>), charspan=(0, 6))], orig='L4 GPU', text='L4 GPU', formatting=None, hyperlink=None), TextItem(self_ref='#/texts/236', parent=RefItem(cref='#/body'), children=[], content_layer=<ContentLayer.BODY: 'body'>, label=<DocItemLabel.TEXT: 'text'>, prov=[ProvenanceItem(page_no=7, bbox=BoundingBox(l=54.0, t=165.74599999999998, r=292.505, b=146.235, coord_origin=<CoordOrigin.BOTTOMLEFT: 'BOTTOMLEFT'>), charspan=(0, 60))], orig='where it supports the enhancement of the knowledge taxonomy.', text='where it supports the enhancement of the knowledge taxonomy.', formatting=None, hyperlink=None), TextItem(self_ref='#/texts/237', parent=RefItem(cref='#/body'), children=[], content_layer=<ContentLayer.BODY: 'body'>, label=<DocItemLabel.TEXT: 'text'>, prov=[ProvenanceItem(page_no=7, bbox=BoundingBox(l=54.0, t=140.322, r=292.505, b=87.93399999999997, coord_origin=<CoordOrigin.BOTTOMLEFT: 'BOTTOMLEFT'>), charspan=(0, 257))], orig='Docling is also available and officially maintained as a system package in the Red Hat ® Enterprise Linux ® AI (RHEL AI) distribution, which seamlessly allows to develop, test, and run the Granite family of large language models for enterprise applications.', text='Docling is also available and officially maintained as a system package in the Red Hat ® Enterprise Linux ® AI (RHEL AI) distribution, which seamlessly allows to develop, test, and run the Granite family of large language models for enterprise applications.', formatting=None, hyperlink=None), TextItem(self_ref='#/texts/238', parent=RefItem(cref='#/pictures/5'), children=[], content_layer=<ContentLayer.BODY: 'body'>, label=<DocItemLabel.CAPTION: 'caption'>, prov=[ProvenanceItem(page_no=7, bbox=BoundingBox(l=319.5, t=350.664, r=558.005, b=309.235, coord_origin=<CoordOrigin.BOTTOMLEFT: 'BOTTOMLEFT'>), charspan=(0, 230))], orig='Figure 6: Ecosystem of Docling integrations contributed by the Docling team or the broader community. Docling is already used for RAG, model fine-tuning, large-scale datasets creation, information extraction and agentic workflows.', text='Figure 6: Ecosystem of Docling integrations contributed by the Docling team or the broader community. Docling is already used for RAG, model fine-tuning, large-scale datasets creation, information extraction and agentic workflows.', formatting=None, hyperlink=None), TextItem(self_ref='#/texts/239', parent=RefItem(cref='#/pictures/5'), children=[], content_layer=<ContentLayer.BODY: 'body'>, label=<DocItemLabel.TEXT: 'text'>, prov=[ProvenanceItem(page_no=7, bbox=BoundingBox(l=415.052, t=372.962, r=460.836, b=361.742, coord_origin=<CoordOrigin.BOTTOMLEFT: 'BOTTOMLEFT'>), charspan=(0, 7))], orig='Docling', text='Docling', formatting=None, hyperlink=None), TextItem(self_ref='#/texts/240', parent=RefItem(cref='#/pictures/5'), children=[], content_layer=<ContentLayer.BODY: 'body'>, label=<DocItemLabel.TEXT: 'text'>, prov=[ProvenanceItem(page_no=7, bbox=BoundingBox(l=332.246, t=453.004, r=381.124, b=444.925, coord_origin=<CoordOrigin.BOTTOMLEFT: 'BOTTOMLEFT'>), charspan=(0, 11))], orig='InstructLab', text='InstructLab', formatting=None, hyperlink=None), TextItem(self_ref='#/texts/241', parent=RefItem(cref='#/pictures/5'), children=[], content_layer=<ContentLayer.BODY: 'body'>, label=<DocItemLabel.TEXT: 'text'>, prov=[ProvenanceItem(page_no=7, bbox=BoundingBox(l=381.098, t=456.247, r=390.554, b=443.831, coord_origin=<CoordOrigin.BOTTOMLEFT: 'BOTTOMLEFT'>), charspan=(0, 1))], orig='🐶', text='🐶', formatting=None, hyperlink=None), TextItem(self_ref='#/texts/242', parent=RefItem(cref='#/pictures/5'), children=[], content_layer=<ContentLayer.BODY: 'body'>, label=<DocItemLabel.TEXT: 'text'>, prov=[ProvenanceItem(page_no=7, bbox=BoundingBox(l=331.483, t=420.853, r=372.613, b=412.774, coord_origin=<CoordOrigin.BOTTOMLEFT: 'BOTTOMLEFT'>), charspan=(0, 9))], orig='Bee Agent', text='Bee Agent', formatting=None, hyperlink=None), TextItem(self_ref='#/texts/243', parent=RefItem(cref='#/pictures/5'), children=[], content_layer=<ContentLayer.BODY: 'body'>, label=<DocItemLabel.TEXT: 'text'>, prov=[ProvenanceItem(page_no=7, bbox=BoundingBox(l=323.597, t=409.758, r=371.087, b=401.679, coord_origin=<CoordOrigin.BOTTOMLEFT: 'BOTTOMLEFT'>), charspan=(0, 9))], orig='Framework', text='Framework', formatting=None, hyperlink=None), TextItem(self_ref='#/texts/244', parent=RefItem(cref='#/pictures/5'), children=[], content_layer=<ContentLayer.BODY: 'body'>, label=<DocItemLabel.TEXT: 'text'>, prov=[ProvenanceItem(page_no=7, bbox=BoundingBox(l=371.067, t=413.001, r=380.523, b=400.585, coord_origin=<CoordOrigin.BOTTOMLEFT: 'BOTTOMLEFT'>), charspan=(0, 1))], orig='🐝', text='🐝', formatting=None, hyperlink=None), TextItem(self_ref='#/texts/245', parent=RefItem(cref='#/pictures/5'), children=[], content_layer=<ContentLayer.BODY: 'body'>, label=<DocItemLabel.TEXT: 'text'>, prov=[ProvenanceItem(page_no=7, bbox=BoundingBox(l=413.625, t=458.047, r=462.88, b=449.968, coord_origin=<CoordOrigin.BOTTOMLEFT: 'BOTTOMLEFT'>), charspan=(0, 10))], orig='LlamaIndex', text='LlamaIndex', formatting=None, hyperlink=None), TextItem(self_ref='#/texts/246', parent=RefItem(cref='#/pictures/5'), children=[], content_layer=<ContentLayer.BODY: 'body'>, label=<DocItemLabel.TEXT: 'text'>, prov=[ProvenanceItem(page_no=7, bbox=BoundingBox(l=462.866, t=461.29, r=472.322, b=448.874, coord_origin=<CoordOrigin.BOTTOMLEFT: 'BOTTOMLEFT'>), charspan=(0, 1))], orig='🦙', text='🦙', formatting=None, hyperlink=None), TextItem(self_ref='#/texts/247', parent=RefItem(cref='#/pictures/5'), children=[], content_layer=<ContentLayer.BODY: 'body'>, label=<DocItemLabel.TEXT: 'text'>, prov=[ProvenanceItem(page_no=7, bbox=BoundingBox(l=488.068, t=452.499, r=533.881, b=444.421, coord_origin=<CoordOrigin.BOTTOMLEFT: 'BOTTOMLEFT'>), charspan=(0, 9))], orig='LangChain', text='LangChain', formatting=None, hyperlink=None), TextItem(self_ref='#/texts/248', parent=RefItem(cref='#/pictures/5'), children=[], content_layer=<ContentLayer.BODY: 'body'>, label=<DocItemLabel.TEXT: 'text'>, prov=[ProvenanceItem(page_no=7, bbox=BoundingBox(l=533.888, t=455.743, r=552.8, b=443.327, coord_origin=<CoordOrigin.BOTTOMLEFT: 'BOTTOMLEFT'>), charspan=(0, 2))], orig='🦜🔗', text='🦜🔗', formatting=None, hyperlink=None), TextItem(self_ref='#/texts/249', parent=RefItem(cref='#/pictures/5'), children=[], content_layer=<ContentLayer.BODY: 'body'>, label=<DocItemLabel.TEXT: 'text'>, prov=[ProvenanceItem(page_no=7, bbox=BoundingBox(l=488.849, t=381.827, r=497.444, b=372.851, coord_origin=<CoordOrigin.BOTTOMLEFT: 'BOTTOMLEFT'>), charspan=(0, 1))], orig='…', text='…', formatting=None, hyperlink=None), TextItem(self_ref='#/texts/250', parent=RefItem(cref='#/pictures/5'), children=[], content_layer=<ContentLayer.BODY: 'body'>, label=<DocItemLabel.TEXT: 'text'>, prov=[ProvenanceItem(page_no=7, bbox=BoundingBox(l=326.89, t=380.885, r=377.758, b=372.807, coord_origin=<CoordOrigin.BOTTOMLEFT: 'BOTTOMLEFT'>), charspan=(0, 11))], orig='DataPrepKit', text='DataPrepKit', formatting=None, hyperlink=None), TextItem(self_ref='#/texts/251', parent=RefItem(cref='#/pictures/5'), children=[], content_layer=<ContentLayer.BODY: 'body'>, label=<DocItemLabel.TEXT: 'text'>, prov=[ProvenanceItem(page_no=7, bbox=BoundingBox(l=377.758, t=384.128, r=387.215, b=371.713, coord_origin=<CoordOrigin.BOTTOMLEFT: 'BOTTOMLEFT'>), charspan=(0, 1))], orig='🧰', text='🧰', formatting=None, hyperlink=None), TextItem(self_ref='#/texts/252', parent=RefItem(cref='#/pictures/5'), children=[], content_layer=<ContentLayer.BODY: 'body'>, label=<DocItemLabel.TEXT: 'text'>, prov=[ProvenanceItem(page_no=7, bbox=BoundingBox(l=500.324, t=414.423, r=526.134, b=406.344, coord_origin=<CoordOrigin.BOTTOMLEFT: 'BOTTOMLEFT'>), charspan=(0, 5))], orig='spaCy', text='spaCy', formatting=None, hyperlink=None), SectionHeaderItem(self_ref='#/texts/253', parent=RefItem(cref='#/body'), children=[], content_layer=<ContentLayer.BODY: 'body'>, label=<DocItemLabel.SECTION_HEADER: 'section_header'>, prov=[ProvenanceItem(page_no=7, bbox=BoundingBox(l=347.927, t=283.11, r=529.574, b=272.3620000000001, coord_origin=<CoordOrigin.BOTTOMLEFT: 'BOTTOMLEFT'>), charspan=(0, 31))], orig='8 Future Work and Contributions', text='8 Future Work and Contributions', formatting=None, hyperlink=None, level=1), TextItem(self_ref='#/texts/254', parent=RefItem(cref='#/body'), children=[], content_layer=<ContentLayer.BODY: 'body'>, label=<DocItemLabel.TEXT: 'text'>, prov=[ProvenanceItem(page_no=7, bbox=BoundingBox(l=319.5, t=262.50199999999995, r=558.005, b=100.52499999999998, coord_origin=<CoordOrigin.BOTTOMLEFT: 'BOTTOMLEFT'>), charspan=(0, 872))], orig=\"Docling's modular architecture allows an easy extension of the model library and pipelines. In the future, we plan to extend Docling with several additional models, such as a figure-classifier model, an equation-recognition model and a code-recognition model. This will help improve the quality of conversion for specific types of content, as well as augment extracted document metadata with additional information. Furthermore, we will focus on building an opensource quality evaluation framework for the tasks performed by Docling, such as layout analysis, table structure recognition, reading order detection, text transcription, etc. This will allow transparent quality comparisons based on publicly available benchmarks such as DP-Bench (Zhong 2020), OmnidDocBench(Ouyang et al. 2024) and others. Results will be published in a future update of this technical report.\", text=\"Docling's modular architecture allows an easy extension of the model library and pipelines. In the future, we plan to extend Docling with several additional models, such as a figure-classifier model, an equation-recognition model and a code-recognition model. This will help improve the quality of conversion for specific types of content, as well as augment extracted document metadata with additional information. Furthermore, we will focus on building an opensource quality evaluation framework for the tasks performed by Docling, such as layout analysis, table structure recognition, reading order detection, text transcription, etc. This will allow transparent quality comparisons based on publicly available benchmarks such as DP-Bench (Zhong 2020), OmnidDocBench(Ouyang et al. 2024) and others. Results will be published in a future update of this technical report.\", formatting=None, hyperlink=None), TextItem(self_ref='#/texts/255', parent=RefItem(cref='#/body'), children=[], content_layer=<ContentLayer.BODY: 'body'>, label=<DocItemLabel.TEXT: 'text'>, prov=[ProvenanceItem(page_no=7, bbox=BoundingBox(l=329.463, t=96.48599999999999, r=557.995, b=87.93399999999997, coord_origin=<CoordOrigin.BOTTOMLEFT: 'BOTTOMLEFT'>), charspan=(0, 53))], orig='The codebase of Docling is open for use under the MIT', text='The codebase of Docling is open for use under the MIT', formatting=None, hyperlink=None), TextItem(self_ref='#/texts/256', parent=RefItem(cref='#/body'), children=[], content_layer=<ContentLayer.BODY: 'body'>, label=<DocItemLabel.TEXT: 'text'>, prov=[ProvenanceItem(page_no=8, bbox=BoundingBox(l=54.0, t=734.523, r=292.505, b=704.054, coord_origin=<CoordOrigin.BOTTOMLEFT: 'BOTTOMLEFT'>), charspan=(0, 170))], orig='license agreement and its roadmap is outlined in the discussions section 1 of our GitHub repository. We encourage everyone to propose improvements and make contributions.', text='license agreement and its roadmap is outlined in the discussions section 1 of our GitHub repository. We encourage everyone to propose improvements and make contributions.', formatting=None, hyperlink=None), SectionHeaderItem(self_ref='#/texts/257', parent=RefItem(cref='#/body'), children=[], content_layer=<ContentLayer.BODY: 'body'>, label=<DocItemLabel.SECTION_HEADER: 'section_header'>, prov=[ProvenanceItem(page_no=8, bbox=BoundingBox(l=145.478, t=691.983, r=201.022, b=681.235, coord_origin=<CoordOrigin.BOTTOMLEFT: 'BOTTOMLEFT'>), charspan=(0, 10))], orig='References', text='References', formatting=None, hyperlink=None, level=1), TextItem(self_ref='#/texts/258', parent=RefItem(cref='#/body'), children=[], content_layer=<ContentLayer.BODY: 'body'>, label=<DocItemLabel.TEXT: 'text'>, prov=[ProvenanceItem(page_no=8, bbox=BoundingBox(l=54.0, t=676.859, r=292.505, b=657.349, coord_origin=<CoordOrigin.BOTTOMLEFT: 'BOTTOMLEFT'>), charspan=(0, 98))], orig='2024. EasyOCR: Ready-to-use OCR with 80+ supported languages. https://github.com/JaidedAI/EasyOCR.', text='2024. EasyOCR: Ready-to-use OCR with 80+ supported languages. https://github.com/JaidedAI/EasyOCR.', formatting=None, hyperlink=None), TextItem(self_ref='#/texts/259', parent=RefItem(cref='#/body'), children=[], content_layer=<ContentLayer.BODY: 'body'>, label=<DocItemLabel.TEXT: 'text'>, prov=[ProvenanceItem(page_no=8, bbox=BoundingBox(l=54.0, t=653.038, r=286.846, b=644.486, coord_origin=<CoordOrigin.BOTTOMLEFT: 'BOTTOMLEFT'>), charspan=(0, 50))], orig='2024. PyMuPDF. https://github.com/pymupdf/PyMuPDF.', text='2024. PyMuPDF. https://github.com/pymupdf/PyMuPDF.', formatting=None, hyperlink=None), TextItem(self_ref='#/texts/260', parent=RefItem(cref='#/body'), children=[], content_layer=<ContentLayer.BODY: 'body'>, label=<DocItemLabel.TEXT: 'text'>, prov=[ProvenanceItem(page_no=8, bbox=BoundingBox(l=54.0, t=640.176, r=292.505, b=576.829, coord_origin=<CoordOrigin.BOTTOMLEFT: 'BOTTOMLEFT'>), charspan=(0, 305))], orig=\"Ansel, J.; Yang, E.; He, H.; et al. 2024. PyTorch 2: Faster Machine Learning Through Dynamic Python Bytecode Transformation and Graph Compilation. In Proceedings of the 29th ACM International Conference on Architectural Support for Programming Languages and Operating Systems, Volume 2 (ASPLOS '24) . ACM.\", text=\"Ansel, J.; Yang, E.; He, H.; et al. 2024. PyTorch 2: Faster Machine Learning Through Dynamic Python Bytecode Transformation and Graph Compilation. In Proceedings of the 29th ACM International Conference on Architectural Support for Programming Languages and Operating Systems, Volume 2 (ASPLOS '24) . ACM.\", formatting=None, hyperlink=None), TextItem(self_ref='#/texts/261', parent=RefItem(cref='#/body'), children=[], content_layer=<ContentLayer.BODY: 'body'>, label=<DocItemLabel.TEXT: 'text'>, prov=[ProvenanceItem(page_no=8, bbox=BoundingBox(l=54.0, t=572.519, r=292.505, b=520.131, coord_origin=<CoordOrigin.BOTTOMLEFT: 'BOTTOMLEFT'>), charspan=(0, 249))], orig='Auer, C.; Dolfi, M.; Carvalho, A.; Ramis, C. B.; and Staar, P. W. 2022. Delivering Document Conversion as a Cloud Service with High Throughput and Responsiveness. In 2022 IEEE 15th International Conference on Cloud Computing (CLOUD) , 363-373. IEEE.', text='Auer, C.; Dolfi, M.; Carvalho, A.; Ramis, C. B.; and Staar, P. W. 2022. Delivering Document Conversion as a Cloud Service with High Throughput and Responsiveness. In 2022 IEEE 15th International Conference on Cloud Computing (CLOUD) , 363-373. IEEE.', formatting=None, hyperlink=None), TextItem(self_ref='#/texts/262', parent=RefItem(cref='#/body'), children=[], content_layer=<ContentLayer.BODY: 'body'>, label=<DocItemLabel.TEXT: 'text'>, prov=[ProvenanceItem(page_no=8, bbox=BoundingBox(l=54.0, t=515.821, r=292.505, b=496.31, coord_origin=<CoordOrigin.BOTTOMLEFT: 'BOTTOMLEFT'>), charspan=(0, 103))], orig='Berkenbilt, J. 2024. QPDF: A Content-Preserving PDF Document Transformer. https://github.com/qpdf/qpdf.', text='Berkenbilt, J. 2024. QPDF: A Content-Preserving PDF Document Transformer. https://github.com/qpdf/qpdf.', formatting=None, hyperlink=None), TextItem(self_ref='#/texts/263', parent=RefItem(cref='#/body'), children=[], content_layer=<ContentLayer.BODY: 'body'>, label=<DocItemLabel.TEXT: 'text'>, prov=[ProvenanceItem(page_no=8, bbox=BoundingBox(l=54.0, t=492.0, r=292.505, b=461.53, coord_origin=<CoordOrigin.BOTTOMLEFT: 'BOTTOMLEFT'>), charspan=(0, 148))], orig='Canny, S.; and contributors. 2013-2024a. python-docx: Create and update Microsoft Word .docx files with Python. https://python-docx.readthedocs.io/.', text='Canny, S.; and contributors. 2013-2024a. python-docx: Create and update Microsoft Word .docx files with Python. https://python-docx.readthedocs.io/.', formatting=None, hyperlink=None), TextItem(self_ref='#/texts/264', parent=RefItem(cref='#/body'), children=[], content_layer=<ContentLayer.BODY: 'body'>, label=<DocItemLabel.TEXT: 'text'>, prov=[ProvenanceItem(page_no=8, bbox=BoundingBox(l=54.0, t=457.219, r=292.505, b=426.75, coord_origin=<CoordOrigin.BOTTOMLEFT: 'BOTTOMLEFT'>), charspan=(0, 157))], orig='Canny, S.; and contributors. 2013-2024b. python-pptx: Python library for creating and updating PowerPoint (.pptx) files. https://python-pptx.readthedocs.io/.', text='Canny, S.; and contributors. 2013-2024b. python-pptx: Python library for creating and updating PowerPoint (.pptx) files. https://python-pptx.readthedocs.io/.', formatting=None, hyperlink=None), TextItem(self_ref='#/texts/265', parent=RefItem(cref='#/body'), children=[], content_layer=<ContentLayer.BODY: 'body'>, label=<DocItemLabel.TEXT: 'text'>, prov=[ProvenanceItem(page_no=8, bbox=BoundingBox(l=54.0, t=422.439, r=292.505, b=402.928, coord_origin=<CoordOrigin.BOTTOMLEFT: 'BOTTOMLEFT'>), charspan=(0, 68))], orig='Chase, H. 2022. LangChain. https://github.com/langchainai/langchain.', text='Chase, H. 2022. LangChain. https://github.com/langchainai/langchain.', formatting=None, hyperlink=None), TextItem(self_ref='#/texts/266', parent=RefItem(cref='#/body'), children=[], content_layer=<ContentLayer.BODY: 'body'>, label=<DocItemLabel.TEXT: 'text'>, prov=[ProvenanceItem(page_no=8, bbox=BoundingBox(l=54.0, t=398.618, r=292.505, b=368.148, coord_origin=<CoordOrigin.BOTTOMLEFT: 'BOTTOMLEFT'>), charspan=(0, 132))], orig='Eric Gazoni, C. C. 2010-2024. openpyxl: A Python library to read/write Excel 2010 xlsx/xlsm files. https://openpyxl.readthedocs.io/.', text='Eric Gazoni, C. C. 2010-2024. openpyxl: A Python library to read/write Excel 2010 xlsx/xlsm files. https://openpyxl.readthedocs.io/.', formatting=None, hyperlink=None), TextItem(self_ref='#/texts/267', parent=RefItem(cref='#/body'), children=[], content_layer=<ContentLayer.BODY: 'body'>, label=<DocItemLabel.TEXT: 'text'>, prov=[ProvenanceItem(page_no=8, bbox=BoundingBox(l=54.0, t=363.838, r=292.505, b=344.327, coord_origin=<CoordOrigin.BOTTOMLEFT: 'BOTTOMLEFT'>), charspan=(0, 89))], orig='IBM Research. 2024. Bee Agent Framework. https://github.com/i-am-bee/bee-agent-framework.', text='IBM Research. 2024. Bee Agent Framework. https://github.com/i-am-bee/bee-agent-framework.', formatting=None, hyperlink=None), TextItem(self_ref='#/texts/268', parent=RefItem(cref='#/body'), children=[], content_layer=<ContentLayer.BODY: 'body'>, label=<DocItemLabel.TEXT: 'text'>, prov=[ProvenanceItem(page_no=8, bbox=BoundingBox(l=54.0, t=340.017, r=292.505, b=320.506, coord_origin=<CoordOrigin.BOTTOMLEFT: 'BOTTOMLEFT'>), charspan=(0, 68))], orig='Liu, J. 2022. LlamaIndex. https://github.com/jerryjliu/ llama index.', text='Liu, J. 2022. LlamaIndex. https://github.com/jerryjliu/ llama index.', formatting=None, hyperlink=None), TextItem(self_ref='#/texts/269', parent=RefItem(cref='#/body'), children=[], content_layer=<ContentLayer.BODY: 'body'>, label=<DocItemLabel.TEXT: 'text'>, prov=[ProvenanceItem(page_no=8, bbox=BoundingBox(l=54.0, t=316.195, r=292.505, b=185.192, coord_origin=<CoordOrigin.BOTTOMLEFT: 'BOTTOMLEFT'>), charspan=(0, 628))], orig='Livathinos, N.; Berrospi, C.; Lysak, M.; Kuropiatnyk, V.; Nassar, A.; Carvalho, A.; Dolfi, M.; Auer, C.; Dinkla, K.; and Staar, P. 2021. Robust PDF Document Conversion using Recurrent Neural Networks. Proceedings of the AAAI Conference on Artificial Intelligence , 35(17): 15137-15145. Lysak, M.; Nassar, A.; Livathinos, N.; Auer, C.; and Staar, P. 2023. Optimized Table Tokenization for Table Structure Recognition. In Document Analysis and Recognition - ICDAR 2023: 17th International Conference, San Jos´ e, CA, USA, August 21-26, 2023, Proceedings, Part II , 3750. Berlin, Heidelberg: Springer-Verlag. ISBN 978-3-03141678-1.', text='Livathinos, N.; Berrospi, C.; Lysak, M.; Kuropiatnyk, V.; Nassar, A.; Carvalho, A.; Dolfi, M.; Auer, C.; Dinkla, K.; and Staar, P. 2021. Robust PDF Document Conversion using Recurrent Neural Networks. Proceedings of the AAAI Conference on Artificial Intelligence , 35(17): 15137-15145. Lysak, M.; Nassar, A.; Livathinos, N.; Auer, C.; and Staar, P. 2023. Optimized Table Tokenization for Table Structure Recognition. In Document Analysis and Recognition - ICDAR 2023: 17th International Conference, San Jos´ e, CA, USA, August 21-26, 2023, Proceedings, Part II , 3750. Berlin, Heidelberg: Springer-Verlag. ISBN 978-3-03141678-1.', formatting=None, hyperlink=None), TextItem(self_ref='#/texts/270', parent=RefItem(cref='#/body'), children=[], content_layer=<ContentLayer.BODY: 'body'>, label=<DocItemLabel.TEXT: 'text'>, prov=[ProvenanceItem(page_no=8, bbox=BoundingBox(l=54.0, t=180.88200000000006, r=292.505, b=161.37099999999998, coord_origin=<CoordOrigin.BOTTOMLEFT: 'BOTTOMLEFT'>), charspan=(0, 105))], orig='Ming, F. 2019-2024. Marko: A markdown parser with high extensibility. https://github.com/frostming/marko.', text='Ming, F. 2019-2024. Marko: A markdown parser with high extensibility. https://github.com/frostming/marko.', formatting=None, hyperlink=None), TextItem(self_ref='#/texts/271', parent=RefItem(cref='#/body'), children=[], content_layer=<ContentLayer.BODY: 'body'>, label=<DocItemLabel.TEXT: 'text'>, prov=[ProvenanceItem(page_no=8, bbox=BoundingBox(l=54.0, t=157.05999999999995, r=292.505, b=115.63200000000006, coord_origin=<CoordOrigin.BOTTOMLEFT: 'BOTTOMLEFT'>), charspan=(0, 218))], orig='Nassar, A.; Livathinos, N.; Lysak, M.; and Staar, P. 2022. Tableformer: Table structure understanding with transformers. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition , 4614-4623.', text='Nassar, A.; Livathinos, N.; Lysak, M.; and Staar, P. 2022. Tableformer: Table structure understanding with transformers. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition , 4614-4623.', formatting=None, hyperlink=None), TextItem(self_ref='#/texts/272', parent=RefItem(cref='#/body'), children=[], content_layer=<ContentLayer.BODY: 'body'>, label=<DocItemLabel.FOOTNOTE: 'footnote'>, prov=[ProvenanceItem(page_no=8, bbox=BoundingBox(l=54.0, t=107.66300000000001, r=279.129, b=88.13999999999999, coord_origin=<CoordOrigin.BOTTOMLEFT: 'BOTTOMLEFT'>), charspan=(0, 66))], orig='1 https://github.com/DS4SD/docling/discussions/categories/ roadmap', text='1 https://github.com/DS4SD/docling/discussions/categories/ roadmap', formatting=None, hyperlink=None), TextItem(self_ref='#/texts/273', parent=RefItem(cref='#/body'), children=[], content_layer=<ContentLayer.BODY: 'body'>, label=<DocItemLabel.TEXT: 'text'>, prov=[ProvenanceItem(page_no=8, bbox=BoundingBox(l=319.5, t=734.523, r=558.005, b=671.177, coord_origin=<CoordOrigin.BOTTOMLEFT: 'BOTTOMLEFT'>), charspan=(0, 301))], orig='Ouyang, L.; Qu, Y.; Zhou, H.; Zhu, J.; Zhang, R.; Lin, Q.; Wang, B.; Zhao, Z.; Jiang, M.; Zhao, X.; Shi, J.; Wu, F.; Chu, P.; Liu, M.; Li, Z.; Xu, C.; Zhang, B.; Shi, B.; Tu, Z.; and He, C. 2024. OmniDocBench: Benchmarking Diverse PDF Document Parsing with Comprehensive Annotations. arXiv:2412.07626.', text='Ouyang, L.; Qu, Y.; Zhou, H.; Zhu, J.; Zhang, R.; Lin, Q.; Wang, B.; Zhao, Z.; Jiang, M.; Zhao, X.; Shi, J.; Wu, F.; Chu, P.; Liu, M.; Li, Z.; Xu, C.; Zhang, B.; Shi, B.; Tu, Z.; and He, C. 2024. OmniDocBench: Benchmarking Diverse PDF Document Parsing with Comprehensive Annotations. arXiv:2412.07626.', formatting=None, hyperlink=None), TextItem(self_ref='#/texts/274', parent=RefItem(cref='#/body'), children=[], content_layer=<ContentLayer.BODY: 'body'>, label=<DocItemLabel.TEXT: 'text'>, prov=[ProvenanceItem(page_no=8, bbox=BoundingBox(l=319.5, t=666.279, r=558.005, b=635.809, coord_origin=<CoordOrigin.BOTTOMLEFT: 'BOTTOMLEFT'>), charspan=(0, 119))], orig='Paruchuri, V. 2024. Marker: Convert PDF to Markdown Quickly with High Accuracy. https://github.com/VikParuchuri/marker.', text='Paruchuri, V. 2024. Marker: Convert PDF to Markdown Quickly with High Accuracy. https://github.com/VikParuchuri/marker.', formatting=None, hyperlink=None), TextItem(self_ref='#/texts/275', parent=RefItem(cref='#/body'), children=[], content_layer=<ContentLayer.BODY: 'body'>, label=<DocItemLabel.TEXT: 'text'>, prov=[ProvenanceItem(page_no=8, bbox=BoundingBox(l=319.5, t=630.912, r=558.005, b=600.442, coord_origin=<CoordOrigin.BOTTOMLEFT: 'BOTTOMLEFT'>), charspan=(0, 158))], orig='Pfitzmann, B.; Auer, C.; Dolfi, M.; Nassar, A. S.; and Staar, P. 2022. DocLayNet: a large human-annotated dataset for document-layout segmentation. 3743-3751.', text='Pfitzmann, B.; Auer, C.; Dolfi, M.; Nassar, A. S.; and Staar, P. 2022. DocLayNet: a large human-annotated dataset for document-layout segmentation. 3743-3751.', formatting=None, hyperlink=None), TextItem(self_ref='#/texts/276', parent=RefItem(cref='#/body'), children=[], content_layer=<ContentLayer.BODY: 'body'>, label=<DocItemLabel.TEXT: 'text'>, prov=[ProvenanceItem(page_no=8, bbox=BoundingBox(l=319.5, t=595.545, r=558.005, b=576.034, coord_origin=<CoordOrigin.BOTTOMLEFT: 'BOTTOMLEFT'>), charspan=(0, 91))], orig='pypdf Maintainers. 2024. pypdf: A Pure-Python PDF Library. https://github.com/py-pdf/pypdf.', text='pypdf Maintainers. 2024. pypdf: A Pure-Python PDF Library. https://github.com/py-pdf/pypdf.', formatting=None, hyperlink=None), TextItem(self_ref='#/texts/277', parent=RefItem(cref='#/body'), children=[], content_layer=<ContentLayer.BODY: 'body'>, label=<DocItemLabel.TEXT: 'text'>, prov=[ProvenanceItem(page_no=8, bbox=BoundingBox(l=319.5, t=571.136, r=558.005, b=551.625, coord_origin=<CoordOrigin.BOTTOMLEFT: 'BOTTOMLEFT'>), charspan=(0, 104))], orig='PyPDFium Team. 2024. PyPDFium2: Python bindings for PDFium. https://github.com/pypdfium2-team/pypdfium2.', text='PyPDFium Team. 2024. PyPDFium2: Python bindings for PDFium. https://github.com/pypdfium2-team/pypdfium2.', formatting=None, hyperlink=None), TextItem(self_ref='#/texts/278', parent=RefItem(cref='#/body'), children=[], content_layer=<ContentLayer.BODY: 'body'>, label=<DocItemLabel.TEXT: 'text'>, prov=[ProvenanceItem(page_no=8, bbox=BoundingBox(l=319.5, t=546.728, r=558.005, b=516.258, coord_origin=<CoordOrigin.BOTTOMLEFT: 'BOTTOMLEFT'>), charspan=(0, 132))], orig='Richardson, L. 2004-2024. Beautiful Soup: A Python library for parsing HTML and XML. https://www.crummy.com/software/BeautifulSoup/.', text='Richardson, L. 2004-2024. Beautiful Soup: A Python library for parsing HTML and XML. https://www.crummy.com/software/BeautifulSoup/.', formatting=None, hyperlink=None), TextItem(self_ref='#/texts/279', parent=RefItem(cref='#/body'), children=[], content_layer=<ContentLayer.BODY: 'body'>, label=<DocItemLabel.TEXT: 'text'>, prov=[ProvenanceItem(page_no=8, bbox=BoundingBox(l=319.5, t=511.36, r=558.005, b=480.89, coord_origin=<CoordOrigin.BOTTOMLEFT: 'BOTTOMLEFT'>), charspan=(0, 148))], orig='Sudalairaj, S.; Bhandwaldar, A.; Pareja, A.; Xu, K.; Cox, D. D.; and Srivastava, A. 2024. LAB: Large-Scale Alignment for ChatBots. arXiv:2403.01081.', text='Sudalairaj, S.; Bhandwaldar, A.; Pareja, A.; Xu, K.; Cox, D. D.; and Srivastava, A. 2024. LAB: Large-Scale Alignment for ChatBots. arXiv:2403.01081.', formatting=None, hyperlink=None), TextItem(self_ref='#/texts/280', parent=RefItem(cref='#/body'), children=[], content_layer=<ContentLayer.BODY: 'body'>, label=<DocItemLabel.TEXT: 'text'>, prov=[ProvenanceItem(page_no=8, bbox=BoundingBox(l=319.5, t=475.993, r=558.005, b=412.646, coord_origin=<CoordOrigin.BOTTOMLEFT: 'BOTTOMLEFT'>), charspan=(0, 342))], orig='Turski, M.; Stanisławek, T.; Kaczmarek, K.; Dyda, P.; and Grali´ nski, F. 2023. CCpdf: Building a High Quality Corpus for Visually Rich Documents from Web Crawl Data. In Fink, G. A.; Jain, R.; Kise, K.; and Zanibbi, R., eds., Document Analysis and Recognition - ICDAR 2023 , 348-365. Cham: Springer Nature Switzerland. ISBN 978-3-031-41682-8.', text='Turski, M.; Stanisławek, T.; Kaczmarek, K.; Dyda, P.; and Grali´ nski, F. 2023. CCpdf: Building a High Quality Corpus for Visually Rich Documents from Web Crawl Data. In Fink, G. A.; Jain, R.; Kise, K.; and Zanibbi, R., eds., Document Analysis and Recognition - ICDAR 2023 , 348-365. Cham: Springer Nature Switzerland. ISBN 978-3-031-41682-8.', formatting=None, hyperlink=None), TextItem(self_ref='#/texts/281', parent=RefItem(cref='#/body'), children=[], content_layer=<ContentLayer.BODY: 'body'>, label=<DocItemLabel.TEXT: 'text'>, prov=[ProvenanceItem(page_no=8, bbox=BoundingBox(l=319.5, t=407.749, r=558.005, b=377.279, coord_origin=<CoordOrigin.BOTTOMLEFT: 'BOTTOMLEFT'>), charspan=(0, 146))], orig='Unstructured.io Team. 2024. Unstructured.io: OpenSource Pre-Processing Tools for Unstructured Data. https://unstructured.io. Accessed: 2024-11-19.', text='Unstructured.io Team. 2024. Unstructured.io: OpenSource Pre-Processing Tools for Unstructured Data. https://unstructured.io. Accessed: 2024-11-19.', formatting=None, hyperlink=None), TextItem(self_ref='#/texts/282', parent=RefItem(cref='#/body'), children=[], content_layer=<ContentLayer.BODY: 'body'>, label=<DocItemLabel.TEXT: 'text'>, prov=[ProvenanceItem(page_no=8, bbox=BoundingBox(l=319.5, t=372.381, r=558.005, b=319.994, coord_origin=<CoordOrigin.BOTTOMLEFT: 'BOTTOMLEFT'>), charspan=(0, 266))], orig='Wang, B.; Xu, C.; Zhao, X.; Ouyang, L.; Wu, F.; Zhao, Z.; Xu, R.; Liu, K.; Qu, Y.; Shang, F.; Zhang, B.; Wei, L.; Sui, Z.; Li, W.; Shi, B.; Qiao, Y.; Lin, D.; and He, C. 2024. MinerU: An Open-Source Solution for Precise Document Content Extraction. arXiv:2409.18839.', text='Wang, B.; Xu, C.; Zhao, X.; Ouyang, L.; Wu, F.; Zhao, Z.; Xu, R.; Liu, K.; Qu, Y.; Shang, F.; Zhang, B.; Wei, L.; Sui, Z.; Li, W.; Shi, B.; Qiao, Y.; Lin, D.; and He, C. 2024. MinerU: An Open-Source Solution for Precise Document Content Extraction. arXiv:2409.18839.', formatting=None, hyperlink=None), TextItem(self_ref='#/texts/283', parent=RefItem(cref='#/body'), children=[], content_layer=<ContentLayer.BODY: 'body'>, label=<DocItemLabel.TEXT: 'text'>, prov=[ProvenanceItem(page_no=8, bbox=BoundingBox(l=319.5, t=315.096, r=558.005, b=251.75, coord_origin=<CoordOrigin.BOTTOMLEFT: 'BOTTOMLEFT'>), charspan=(0, 358))], orig=\"Wolf, T.; Debut, L.; Sanh, V.; Chaumond, J.; Delangue, C.; Moi, A.; Cistac, P.; Rault, T.; Louf, R.; Funtowicz, M.; Davison, J.; Shleifer, S.; von Platen, P.; Ma, C.; Jernite, Y .; Plu, J.; Xu, C.; Scao, T. L.; Gugger, S.; Drame, M.; Lhoest, Q.; and Rush, A. M. 2020. HuggingFace's Transformers: Stateof-the-art Natural Language Processing. arXiv:1910.03771.\", text=\"Wolf, T.; Debut, L.; Sanh, V.; Chaumond, J.; Delangue, C.; Moi, A.; Cistac, P.; Rault, T.; Louf, R.; Funtowicz, M.; Davison, J.; Shleifer, S.; von Platen, P.; Ma, C.; Jernite, Y .; Plu, J.; Xu, C.; Scao, T. L.; Gugger, S.; Drame, M.; Lhoest, Q.; and Rush, A. M. 2020. HuggingFace's Transformers: Stateof-the-art Natural Language Processing. arXiv:1910.03771.\", formatting=None, hyperlink=None), TextItem(self_ref='#/texts/284', parent=RefItem(cref='#/body'), children=[], content_layer=<ContentLayer.BODY: 'body'>, label=<DocItemLabel.TEXT: 'text'>, prov=[ProvenanceItem(page_no=8, bbox=BoundingBox(l=319.5, t=246.85199999999998, r=558.005, b=172.54700000000003, coord_origin=<CoordOrigin.BOTTOMLEFT: 'BOTTOMLEFT'>), charspan=(0, 388))], orig='Wood, D.; Lublinsky, B.; Roytman, A.; Singh, S.; Adam, C.; Adebayo, A.; An, S.; Chang, Y. C.; Dang, X.-H.; Desai, N.; Dolfi, M.; Emami-Gohari, H.; Eres, R.; Goto, T.; Joshi, D.; Koyfman, Y.; Nassar, M.; Patel, H.; Selvam, P.; Shah, Y.; Surendran, S.; Tsuzuku, D.; Zerfos, P.; and Daijavad, S. 2024. Data-Prep-Kit: getting your data ready for LLM application development. arXiv:2409.18164.', text='Wood, D.; Lublinsky, B.; Roytman, A.; Singh, S.; Adam, C.; Adebayo, A.; An, S.; Chang, Y. C.; Dang, X.-H.; Desai, N.; Dolfi, M.; Emami-Gohari, H.; Eres, R.; Goto, T.; Joshi, D.; Koyfman, Y.; Nassar, M.; Patel, H.; Selvam, P.; Shah, Y.; Surendran, S.; Tsuzuku, D.; Zerfos, P.; and Daijavad, S. 2024. Data-Prep-Kit: getting your data ready for LLM application development. arXiv:2409.18164.', formatting=None, hyperlink=None), TextItem(self_ref='#/texts/285', parent=RefItem(cref='#/body'), children=[], content_layer=<ContentLayer.BODY: 'body'>, label=<DocItemLabel.TEXT: 'text'>, prov=[ProvenanceItem(page_no=8, bbox=BoundingBox(l=319.5, t=167.649, r=558.005, b=137.17899999999997, coord_origin=<CoordOrigin.BOTTOMLEFT: 'BOTTOMLEFT'>), charspan=(0, 148))], orig='Zhao, Y.; Lv, W.; Xu, S.; Wei, J.; Wang, G.; Dang, Q.; Liu, Y.; and Chen, J. 2023. DETRs Beat YOLOs on Real-time Object Detection. arXiv:2304.08069.', text='Zhao, Y.; Lv, W.; Xu, S.; Wei, J.; Wang, G.; Dang, Q.; Liu, Y.; and Chen, J. 2023. DETRs Beat YOLOs on Real-time Object Detection. arXiv:2304.08069.', formatting=None, hyperlink=None), TextItem(self_ref='#/texts/286', parent=RefItem(cref='#/body'), children=[], content_layer=<ContentLayer.BODY: 'body'>, label=<DocItemLabel.TEXT: 'text'>, prov=[ProvenanceItem(page_no=8, bbox=BoundingBox(l=319.5, t=132.28200000000004, r=558.005, b=112.77099999999996, coord_origin=<CoordOrigin.BOTTOMLEFT: 'BOTTOMLEFT'>), charspan=(0, 93))], orig='Zhong, X. 2020. Image-based table recognition: data, model, and evaluation. arXiv:1911.10683.', text='Zhong, X. 2020. Image-based table recognition: data, model, and evaluation. arXiv:1911.10683.', formatting=None, hyperlink=None)], pictures=[PictureItem(self_ref='#/pictures/0', parent=RefItem(cref='#/body'), children=[RefItem(cref='#/texts/22'), RefItem(cref='#/texts/23'), RefItem(cref='#/texts/24'), RefItem(cref='#/texts/25'), RefItem(cref='#/texts/26'), RefItem(cref='#/texts/27'), RefItem(cref='#/texts/28'), RefItem(cref='#/texts/29'), RefItem(cref='#/texts/30'), RefItem(cref='#/texts/31'), RefItem(cref='#/texts/32'), RefItem(cref='#/texts/33'), RefItem(cref='#/texts/34'), RefItem(cref='#/texts/35'), RefItem(cref='#/texts/36'), RefItem(cref='#/texts/37'), RefItem(cref='#/texts/38'), RefItem(cref='#/texts/39'), RefItem(cref='#/texts/40'), RefItem(cref='#/texts/41'), RefItem(cref='#/texts/42'), RefItem(cref='#/texts/43'), RefItem(cref='#/texts/44'), RefItem(cref='#/texts/45'), RefItem(cref='#/texts/46'), RefItem(cref='#/texts/47'), RefItem(cref='#/texts/48'), RefItem(cref='#/texts/49'), RefItem(cref='#/texts/50'), RefItem(cref='#/texts/51'), RefItem(cref='#/texts/52'), RefItem(cref='#/texts/53'), RefItem(cref='#/texts/54'), RefItem(cref='#/texts/55'), RefItem(cref='#/texts/56'), RefItem(cref='#/texts/57'), RefItem(cref='#/texts/58'), RefItem(cref='#/texts/59'), RefItem(cref='#/texts/60'), RefItem(cref='#/texts/61'), RefItem(cref='#/texts/62'), RefItem(cref='#/texts/63')], content_layer=<ContentLayer.BODY: 'body'>, label=<DocItemLabel.PICTURE: 'picture'>, prov=[ProvenanceItem(page_no=2, bbox=BoundingBox(l=92.13404846191406, t=737.0841445922852, r=514.7477416992188, b=538.5709838867188, coord_origin=<CoordOrigin.BOTTOMLEFT: 'BOTTOMLEFT'>), charspan=(0, 0))], captions=[RefItem(cref='#/texts/22')], references=[], footnotes=[], image=None, annotations=[]), PictureItem(self_ref='#/pictures/1', parent=RefItem(cref='#/body'), children=[RefItem(cref='#/texts/113'), RefItem(cref='#/texts/114'), RefItem(cref='#/texts/115'), RefItem(cref='#/texts/116'), RefItem(cref='#/texts/117'), RefItem(cref='#/texts/118'), RefItem(cref='#/texts/119'), RefItem(cref='#/texts/120'), RefItem(cref='#/texts/121'), RefItem(cref='#/texts/122'), RefItem(cref='#/texts/123'), RefItem(cref='#/texts/124'), RefItem(cref='#/texts/125'), RefItem(cref='#/texts/126'), RefItem(cref='#/texts/127'), RefItem(cref='#/texts/128'), RefItem(cref='#/texts/129'), RefItem(cref='#/texts/130'), RefItem(cref='#/texts/131'), RefItem(cref='#/texts/132'), RefItem(cref='#/texts/133'), RefItem(cref='#/texts/134'), RefItem(cref='#/texts/135'), RefItem(cref='#/texts/136'), RefItem(cref='#/texts/137'), RefItem(cref='#/texts/138'), RefItem(cref='#/texts/139'), RefItem(cref='#/texts/140'), RefItem(cref='#/texts/141'), RefItem(cref='#/texts/142'), RefItem(cref='#/texts/143'), RefItem(cref='#/texts/144'), RefItem(cref='#/texts/145'), RefItem(cref='#/texts/146'), RefItem(cref='#/texts/147'), RefItem(cref='#/texts/148'), RefItem(cref='#/texts/149'), RefItem(cref='#/texts/150'), RefItem(cref='#/texts/151')], content_layer=<ContentLayer.BODY: 'body'>, label=<DocItemLabel.PICTURE: 'picture'>, prov=[ProvenanceItem(page_no=5, bbox=BoundingBox(l=71.60702514648438, t=615.9085083007812, r=278.9543151855469, b=326.2925720214844, coord_origin=<CoordOrigin.BOTTOMLEFT: 'BOTTOMLEFT'>), charspan=(0, 0))], captions=[RefItem(cref='#/texts/113')], references=[], footnotes=[], image=None, annotations=[]), PictureItem(self_ref='#/pictures/2', parent=RefItem(cref='#/body'), children=[RefItem(cref='#/texts/159'), RefItem(cref='#/texts/160'), RefItem(cref='#/texts/161'), RefItem(cref='#/texts/162'), RefItem(cref='#/texts/163'), RefItem(cref='#/texts/164'), RefItem(cref='#/texts/165'), RefItem(cref='#/texts/166'), RefItem(cref='#/texts/167'), RefItem(cref='#/texts/168'), RefItem(cref='#/texts/169'), RefItem(cref='#/texts/170'), RefItem(cref='#/texts/171')], content_layer=<ContentLayer.BODY: 'body'>, label=<DocItemLabel.PICTURE: 'picture'>, prov=[ProvenanceItem(page_no=5, bbox=BoundingBox(l=356.2509460449219, t=509.60369873046875, r=521.4921264648438, b=343.9695739746094, coord_origin=<CoordOrigin.BOTTOMLEFT: 'BOTTOMLEFT'>), charspan=(0, 0))], captions=[RefItem(cref='#/texts/159')], references=[], footnotes=[], image=None, annotations=[]), PictureItem(self_ref='#/pictures/3', parent=RefItem(cref='#/body'), children=[RefItem(cref='#/texts/189'), RefItem(cref='#/texts/190'), RefItem(cref='#/texts/191'), RefItem(cref='#/texts/192'), RefItem(cref='#/texts/193'), RefItem(cref='#/texts/194'), RefItem(cref='#/texts/195'), RefItem(cref='#/texts/196'), RefItem(cref='#/texts/197'), RefItem(cref='#/texts/198'), RefItem(cref='#/texts/199'), RefItem(cref='#/texts/200'), RefItem(cref='#/texts/201'), RefItem(cref='#/texts/202'), RefItem(cref='#/texts/203'), RefItem(cref='#/texts/204'), RefItem(cref='#/texts/205'), RefItem(cref='#/texts/206'), RefItem(cref='#/texts/207'), RefItem(cref='#/texts/208'), RefItem(cref='#/texts/209'), RefItem(cref='#/texts/210'), RefItem(cref='#/texts/211'), RefItem(cref='#/texts/212'), RefItem(cref='#/texts/213'), RefItem(cref='#/texts/214'), RefItem(cref='#/texts/215'), RefItem(cref='#/texts/216'), RefItem(cref='#/texts/217')], content_layer=<ContentLayer.BODY: 'body'>, label=<DocItemLabel.PICTURE: 'picture'>, prov=[ProvenanceItem(page_no=7, bbox=BoundingBox(l=105.40738677978516, t=738.2883567810059, r=506.916748046875, b=540.9850769042969, coord_origin=<CoordOrigin.BOTTOMLEFT: 'BOTTOMLEFT'>), charspan=(0, 0))], captions=[RefItem(cref='#/texts/189')], references=[], footnotes=[], image=None, annotations=[]), PictureItem(self_ref='#/pictures/4', parent=RefItem(cref='#/body'), children=[RefItem(cref='#/texts/218'), RefItem(cref='#/texts/219'), RefItem(cref='#/texts/220'), RefItem(cref='#/texts/221'), RefItem(cref='#/texts/222'), RefItem(cref='#/texts/223'), RefItem(cref='#/texts/224'), RefItem(cref='#/texts/225'), RefItem(cref='#/texts/226'), RefItem(cref='#/texts/227'), RefItem(cref='#/texts/228'), RefItem(cref='#/texts/229'), RefItem(cref='#/texts/230'), RefItem(cref='#/texts/231'), RefItem(cref='#/texts/232'), RefItem(cref='#/texts/233'), RefItem(cref='#/texts/234'), RefItem(cref='#/texts/235')], content_layer=<ContentLayer.BODY: 'body'>, label=<DocItemLabel.PICTURE: 'picture'>, prov=[ProvenanceItem(page_no=7, bbox=BoundingBox(l=79.11772155761719, t=462.92974853515625, r=268.16009521484375, b=275.2188720703125, coord_origin=<CoordOrigin.BOTTOMLEFT: 'BOTTOMLEFT'>), charspan=(0, 0))], captions=[RefItem(cref='#/texts/218')], references=[], footnotes=[], image=None, annotations=[]), PictureItem(self_ref='#/pictures/5', parent=RefItem(cref='#/body'), children=[RefItem(cref='#/texts/238'), RefItem(cref='#/texts/239'), RefItem(cref='#/texts/240'), RefItem(cref='#/texts/241'), RefItem(cref='#/texts/242'), RefItem(cref='#/texts/243'), RefItem(cref='#/texts/244'), RefItem(cref='#/texts/245'), RefItem(cref='#/texts/246'), RefItem(cref='#/texts/247'), RefItem(cref='#/texts/248'), RefItem(cref='#/texts/249'), RefItem(cref='#/texts/250'), RefItem(cref='#/texts/251'), RefItem(cref='#/texts/252')], content_layer=<ContentLayer.BODY: 'body'>, label=<DocItemLabel.PICTURE: 'picture'>, prov=[ProvenanceItem(page_no=7, bbox=BoundingBox(l=322.7547912597656, t=460.4932861328125, r=553.9041137695312, b=361.5787353515625, coord_origin=<CoordOrigin.BOTTOMLEFT: 'BOTTOMLEFT'>), charspan=(0, 0))], captions=[RefItem(cref='#/texts/238')], references=[], footnotes=[], image=None, annotations=[])], tables=[TableItem(self_ref='#/tables/0', parent=RefItem(cref='#/body'), children=[RefItem(cref='#/texts/112')], content_layer=<ContentLayer.BODY: 'body'>, label=<DocItemLabel.TABLE: 'table'>, prov=[ProvenanceItem(page_no=5, bbox=BoundingBox(l=155.46766662597656, t=717.3967056274414, r=456.41375732421875, b=637.3744354248047, coord_origin=<CoordOrigin.BOTTOMLEFT: 'BOTTOMLEFT'>), charspan=(0, 0))], captions=[RefItem(cref='#/texts/112')], references=[], footnotes=[], image=None, data=TableData(table_cells=[TableCell(bbox=BoundingBox(l=188.384, t=79.99400000000003, r=208.8, b=88.05499999999995, coord_origin=<CoordOrigin.TOPLEFT: 'TOPLEFT'>), row_span=1, col_span=1, start_row_offset_idx=0, end_row_offset_idx=1, start_col_offset_idx=0, end_col_offset_idx=1, text='Asset', column_header=True, row_header=False, row_section=False, fillable=False), TableCell(bbox=BoundingBox(l=220.753, t=79.99400000000003, r=249.741, b=88.05499999999995, coord_origin=<CoordOrigin.TOPLEFT: 'TOPLEFT'>), row_span=1, col_span=1, start_row_offset_idx=0, end_row_offset_idx=1, start_col_offset_idx=1, end_col_offset_idx=2, text='Version', column_header=True, row_header=False, row_section=False, fillable=False), TableCell(bbox=BoundingBox(l=261.702, t=79.99400000000003, r=281.626, b=88.05499999999995, coord_origin=<CoordOrigin.TOPLEFT: 'TOPLEFT'>), row_span=1, col_span=1, start_row_offset_idx=0, end_row_offset_idx=1, start_col_offset_idx=2, end_col_offset_idx=3, text='OCR', column_header=True, row_header=False, row_section=False, fillable=False), TableCell(bbox=BoundingBox(l=313.008, t=79.99400000000003, r=340.185, b=88.05499999999995, coord_origin=<CoordOrigin.TOPLEFT: 'TOPLEFT'>), row_span=1, col_span=1, start_row_offset_idx=0, end_row_offset_idx=1, start_col_offset_idx=3, end_col_offset_idx=4, text='Layout', column_header=True, row_header=False, row_section=False, fillable=False), TableCell(bbox=BoundingBox(l=379.494, t=79.99400000000003, r=404.08, b=88.05499999999995, coord_origin=<CoordOrigin.TOPLEFT: 'TOPLEFT'>), row_span=1, col_span=1, start_row_offset_idx=0, end_row_offset_idx=1, start_col_offset_idx=4, end_col_offset_idx=5, text='Tables', column_header=True, row_header=False, row_section=False, fillable=False), TableCell(bbox=BoundingBox(l=179.911, t=96.22000000000003, r=208.801, b=103.91700000000003, coord_origin=<CoordOrigin.TOPLEFT: 'TOPLEFT'>), row_span=1, col_span=1, start_row_offset_idx=1, end_row_offset_idx=2, start_col_offset_idx=0, end_col_offset_idx=1, text='Docling', column_header=False, row_header=False, row_section=False, fillable=False), TableCell(bbox=BoundingBox(l=220.753, t=96.22000000000003, r=238.686, b=103.91700000000003, coord_origin=<CoordOrigin.TOPLEFT: 'TOPLEFT'>), row_span=1, col_span=1, start_row_offset_idx=1, end_row_offset_idx=2, start_col_offset_idx=1, end_col_offset_idx=2, text='2.5.2', column_header=False, row_header=False, row_section=False, fillable=False), TableCell(bbox=BoundingBox(l=261.703, t=94.35699999999997, r=300.553, b=103.91700000000003, coord_origin=<CoordOrigin.TOPLEFT: 'TOPLEFT'>), row_span=1, col_span=1, start_row_offset_idx=1, end_row_offset_idx=2, start_col_offset_idx=2, end_col_offset_idx=3, text='EasyOCR *', column_header=False, row_header=False, row_section=False, fillable=False), TableCell(bbox=BoundingBox(l=313.006, t=96.22000000000003, r=337.816, b=103.91700000000003, coord_origin=<CoordOrigin.TOPLEFT: 'TOPLEFT'>), row_span=1, col_span=1, start_row_offset_idx=1, end_row_offset_idx=2, start_col_offset_idx=3, end_col_offset_idx=4, text='default', column_header=False, row_header=False, row_section=False, fillable=False), TableCell(bbox=BoundingBox(l=379.492, t=94.35699999999997, r=449.515, b=103.91700000000003, coord_origin=<CoordOrigin.TOPLEFT: 'TOPLEFT'>), row_span=1, col_span=1, start_row_offset_idx=1, end_row_offset_idx=2, start_col_offset_idx=4, end_col_offset_idx=5, text='TableFormer (fast) *', column_header=False, row_header=False, row_section=False, fillable=False), TableCell(bbox=BoundingBox(l=182.502, t=112.09699999999998, r=208.8, b=119.79399999999998, coord_origin=<CoordOrigin.TOPLEFT: 'TOPLEFT'>), row_span=1, col_span=1, start_row_offset_idx=2, end_row_offset_idx=3, start_col_offset_idx=0, end_col_offset_idx=1, text='Marker', column_header=False, row_header=False, row_section=False, fillable=False), TableCell(bbox=BoundingBox(l=220.753, t=112.09699999999998, r=243.169, b=119.79399999999998, coord_origin=<CoordOrigin.TOPLEFT: 'TOPLEFT'>), row_span=1, col_span=1, start_row_offset_idx=2, end_row_offset_idx=3, start_col_offset_idx=1, end_col_offset_idx=2, text='0.3.10', column_header=False, row_header=False, row_section=False, fillable=False), TableCell(bbox=BoundingBox(l=261.702, t=110.23400000000004, r=285.606, b=119.79399999999998, coord_origin=<CoordOrigin.TOPLEFT: 'TOPLEFT'>), row_span=1, col_span=1, start_row_offset_idx=2, end_row_offset_idx=3, start_col_offset_idx=2, end_col_offset_idx=3, text='Surya *', column_header=False, row_header=False, row_section=False, fillable=False), TableCell(bbox=BoundingBox(l=313.006, t=112.09699999999998, r=337.816, b=119.79399999999998, coord_origin=<CoordOrigin.TOPLEFT: 'TOPLEFT'>), row_span=1, col_span=1, start_row_offset_idx=2, end_row_offset_idx=3, start_col_offset_idx=3, end_col_offset_idx=4, text='default', column_header=False, row_header=False, row_section=False, fillable=False), TableCell(bbox=BoundingBox(l=379.492, t=112.09699999999998, r=404.302, b=119.79399999999998, coord_origin=<CoordOrigin.TOPLEFT: 'TOPLEFT'>), row_span=1, col_span=1, start_row_offset_idx=2, end_row_offset_idx=3, start_col_offset_idx=4, end_col_offset_idx=5, text='default', column_header=False, row_header=False, row_section=False, fillable=False), TableCell(bbox=BoundingBox(l=180.413, t=127.97299999999996, r=208.801, b=135.66999999999996, coord_origin=<CoordOrigin.TOPLEFT: 'TOPLEFT'>), row_span=1, col_span=1, start_row_offset_idx=3, end_row_offset_idx=4, start_col_offset_idx=0, end_col_offset_idx=1, text='MinerU', column_header=False, row_header=False, row_section=False, fillable=False), TableCell(bbox=BoundingBox(l=220.753, t=127.97299999999996, r=238.686, b=135.66999999999996, coord_origin=<CoordOrigin.TOPLEFT: 'TOPLEFT'>), row_span=1, col_span=1, start_row_offset_idx=3, end_row_offset_idx=4, start_col_offset_idx=1, end_col_offset_idx=2, text='0.9.3', column_header=False, row_header=False, row_section=False, fillable=False), TableCell(bbox=BoundingBox(l=261.702, t=126.11000000000001, r=280.127, b=135.66999999999996, coord_origin=<CoordOrigin.TOPLEFT: 'TOPLEFT'>), row_span=1, col_span=1, start_row_offset_idx=3, end_row_offset_idx=4, start_col_offset_idx=2, end_col_offset_idx=3, text='auto *', column_header=False, row_header=False, row_section=False, fillable=False), TableCell(bbox=BoundingBox(l=313.006, t=127.97299999999996, r=367.539, b=135.66999999999996, coord_origin=<CoordOrigin.TOPLEFT: 'TOPLEFT'>), row_span=1, col_span=1, start_row_offset_idx=3, end_row_offset_idx=4, start_col_offset_idx=3, end_col_offset_idx=4, text='doclayout yolo', column_header=False, row_header=False, row_section=False, fillable=False), TableCell(bbox=BoundingBox(l=379.491, t=126.11000000000001, r=421.567, b=135.66999999999996, coord_origin=<CoordOrigin.TOPLEFT: 'TOPLEFT'>), row_span=1, col_span=1, start_row_offset_idx=3, end_row_offset_idx=4, start_col_offset_idx=4, end_col_offset_idx=5, text='rapid table *', column_header=False, row_header=False, row_section=False, fillable=False), TableCell(bbox=BoundingBox(l=161.987, t=142.938, r=208.801, b=150.635, coord_origin=<CoordOrigin.TOPLEFT: 'TOPLEFT'>), row_span=1, col_span=1, start_row_offset_idx=4, end_row_offset_idx=5, start_col_offset_idx=0, end_col_offset_idx=1, text='Unstructured', column_header=False, row_header=False, row_section=False, fillable=False), TableCell(bbox=BoundingBox(l=220.753, t=142.938, r=243.169, b=150.635, coord_origin=<CoordOrigin.TOPLEFT: 'TOPLEFT'>), row_span=1, col_span=1, start_row_offset_idx=4, end_row_offset_idx=5, start_col_offset_idx=1, end_col_offset_idx=2, text='0.16.5', column_header=False, row_header=False, row_section=False, fillable=False), TableCell(bbox=BoundingBox(l=305.057, t=142.938, r=406.656, b=150.635, coord_origin=<CoordOrigin.TOPLEFT: 'TOPLEFT'>), row_span=1, col_span=2, start_row_offset_idx=4, end_row_offset_idx=5, start_col_offset_idx=3, end_col_offset_idx=5, text='hi res with table structure', column_header=False, row_header=False, row_section=False, fillable=False)], num_rows=5, num_cols=5, grid=[[TableCell(bbox=BoundingBox(l=188.384, t=79.99400000000003, r=208.8, b=88.05499999999995, coord_origin=<CoordOrigin.TOPLEFT: 'TOPLEFT'>), row_span=1, col_span=1, start_row_offset_idx=0, end_row_offset_idx=1, start_col_offset_idx=0, end_col_offset_idx=1, text='Asset', column_header=True, row_header=False, row_section=False, fillable=False), TableCell(bbox=BoundingBox(l=220.753, t=79.99400000000003, r=249.741, b=88.05499999999995, coord_origin=<CoordOrigin.TOPLEFT: 'TOPLEFT'>), row_span=1, col_span=1, start_row_offset_idx=0, end_row_offset_idx=1, start_col_offset_idx=1, end_col_offset_idx=2, text='Version', column_header=True, row_header=False, row_section=False, fillable=False), TableCell(bbox=BoundingBox(l=261.702, t=79.99400000000003, r=281.626, b=88.05499999999995, coord_origin=<CoordOrigin.TOPLEFT: 'TOPLEFT'>), row_span=1, col_span=1, start_row_offset_idx=0, end_row_offset_idx=1, start_col_offset_idx=2, end_col_offset_idx=3, text='OCR', column_header=True, row_header=False, row_section=False, fillable=False), TableCell(bbox=BoundingBox(l=313.008, t=79.99400000000003, r=340.185, b=88.05499999999995, coord_origin=<CoordOrigin.TOPLEFT: 'TOPLEFT'>), row_span=1, col_span=1, start_row_offset_idx=0, end_row_offset_idx=1, start_col_offset_idx=3, end_col_offset_idx=4, text='Layout', column_header=True, row_header=False, row_section=False, fillable=False), TableCell(bbox=BoundingBox(l=379.494, t=79.99400000000003, r=404.08, b=88.05499999999995, coord_origin=<CoordOrigin.TOPLEFT: 'TOPLEFT'>), row_span=1, col_span=1, start_row_offset_idx=0, end_row_offset_idx=1, start_col_offset_idx=4, end_col_offset_idx=5, text='Tables', column_header=True, row_header=False, row_section=False, fillable=False)], [TableCell(bbox=BoundingBox(l=179.911, t=96.22000000000003, r=208.801, b=103.91700000000003, coord_origin=<CoordOrigin.TOPLEFT: 'TOPLEFT'>), row_span=1, col_span=1, start_row_offset_idx=1, end_row_offset_idx=2, start_col_offset_idx=0, end_col_offset_idx=1, text='Docling', column_header=False, row_header=False, row_section=False, fillable=False), TableCell(bbox=BoundingBox(l=220.753, t=96.22000000000003, r=238.686, b=103.91700000000003, coord_origin=<CoordOrigin.TOPLEFT: 'TOPLEFT'>), row_span=1, col_span=1, start_row_offset_idx=1, end_row_offset_idx=2, start_col_offset_idx=1, end_col_offset_idx=2, text='2.5.2', column_header=False, row_header=False, row_section=False, fillable=False), TableCell(bbox=BoundingBox(l=261.703, t=94.35699999999997, r=300.553, b=103.91700000000003, coord_origin=<CoordOrigin.TOPLEFT: 'TOPLEFT'>), row_span=1, col_span=1, start_row_offset_idx=1, end_row_offset_idx=2, start_col_offset_idx=2, end_col_offset_idx=3, text='EasyOCR *', column_header=False, row_header=False, row_section=False, fillable=False), TableCell(bbox=BoundingBox(l=313.006, t=96.22000000000003, r=337.816, b=103.91700000000003, coord_origin=<CoordOrigin.TOPLEFT: 'TOPLEFT'>), row_span=1, col_span=1, start_row_offset_idx=1, end_row_offset_idx=2, start_col_offset_idx=3, end_col_offset_idx=4, text='default', column_header=False, row_header=False, row_section=False, fillable=False), TableCell(bbox=BoundingBox(l=379.492, t=94.35699999999997, r=449.515, b=103.91700000000003, coord_origin=<CoordOrigin.TOPLEFT: 'TOPLEFT'>), row_span=1, col_span=1, start_row_offset_idx=1, end_row_offset_idx=2, start_col_offset_idx=4, end_col_offset_idx=5, text='TableFormer (fast) *', column_header=False, row_header=False, row_section=False, fillable=False)], [TableCell(bbox=BoundingBox(l=182.502, t=112.09699999999998, r=208.8, b=119.79399999999998, coord_origin=<CoordOrigin.TOPLEFT: 'TOPLEFT'>), row_span=1, col_span=1, start_row_offset_idx=2, end_row_offset_idx=3, start_col_offset_idx=0, end_col_offset_idx=1, text='Marker', column_header=False, row_header=False, row_section=False, fillable=False), TableCell(bbox=BoundingBox(l=220.753, t=112.09699999999998, r=243.169, b=119.79399999999998, coord_origin=<CoordOrigin.TOPLEFT: 'TOPLEFT'>), row_span=1, col_span=1, start_row_offset_idx=2, end_row_offset_idx=3, start_col_offset_idx=1, end_col_offset_idx=2, text='0.3.10', column_header=False, row_header=False, row_section=False, fillable=False), TableCell(bbox=BoundingBox(l=261.702, t=110.23400000000004, r=285.606, b=119.79399999999998, coord_origin=<CoordOrigin.TOPLEFT: 'TOPLEFT'>), row_span=1, col_span=1, start_row_offset_idx=2, end_row_offset_idx=3, start_col_offset_idx=2, end_col_offset_idx=3, text='Surya *', column_header=False, row_header=False, row_section=False, fillable=False), TableCell(bbox=BoundingBox(l=313.006, t=112.09699999999998, r=337.816, b=119.79399999999998, coord_origin=<CoordOrigin.TOPLEFT: 'TOPLEFT'>), row_span=1, col_span=1, start_row_offset_idx=2, end_row_offset_idx=3, start_col_offset_idx=3, end_col_offset_idx=4, text='default', column_header=False, row_header=False, row_section=False, fillable=False), TableCell(bbox=BoundingBox(l=379.492, t=112.09699999999998, r=404.302, b=119.79399999999998, coord_origin=<CoordOrigin.TOPLEFT: 'TOPLEFT'>), row_span=1, col_span=1, start_row_offset_idx=2, end_row_offset_idx=3, start_col_offset_idx=4, end_col_offset_idx=5, text='default', column_header=False, row_header=False, row_section=False, fillable=False)], [TableCell(bbox=BoundingBox(l=180.413, t=127.97299999999996, r=208.801, b=135.66999999999996, coord_origin=<CoordOrigin.TOPLEFT: 'TOPLEFT'>), row_span=1, col_span=1, start_row_offset_idx=3, end_row_offset_idx=4, start_col_offset_idx=0, end_col_offset_idx=1, text='MinerU', column_header=False, row_header=False, row_section=False, fillable=False), TableCell(bbox=BoundingBox(l=220.753, t=127.97299999999996, r=238.686, b=135.66999999999996, coord_origin=<CoordOrigin.TOPLEFT: 'TOPLEFT'>), row_span=1, col_span=1, start_row_offset_idx=3, end_row_offset_idx=4, start_col_offset_idx=1, end_col_offset_idx=2, text='0.9.3', column_header=False, row_header=False, row_section=False, fillable=False), TableCell(bbox=BoundingBox(l=261.702, t=126.11000000000001, r=280.127, b=135.66999999999996, coord_origin=<CoordOrigin.TOPLEFT: 'TOPLEFT'>), row_span=1, col_span=1, start_row_offset_idx=3, end_row_offset_idx=4, start_col_offset_idx=2, end_col_offset_idx=3, text='auto *', column_header=False, row_header=False, row_section=False, fillable=False), TableCell(bbox=BoundingBox(l=313.006, t=127.97299999999996, r=367.539, b=135.66999999999996, coord_origin=<CoordOrigin.TOPLEFT: 'TOPLEFT'>), row_span=1, col_span=1, start_row_offset_idx=3, end_row_offset_idx=4, start_col_offset_idx=3, end_col_offset_idx=4, text='doclayout yolo', column_header=False, row_header=False, row_section=False, fillable=False), TableCell(bbox=BoundingBox(l=379.491, t=126.11000000000001, r=421.567, b=135.66999999999996, coord_origin=<CoordOrigin.TOPLEFT: 'TOPLEFT'>), row_span=1, col_span=1, start_row_offset_idx=3, end_row_offset_idx=4, start_col_offset_idx=4, end_col_offset_idx=5, text='rapid table *', column_header=False, row_header=False, row_section=False, fillable=False)], [TableCell(bbox=BoundingBox(l=161.987, t=142.938, r=208.801, b=150.635, coord_origin=<CoordOrigin.TOPLEFT: 'TOPLEFT'>), row_span=1, col_span=1, start_row_offset_idx=4, end_row_offset_idx=5, start_col_offset_idx=0, end_col_offset_idx=1, text='Unstructured', column_header=False, row_header=False, row_section=False, fillable=False), TableCell(bbox=BoundingBox(l=220.753, t=142.938, r=243.169, b=150.635, coord_origin=<CoordOrigin.TOPLEFT: 'TOPLEFT'>), row_span=1, col_span=1, start_row_offset_idx=4, end_row_offset_idx=5, start_col_offset_idx=1, end_col_offset_idx=2, text='0.16.5', column_header=False, row_header=False, row_section=False, fillable=False), TableCell(bbox=None, row_span=1, col_span=1, start_row_offset_idx=4, end_row_offset_idx=5, start_col_offset_idx=2, end_col_offset_idx=3, text='', column_header=False, row_header=False, row_section=False, fillable=False), TableCell(bbox=BoundingBox(l=305.057, t=142.938, r=406.656, b=150.635, coord_origin=<CoordOrigin.TOPLEFT: 'TOPLEFT'>), row_span=1, col_span=2, start_row_offset_idx=4, end_row_offset_idx=5, start_col_offset_idx=3, end_col_offset_idx=5, text='hi res with table structure', column_header=False, row_header=False, row_section=False, fillable=False), TableCell(bbox=BoundingBox(l=305.057, t=142.938, r=406.656, b=150.635, coord_origin=<CoordOrigin.TOPLEFT: 'TOPLEFT'>), row_span=1, col_span=2, start_row_offset_idx=4, end_row_offset_idx=5, start_col_offset_idx=3, end_col_offset_idx=5, text='hi res with table structure', column_header=False, row_header=False, row_section=False, fillable=False)]]), annotations=[])], key_value_items=[], form_items=[], pages={1: PageItem(size=Size(width=612.0, height=792.0), image=None, page_no=1), 2: PageItem(size=Size(width=612.0, height=792.0), image=None, page_no=2), 3: PageItem(size=Size(width=612.0, height=792.0), image=None, page_no=3), 4: PageItem(size=Size(width=612.0, height=792.0), image=None, page_no=4), 5: PageItem(size=Size(width=612.0, height=792.0), image=None, page_no=5), 6: PageItem(size=Size(width=612.0, height=792.0), image=None, page_no=6), 7: PageItem(size=Size(width=612.0, height=792.0), image=None, page_no=7), 8: PageItem(size=Size(width=612.0, height=792.0), image=None, page_no=8)})>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Export methods of the DoclingDocument"
      ],
      "metadata": {
        "id": "Gp0-JWPanU5J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(doc.export_to_dict())\n",
        "# print(doc.export_to_html())\n",
        "# print(doc.export_to_doctags())\n",
        "# print(doc.export_to_markdown())"
      ],
      "metadata": {
        "id": "MtgNBISycD6a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "61273929-e91c-458f-db18-bee9f72047cb",
        "collapsed": true
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "{'schema_name': 'DoclingDocument',\n",
              " 'version': '1.7.0',\n",
              " 'name': '2501.17887v1',\n",
              " 'origin': {'mimetype': 'application/pdf',\n",
              "  'binary_hash': 1554916940463874186,\n",
              "  'filename': '2501.17887v1.pdf'},\n",
              " 'furniture': {'self_ref': '#/furniture',\n",
              "  'children': [],\n",
              "  'content_layer': 'furniture',\n",
              "  'name': '_root_',\n",
              "  'label': 'unspecified'},\n",
              " 'body': {'self_ref': '#/body',\n",
              "  'children': [{'$ref': '#/texts/0'},\n",
              "   {'$ref': '#/texts/1'},\n",
              "   {'$ref': '#/texts/2'},\n",
              "   {'$ref': '#/texts/3'},\n",
              "   {'$ref': '#/texts/4'},\n",
              "   {'$ref': '#/texts/5'},\n",
              "   {'$ref': '#/texts/6'},\n",
              "   {'$ref': '#/texts/7'},\n",
              "   {'$ref': '#/texts/8'},\n",
              "   {'$ref': '#/texts/9'},\n",
              "   {'$ref': '#/texts/10'},\n",
              "   {'$ref': '#/texts/11'},\n",
              "   {'$ref': '#/texts/12'},\n",
              "   {'$ref': '#/texts/13'},\n",
              "   {'$ref': '#/groups/0'},\n",
              "   {'$ref': '#/texts/20'},\n",
              "   {'$ref': '#/texts/21'},\n",
              "   {'$ref': '#/pictures/0'},\n",
              "   {'$ref': '#/texts/64'},\n",
              "   {'$ref': '#/texts/65'},\n",
              "   {'$ref': '#/texts/66'},\n",
              "   {'$ref': '#/texts/67'},\n",
              "   {'$ref': '#/texts/68'},\n",
              "   {'$ref': '#/texts/69'},\n",
              "   {'$ref': '#/texts/70'},\n",
              "   {'$ref': '#/texts/71'},\n",
              "   {'$ref': '#/texts/72'},\n",
              "   {'$ref': '#/groups/1'},\n",
              "   {'$ref': '#/texts/78'},\n",
              "   {'$ref': '#/texts/79'},\n",
              "   {'$ref': '#/texts/80'},\n",
              "   {'$ref': '#/texts/81'},\n",
              "   {'$ref': '#/texts/82'},\n",
              "   {'$ref': '#/groups/2'},\n",
              "   {'$ref': '#/texts/85'},\n",
              "   {'$ref': '#/texts/86'},\n",
              "   {'$ref': '#/texts/87'},\n",
              "   {'$ref': '#/texts/88'},\n",
              "   {'$ref': '#/texts/89'},\n",
              "   {'$ref': '#/texts/90'},\n",
              "   {'$ref': '#/texts/91'},\n",
              "   {'$ref': '#/texts/92'},\n",
              "   {'$ref': '#/texts/93'},\n",
              "   {'$ref': '#/texts/94'},\n",
              "   {'$ref': '#/texts/95'},\n",
              "   {'$ref': '#/texts/96'},\n",
              "   {'$ref': '#/texts/97'},\n",
              "   {'$ref': '#/texts/98'},\n",
              "   {'$ref': '#/texts/99'},\n",
              "   {'$ref': '#/texts/100'},\n",
              "   {'$ref': '#/texts/101'},\n",
              "   {'$ref': '#/texts/102'},\n",
              "   {'$ref': '#/texts/103'},\n",
              "   {'$ref': '#/texts/104'},\n",
              "   {'$ref': '#/texts/105'},\n",
              "   {'$ref': '#/texts/106'},\n",
              "   {'$ref': '#/texts/107'},\n",
              "   {'$ref': '#/texts/108'},\n",
              "   {'$ref': '#/groups/3'},\n",
              "   {'$ref': '#/texts/111'},\n",
              "   {'$ref': '#/tables/0'},\n",
              "   {'$ref': '#/pictures/1'},\n",
              "   {'$ref': '#/texts/152'},\n",
              "   {'$ref': '#/texts/153'},\n",
              "   {'$ref': '#/groups/4'},\n",
              "   {'$ref': '#/texts/157'},\n",
              "   {'$ref': '#/texts/158'},\n",
              "   {'$ref': '#/pictures/2'},\n",
              "   {'$ref': '#/texts/172'},\n",
              "   {'$ref': '#/texts/173'},\n",
              "   {'$ref': '#/texts/174'},\n",
              "   {'$ref': '#/texts/175'},\n",
              "   {'$ref': '#/texts/176'},\n",
              "   {'$ref': '#/texts/177'},\n",
              "   {'$ref': '#/texts/178'},\n",
              "   {'$ref': '#/texts/179'},\n",
              "   {'$ref': '#/texts/180'},\n",
              "   {'$ref': '#/texts/181'},\n",
              "   {'$ref': '#/texts/182'},\n",
              "   {'$ref': '#/texts/183'},\n",
              "   {'$ref': '#/texts/184'},\n",
              "   {'$ref': '#/texts/185'},\n",
              "   {'$ref': '#/texts/186'},\n",
              "   {'$ref': '#/texts/187'},\n",
              "   {'$ref': '#/texts/188'},\n",
              "   {'$ref': '#/pictures/3'},\n",
              "   {'$ref': '#/pictures/4'},\n",
              "   {'$ref': '#/texts/236'},\n",
              "   {'$ref': '#/texts/237'},\n",
              "   {'$ref': '#/pictures/5'},\n",
              "   {'$ref': '#/texts/253'},\n",
              "   {'$ref': '#/texts/254'},\n",
              "   {'$ref': '#/texts/255'},\n",
              "   {'$ref': '#/texts/256'},\n",
              "   {'$ref': '#/texts/257'},\n",
              "   {'$ref': '#/texts/258'},\n",
              "   {'$ref': '#/texts/259'},\n",
              "   {'$ref': '#/texts/260'},\n",
              "   {'$ref': '#/texts/261'},\n",
              "   {'$ref': '#/texts/262'},\n",
              "   {'$ref': '#/texts/263'},\n",
              "   {'$ref': '#/texts/264'},\n",
              "   {'$ref': '#/texts/265'},\n",
              "   {'$ref': '#/texts/266'},\n",
              "   {'$ref': '#/texts/267'},\n",
              "   {'$ref': '#/texts/268'},\n",
              "   {'$ref': '#/texts/269'},\n",
              "   {'$ref': '#/texts/270'},\n",
              "   {'$ref': '#/texts/271'},\n",
              "   {'$ref': '#/texts/272'},\n",
              "   {'$ref': '#/texts/273'},\n",
              "   {'$ref': '#/texts/274'},\n",
              "   {'$ref': '#/texts/275'},\n",
              "   {'$ref': '#/texts/276'},\n",
              "   {'$ref': '#/texts/277'},\n",
              "   {'$ref': '#/texts/278'},\n",
              "   {'$ref': '#/texts/279'},\n",
              "   {'$ref': '#/texts/280'},\n",
              "   {'$ref': '#/texts/281'},\n",
              "   {'$ref': '#/texts/282'},\n",
              "   {'$ref': '#/texts/283'},\n",
              "   {'$ref': '#/texts/284'},\n",
              "   {'$ref': '#/texts/285'},\n",
              "   {'$ref': '#/texts/286'}],\n",
              "  'content_layer': 'body',\n",
              "  'name': '_root_',\n",
              "  'label': 'unspecified'},\n",
              " 'groups': [{'self_ref': '#/groups/0',\n",
              "   'parent': {'$ref': '#/body'},\n",
              "   'children': [{'$ref': '#/texts/14'},\n",
              "    {'$ref': '#/texts/15'},\n",
              "    {'$ref': '#/texts/16'},\n",
              "    {'$ref': '#/texts/17'},\n",
              "    {'$ref': '#/texts/18'},\n",
              "    {'$ref': '#/texts/19'}],\n",
              "   'content_layer': 'body',\n",
              "   'name': 'list',\n",
              "   'label': 'list'},\n",
              "  {'self_ref': '#/groups/1',\n",
              "   'parent': {'$ref': '#/body'},\n",
              "   'children': [{'$ref': '#/texts/73'},\n",
              "    {'$ref': '#/texts/74'},\n",
              "    {'$ref': '#/texts/75'},\n",
              "    {'$ref': '#/texts/76'},\n",
              "    {'$ref': '#/texts/77'}],\n",
              "   'content_layer': 'body',\n",
              "   'name': 'list',\n",
              "   'label': 'list'},\n",
              "  {'self_ref': '#/groups/2',\n",
              "   'parent': {'$ref': '#/body'},\n",
              "   'children': [{'$ref': '#/texts/83'}, {'$ref': '#/texts/84'}],\n",
              "   'content_layer': 'body',\n",
              "   'name': 'list',\n",
              "   'label': 'list'},\n",
              "  {'self_ref': '#/groups/3',\n",
              "   'parent': {'$ref': '#/body'},\n",
              "   'children': [{'$ref': '#/texts/109'}, {'$ref': '#/texts/110'}],\n",
              "   'content_layer': 'body',\n",
              "   'name': 'list',\n",
              "   'label': 'list'},\n",
              "  {'self_ref': '#/groups/4',\n",
              "   'parent': {'$ref': '#/body'},\n",
              "   'children': [{'$ref': '#/texts/154'},\n",
              "    {'$ref': '#/texts/155'},\n",
              "    {'$ref': '#/texts/156'}],\n",
              "   'content_layer': 'body',\n",
              "   'name': 'list',\n",
              "   'label': 'list'}],\n",
              " 'texts': [{'self_ref': '#/texts/0',\n",
              "   'parent': {'$ref': '#/body'},\n",
              "   'children': [],\n",
              "   'content_layer': 'furniture',\n",
              "   'label': 'page_header',\n",
              "   'prov': [{'page_no': 1,\n",
              "     'bbox': {'l': 18.34,\n",
              "      't': 632.0,\n",
              "      'r': 36.34,\n",
              "      'b': 232.0,\n",
              "      'coord_origin': 'BOTTOMLEFT'},\n",
              "     'charspan': [0, 40]}],\n",
              "   'orig': 'arXiv:2501.17887v1  [cs.CL]  27 Jan 2025',\n",
              "   'text': 'arXiv:2501.17887v1  [cs.CL]  27 Jan 2025'},\n",
              "  {'self_ref': '#/texts/1',\n",
              "   'parent': {'$ref': '#/body'},\n",
              "   'children': [],\n",
              "   'content_layer': 'body',\n",
              "   'label': 'section_header',\n",
              "   'prov': [{'page_no': 1,\n",
              "     'bbox': {'l': 63.595,\n",
              "      't': 693.015,\n",
              "      'r': 548.41,\n",
              "      'b': 680.118,\n",
              "      'coord_origin': 'BOTTOMLEFT'},\n",
              "     'charspan': [0, 75]}],\n",
              "   'orig': 'Docling: An Efficient Open-Source Toolkit for AI-driven Document Conversion',\n",
              "   'text': 'Docling: An Efficient Open-Source Toolkit for AI-driven Document Conversion',\n",
              "   'level': 1},\n",
              "  {'self_ref': '#/texts/2',\n",
              "   'parent': {'$ref': '#/body'},\n",
              "   'children': [],\n",
              "   'content_layer': 'body',\n",
              "   'label': 'text',\n",
              "   'prov': [{'page_no': 1,\n",
              "     'bbox': {'l': 83.779,\n",
              "      't': 667.68,\n",
              "      'r': 529.449,\n",
              "      'b': 615.089,\n",
              "      'coord_origin': 'BOTTOMLEFT'},\n",
              "     'charspan': [0, 284]}],\n",
              "   'orig': 'Nikolaos Livathinos * , Christoph Auer * , Maksym Lysak, Ahmed Nassar, Michele Dolfi, Panagiotis Vagenas, Cesar Berrospi, Matteo Omenetti, Kasper Dinkla, Yusik Kim, Shubham Gupta, Rafael Teixeira de Lima, Valery Weber, Lucas Morin, Ingmar Meijer, Viktor Kuropiatnyk, Peter W. J. Staar',\n",
              "   'text': 'Nikolaos Livathinos * , Christoph Auer * , Maksym Lysak, Ahmed Nassar, Michele Dolfi, Panagiotis Vagenas, Cesar Berrospi, Matteo Omenetti, Kasper Dinkla, Yusik Kim, Shubham Gupta, Rafael Teixeira de Lima, Valery Weber, Lucas Morin, Ingmar Meijer, Viktor Kuropiatnyk, Peter W. J. Staar'},\n",
              "  {'self_ref': '#/texts/3',\n",
              "   'parent': {'$ref': '#/body'},\n",
              "   'children': [],\n",
              "   'content_layer': 'body',\n",
              "   'label': 'text',\n",
              "   'prov': [{'page_no': 1,\n",
              "     'bbox': {'l': 225.667,\n",
              "      't': 609.855,\n",
              "      'r': 386.334,\n",
              "      'b': 601.303,\n",
              "      'coord_origin': 'BOTTOMLEFT'},\n",
              "     'charspan': [0, 39]}],\n",
              "   'orig': 'IBM Research, R¨ uschlikon, Switzerland',\n",
              "   'text': 'IBM Research, R¨ uschlikon, Switzerland'},\n",
              "  {'self_ref': '#/texts/4',\n",
              "   'parent': {'$ref': '#/body'},\n",
              "   'children': [],\n",
              "   'content_layer': 'body',\n",
              "   'label': 'text',\n",
              "   'prov': [{'page_no': 1,\n",
              "     'bbox': {'l': 152.98,\n",
              "      't': 598.896,\n",
              "      'r': 459.02,\n",
              "      'b': 590.344,\n",
              "      'coord_origin': 'BOTTOMLEFT'},\n",
              "     'charspan': [0, 61]}],\n",
              "   'orig': 'Please send correspondence to: deepsearch-core@zurich.ibm.com',\n",
              "   'text': 'Please send correspondence to: deepsearch-core@zurich.ibm.com'},\n",
              "  {'self_ref': '#/texts/5',\n",
              "   'parent': {'$ref': '#/body'},\n",
              "   'children': [],\n",
              "   'content_layer': 'body',\n",
              "   'label': 'section_header',\n",
              "   'prov': [{'page_no': 1,\n",
              "     'bbox': {'l': 154.715,\n",
              "      't': 572.04,\n",
              "      'r': 191.786,\n",
              "      'b': 563.084,\n",
              "      'coord_origin': 'BOTTOMLEFT'},\n",
              "     'charspan': [0, 8]}],\n",
              "   'orig': 'Abstract',\n",
              "   'text': 'Abstract',\n",
              "   'level': 1},\n",
              "  {'self_ref': '#/texts/6',\n",
              "   'parent': {'$ref': '#/body'},\n",
              "   'children': [],\n",
              "   'content_layer': 'body',\n",
              "   'label': 'text',\n",
              "   'prov': [{'page_no': 1,\n",
              "     'bbox': {'l': 63.963,\n",
              "      't': 555.628,\n",
              "      'r': 282.54,\n",
              "      'b': 368.451,\n",
              "      'coord_origin': 'BOTTOMLEFT'},\n",
              "     'charspan': [0, 1117]}],\n",
              "   'orig': \"We introduce Docling , an easy-to-use, self-contained, MITlicensed, open-source toolkit for document conversion, that can parse several types of popular document formats into a unified, richly structured representation. It is powered by state-of-the-art specialized AI models for layout analysis (DocLayNet) and table structure recognition (TableFormer), and runs efficiently on commodity hardware in a small resource budget. Docling is released as a Python package and can be used as a Python API or as a CLI tool. Docling's modular architecture and efficient document representation make it easy to implement extensions, new features, models, and customizations. Docling has been already integrated in other popular open-source frameworks (e.g., LangChain, LlamaIndex, spaCy), making it a natural fit for the processing of documents and the development of high-end applications. The open-source community has fully engaged in using, promoting, and developing for Docling, which gathered 10k stars on GitHub in less than a month and was reported as the No. 1 trending repository in GitHub worldwide in November 2024.\",\n",
              "   'text': \"We introduce Docling , an easy-to-use, self-contained, MITlicensed, open-source toolkit for document conversion, that can parse several types of popular document formats into a unified, richly structured representation. It is powered by state-of-the-art specialized AI models for layout analysis (DocLayNet) and table structure recognition (TableFormer), and runs efficiently on commodity hardware in a small resource budget. Docling is released as a Python package and can be used as a Python API or as a CLI tool. Docling's modular architecture and efficient document representation make it easy to implement extensions, new features, models, and customizations. Docling has been already integrated in other popular open-source frameworks (e.g., LangChain, LlamaIndex, spaCy), making it a natural fit for the processing of documents and the development of high-end applications. The open-source community has fully engaged in using, promoting, and developing for Docling, which gathered 10k stars on GitHub in less than a month and was reported as the No. 1 trending repository in GitHub worldwide in November 2024.\"},\n",
              "  {'self_ref': '#/texts/7',\n",
              "   'parent': {'$ref': '#/body'},\n",
              "   'children': [],\n",
              "   'content_layer': 'body',\n",
              "   'label': 'text',\n",
              "   'prov': [{'page_no': 1,\n",
              "     'bbox': {'l': 54.0,\n",
              "      't': 357.588,\n",
              "      'r': 253.7,\n",
              "      'b': 348.632,\n",
              "      'coord_origin': 'BOTTOMLEFT'},\n",
              "     'charspan': [0, 44]}],\n",
              "   'orig': 'Repository -https://github.com/DS4SD/docling',\n",
              "   'text': 'Repository -https://github.com/DS4SD/docling'},\n",
              "  {'self_ref': '#/texts/8',\n",
              "   'parent': {'$ref': '#/body'},\n",
              "   'children': [],\n",
              "   'content_layer': 'body',\n",
              "   'label': 'section_header',\n",
              "   'prov': [{'page_no': 1,\n",
              "     'bbox': {'l': 131.844,\n",
              "      't': 333.323,\n",
              "      'r': 214.658,\n",
              "      'b': 322.575,\n",
              "      'coord_origin': 'BOTTOMLEFT'},\n",
              "     'charspan': [0, 14]}],\n",
              "   'orig': '1 Introduction',\n",
              "   'text': '1 Introduction',\n",
              "   'level': 1},\n",
              "  {'self_ref': '#/texts/9',\n",
              "   'parent': {'$ref': '#/body'},\n",
              "   'children': [],\n",
              "   'content_layer': 'body',\n",
              "   'label': 'text',\n",
              "   'prov': [{'page_no': 1,\n",
              "     'bbox': {'l': 54.0,\n",
              "      't': 318.275,\n",
              "      'r': 292.505,\n",
              "      'b': 123.42200000000003,\n",
              "      'coord_origin': 'BOTTOMLEFT'},\n",
              "     'charspan': [0, 1033]}],\n",
              "   'orig': 'Converting documents back into a unified machineprocessable format has been a major challenge for decades due to their huge variability in formats, weak standardization and printing-optimized characteristic, which often discards structural features and metadata. With the advent of LLMs and popular application patterns such as retrieval-augmented generation (RAG), leveraging the rich content embedded in PDFs, Office documents, and scanned document images has become ever more relevant. In the past decade, several powerful document understanding solutions have emerged on the market, most of which are commercial software, SaaS offerings on hyperscalers (Auer et al. 2022) and most recently, multimodal vision-language models. Typically, they incur a cost (e.g., for licensing or LLM inference) and cannot be run easily on local hardware. Meanwhile, only a handful of different open-source tools cover PDF, MS Word, MS PowerPoint, Images, or HTML conversion, leaving a significant feature and quality gap to proprietary solutions.',\n",
              "   'text': 'Converting documents back into a unified machineprocessable format has been a major challenge for decades due to their huge variability in formats, weak standardization and printing-optimized characteristic, which often discards structural features and metadata. With the advent of LLMs and popular application patterns such as retrieval-augmented generation (RAG), leveraging the rich content embedded in PDFs, Office documents, and scanned document images has become ever more relevant. In the past decade, several powerful document understanding solutions have emerged on the market, most of which are commercial software, SaaS offerings on hyperscalers (Auer et al. 2022) and most recently, multimodal vision-language models. Typically, they incur a cost (e.g., for licensing or LLM inference) and cannot be run easily on local hardware. Meanwhile, only a handful of different open-source tools cover PDF, MS Word, MS PowerPoint, Images, or HTML conversion, leaving a significant feature and quality gap to proprietary solutions.'},\n",
              "  {'self_ref': '#/texts/10',\n",
              "   'parent': {'$ref': '#/body'},\n",
              "   'children': [],\n",
              "   'content_layer': 'body',\n",
              "   'label': 'footnote',\n",
              "   'prov': [{'page_no': 1,\n",
              "     'bbox': {'l': 66.653,\n",
              "      't': 115.44499999999994,\n",
              "      'r': 193.392,\n",
              "      'b': 107.20600000000002,\n",
              "      'coord_origin': 'BOTTOMLEFT'},\n",
              "     'charspan': [0, 36]}],\n",
              "   'orig': '* These authors contributed equally.',\n",
              "   'text': '* These authors contributed equally.'},\n",
              "  {'self_ref': '#/texts/11',\n",
              "   'parent': {'$ref': '#/body'},\n",
              "   'children': [],\n",
              "   'content_layer': 'body',\n",
              "   'label': 'footnote',\n",
              "   'prov': [{'page_no': 1,\n",
              "     'bbox': {'l': 54.0,\n",
              "      't': 105.79999999999995,\n",
              "      'r': 292.497,\n",
              "      'b': 88.13999999999999,\n",
              "      'coord_origin': 'BOTTOMLEFT'},\n",
              "     'charspan': [0, 113]}],\n",
              "   'orig': 'Copyright © 2025, Association for the Advancement of Artificial Intelligence (www.aaai.org). All rights reserved.',\n",
              "   'text': 'Copyright © 2025, Association for the Advancement of Artificial Intelligence (www.aaai.org). All rights reserved.'},\n",
              "  {'self_ref': '#/texts/12',\n",
              "   'parent': {'$ref': '#/body'},\n",
              "   'children': [],\n",
              "   'content_layer': 'body',\n",
              "   'label': 'text',\n",
              "   'prov': [{'page_no': 1,\n",
              "     'bbox': {'l': 319.5,\n",
              "      't': 571.821,\n",
              "      'r': 558.005,\n",
              "      'b': 376.798,\n",
              "      'coord_origin': 'BOTTOMLEFT'},\n",
              "     'charspan': [0, 1059]}],\n",
              "   'orig': \"With Docling , we recently open-sourced a very capable and efficient document conversion tool which builds on the powerful, specialized AI models and datasets for layout analysis and table structure recognition that we developed and presented in the recent past (Livathinos et al. 2021; Pfitzmann et al. 2022; Lysak et al. 2023). Docling is designed as a simple, self-contained Python library with permissive MIT license, running entirely locally on commodity hardware. Its code architecture allows for easy extensibility and addition of new features and models. Since its launch in July 2024, Docling has attracted considerable attention in the AI developer community and ranks top on GitHub's monthly trending repositories with more than 10,000 stars at the time of writing. On October 16, 2024, Docling reached a major milestone with version 2, introducing several new features and concepts, which we outline in this updated technical report, along with details on its architecture, conversion speed benchmarks, and comparisons to other open-source assets.\",\n",
              "   'text': \"With Docling , we recently open-sourced a very capable and efficient document conversion tool which builds on the powerful, specialized AI models and datasets for layout analysis and table structure recognition that we developed and presented in the recent past (Livathinos et al. 2021; Pfitzmann et al. 2022; Lysak et al. 2023). Docling is designed as a simple, self-contained Python library with permissive MIT license, running entirely locally on commodity hardware. Its code architecture allows for easy extensibility and addition of new features and models. Since its launch in July 2024, Docling has attracted considerable attention in the AI developer community and ranks top on GitHub's monthly trending repositories with more than 10,000 stars at the time of writing. On October 16, 2024, Docling reached a major milestone with version 2, introducing several new features and concepts, which we outline in this updated technical report, along with details on its architecture, conversion speed benchmarks, and comparisons to other open-source assets.\"},\n",
              "  {'self_ref': '#/texts/13',\n",
              "   'parent': {'$ref': '#/body'},\n",
              "   'children': [],\n",
              "   'content_layer': 'body',\n",
              "   'label': 'text',\n",
              "   'prov': [{'page_no': 1,\n",
              "     'bbox': {'l': 319.5,\n",
              "      't': 373.902,\n",
              "      'r': 557.995,\n",
              "      'b': 354.391,\n",
              "      'coord_origin': 'BOTTOMLEFT'},\n",
              "     'charspan': [0, 74]}],\n",
              "   'orig': 'The following list summarizes the features currently available on Docling:',\n",
              "   'text': 'The following list summarizes the features currently available on Docling:'},\n",
              "  {'self_ref': '#/texts/14',\n",
              "   'parent': {'$ref': '#/groups/0'},\n",
              "   'children': [],\n",
              "   'content_layer': 'body',\n",
              "   'label': 'list_item',\n",
              "   'prov': [{'page_no': 1,\n",
              "     'bbox': {'l': 323.983,\n",
              "      't': 345.778,\n",
              "      'r': 558.004,\n",
              "      'b': 315.308,\n",
              "      'coord_origin': 'BOTTOMLEFT'},\n",
              "     'charspan': [0, 112]}],\n",
              "   'orig': '· Parses common document formats (PDF, Images, MS Office formats, HTML) and exports to Markdown, JSON, and HTML.',\n",
              "   'text': 'Parses common document formats (PDF, Images, MS Office formats, HTML) and exports to Markdown, JSON, and HTML.',\n",
              "   'enumerated': False,\n",
              "   'marker': '·'},\n",
              "  {'self_ref': '#/texts/15',\n",
              "   'parent': {'$ref': '#/groups/0'},\n",
              "   'children': [],\n",
              "   'content_layer': 'body',\n",
              "   'label': 'list_item',\n",
              "   'prov': [{'page_no': 1,\n",
              "     'bbox': {'l': 323.983,\n",
              "      't': 309.431,\n",
              "      'r': 558.004,\n",
              "      'b': 278.961,\n",
              "      'coord_origin': 'BOTTOMLEFT'},\n",
              "     'charspan': [0, 153]}],\n",
              "   'orig': '· Applies advanced AI for document understanding, including detailed page layout, OCR, reading order, figure extraction, and table structure recognition.',\n",
              "   'text': 'Applies advanced AI for document understanding, including detailed page layout, OCR, reading order, figure extraction, and table structure recognition.',\n",
              "   'enumerated': False,\n",
              "   'marker': '·'},\n",
              "  {'self_ref': '#/texts/16',\n",
              "   'parent': {'$ref': '#/groups/0'},\n",
              "   'children': [],\n",
              "   'content_layer': 'body',\n",
              "   'label': 'list_item',\n",
              "   'prov': [{'page_no': 1,\n",
              "     'bbox': {'l': 323.983,\n",
              "      't': 273.08400000000006,\n",
              "      'r': 557.997,\n",
              "      'b': 253.57299999999998,\n",
              "      'coord_origin': 'BOTTOMLEFT'},\n",
              "     'charspan': [0, 99]}],\n",
              "   'orig': '· Establishes a unified DoclingDocument data model for rich document representation and operations.',\n",
              "   'text': 'Establishes a unified DoclingDocument data model for rich document representation and operations.',\n",
              "   'enumerated': False,\n",
              "   'marker': '·'},\n",
              "  {'self_ref': '#/texts/17',\n",
              "   'parent': {'$ref': '#/groups/0'},\n",
              "   'children': [],\n",
              "   'content_layer': 'body',\n",
              "   'label': 'list_item',\n",
              "   'prov': [{'page_no': 1,\n",
              "     'bbox': {'l': 323.983,\n",
              "      't': 247.69600000000003,\n",
              "      'r': 558.004,\n",
              "      'b': 228.18499999999995,\n",
              "      'coord_origin': 'BOTTOMLEFT'},\n",
              "     'charspan': [0, 112]}],\n",
              "   'orig': '· Provides fully local execution capabilities making it suitable for sensitive data and air-gapped environments.',\n",
              "   'text': 'Provides fully local execution capabilities making it suitable for sensitive data and air-gapped environments.',\n",
              "   'enumerated': False,\n",
              "   'marker': '·'},\n",
              "  {'self_ref': '#/texts/18',\n",
              "   'parent': {'$ref': '#/groups/0'},\n",
              "   'children': [],\n",
              "   'content_layer': 'body',\n",
              "   'label': 'list_item',\n",
              "   'prov': [{'page_no': 1,\n",
              "     'bbox': {'l': 323.983,\n",
              "      't': 222.308,\n",
              "      'r': 558.004,\n",
              "      'b': 191.83799999999997,\n",
              "      'coord_origin': 'BOTTOMLEFT'},\n",
              "     'charspan': [0, 137]}],\n",
              "   'orig': '· Has an ecosystem of plug-and-play integrations with prominent generative AI development frameworks, including LangChain and LlamaIndex.',\n",
              "   'text': 'Has an ecosystem of plug-and-play integrations with prominent generative AI development frameworks, including LangChain and LlamaIndex.',\n",
              "   'enumerated': False,\n",
              "   'marker': '·'},\n",
              "  {'self_ref': '#/texts/19',\n",
              "   'parent': {'$ref': '#/groups/0'},\n",
              "   'children': [],\n",
              "   'content_layer': 'body',\n",
              "   'label': 'list_item',\n",
              "   'prov': [{'page_no': 1,\n",
              "     'bbox': {'l': 323.983,\n",
              "      't': 185.961,\n",
              "      'r': 534.174,\n",
              "      'b': 177.409,\n",
              "      'coord_origin': 'BOTTOMLEFT'},\n",
              "     'charspan': [0, 50]}],\n",
              "   'orig': '· Can leverage hardware accelerators such as GPUs.',\n",
              "   'text': 'Can leverage hardware accelerators such as GPUs.',\n",
              "   'enumerated': False,\n",
              "   'marker': '·'},\n",
              "  {'self_ref': '#/texts/20',\n",
              "   'parent': {'$ref': '#/body'},\n",
              "   'children': [],\n",
              "   'content_layer': 'body',\n",
              "   'label': 'section_header',\n",
              "   'prov': [{'page_no': 1,\n",
              "     'bbox': {'l': 390.445,\n",
              "      't': 157.50199999999995,\n",
              "      'r': 487.055,\n",
              "      'b': 146.75400000000002,\n",
              "      'coord_origin': 'BOTTOMLEFT'},\n",
              "     'charspan': [0, 18]}],\n",
              "   'orig': '2 State of the Art',\n",
              "   'text': '2 State of the Art',\n",
              "   'level': 1},\n",
              "  {'self_ref': '#/texts/21',\n",
              "   'parent': {'$ref': '#/body'},\n",
              "   'children': [],\n",
              "   'content_layer': 'body',\n",
              "   'label': 'text',\n",
              "   'prov': [{'page_no': 1,\n",
              "     'bbox': {'l': 319.5,\n",
              "      't': 140.322,\n",
              "      'r': 558.005,\n",
              "      'b': 87.93399999999997,\n",
              "      'coord_origin': 'BOTTOMLEFT'},\n",
              "     'charspan': [0, 292]}],\n",
              "   'orig': 'Document conversion is a well-established field with numerous solutions already available on the market. These solutions can be categorized along several key dimensions, including open vs. closed source, permissive vs. restrictive licensing, Web APIs vs. local code deployment, susceptibility',\n",
              "   'text': 'Document conversion is a well-established field with numerous solutions already available on the market. These solutions can be categorized along several key dimensions, including open vs. closed source, permissive vs. restrictive licensing, Web APIs vs. local code deployment, susceptibility'},\n",
              "  {'self_ref': '#/texts/22',\n",
              "   'parent': {'$ref': '#/pictures/0'},\n",
              "   'children': [],\n",
              "   'content_layer': 'body',\n",
              "   'label': 'caption',\n",
              "   'prov': [{'page_no': 2,\n",
              "     'bbox': {'l': 54.0,\n",
              "      't': 525.249,\n",
              "      'r': 558.003,\n",
              "      'b': 494.779,\n",
              "      'coord_origin': 'BOTTOMLEFT'},\n",
              "     'charspan': [0, 282]}],\n",
              "   'orig': \"Figure 1: Sketch of Docling's pipelines and usage model. Both PDF pipeline and simple pipeline build up a DoclingDocument representation, which can be further enriched. Downstream applications can utilize Docling's API to inspect, export, or chunk the document for various purposes.\",\n",
              "   'text': \"Figure 1: Sketch of Docling's pipelines and usage model. Both PDF pipeline and simple pipeline build up a DoclingDocument representation, which can be further enriched. Downstream applications can utilize Docling's API to inspect, export, or chunk the document for various purposes.\"},\n",
              "  {'self_ref': '#/texts/23',\n",
              "   'parent': {'$ref': '#/pictures/0'},\n",
              "   'children': [],\n",
              "   'content_layer': 'body',\n",
              "   'label': 'text',\n",
              "   'prov': [{'page_no': 2,\n",
              "     'bbox': {'l': 231.331,\n",
              "      't': 618.266,\n",
              "      'r': 245.41,\n",
              "      'b': 609.849,\n",
              "      'coord_origin': 'BOTTOMLEFT'},\n",
              "     'charspan': [0, 3]}],\n",
              "   'orig': '</>',\n",
              "   'text': '</>'},\n",
              "  {'self_ref': '#/texts/24',\n",
              "   'parent': {'$ref': '#/pictures/0'},\n",
              "   'children': [],\n",
              "   'content_layer': 'body',\n",
              "   'label': 'text',\n",
              "   'prov': [{'page_no': 2,\n",
              "     'bbox': {'l': 292.876,\n",
              "      't': 630.367,\n",
              "      'r': 349.484,\n",
              "      'b': 620.089,\n",
              "      'coord_origin': 'BOTTOMLEFT'},\n",
              "     'charspan': [0, 15]}],\n",
              "   'orig': 'Simple Pipeline',\n",
              "   'text': 'Simple Pipeline'},\n",
              "  {'self_ref': '#/texts/25',\n",
              "   'parent': {'$ref': '#/pictures/0'},\n",
              "   'children': [],\n",
              "   'content_layer': 'body',\n",
              "   'label': 'text',\n",
              "   'prov': [{'page_no': 2,\n",
              "     'bbox': {'l': 296.327,\n",
              "      't': 571.87,\n",
              "      'r': 339.114,\n",
              "      'b': 565.387,\n",
              "      'coord_origin': 'BOTTOMLEFT'},\n",
              "     'charspan': [0, 12]}],\n",
              "   'orig': 'Parse Markup',\n",
              "   'text': 'Parse Markup'},\n",
              "  {'self_ref': '#/texts/26',\n",
              "   'parent': {'$ref': '#/pictures/0'},\n",
              "   'children': [],\n",
              "   'content_layer': 'body',\n",
              "   'label': 'text',\n",
              "   'prov': [{'page_no': 2,\n",
              "     'bbox': {'l': 306.491,\n",
              "      't': 563.452,\n",
              "      'r': 329.345,\n",
              "      'b': 556.969,\n",
              "      'coord_origin': 'BOTTOMLEFT'},\n",
              "     'charspan': [0, 6]}],\n",
              "   'orig': 'Format',\n",
              "   'text': 'Format'},\n",
              "  {'self_ref': '#/texts/27',\n",
              "   'parent': {'$ref': '#/pictures/0'},\n",
              "   'children': [],\n",
              "   'content_layer': 'body',\n",
              "   'label': 'text',\n",
              "   'prov': [{'page_no': 2,\n",
              "     'bbox': {'l': 332.09,\n",
              "      't': 550.356,\n",
              "      'r': 350.971,\n",
              "      'b': 540.078,\n",
              "      'coord_origin': 'BOTTOMLEFT'},\n",
              "     'charspan': [0, 5]}],\n",
              "   'orig': 'Build',\n",
              "   'text': 'Build'},\n",
              "  {'self_ref': '#/texts/28',\n",
              "   'parent': {'$ref': '#/pictures/0'},\n",
              "   'children': [],\n",
              "   'content_layer': 'body',\n",
              "   'label': 'text',\n",
              "   'prov': [{'page_no': 2,\n",
              "     'bbox': {'l': 412.368,\n",
              "      't': 550.356,\n",
              "      'r': 435.348,\n",
              "      'b': 540.078,\n",
              "      'coord_origin': 'BOTTOMLEFT'},\n",
              "     'charspan': [0, 6]}],\n",
              "   'orig': 'Enrich',\n",
              "   'text': 'Enrich'},\n",
              "  {'self_ref': '#/texts/29',\n",
              "   'parent': {'$ref': '#/pictures/0'},\n",
              "   'children': [],\n",
              "   'content_layer': 'body',\n",
              "   'label': 'text',\n",
              "   'prov': [{'page_no': 2,\n",
              "     'bbox': {'l': 134.289,\n",
              "      't': 733.334,\n",
              "      'r': 180.361,\n",
              "      'b': 723.035,\n",
              "      'coord_origin': 'BOTTOMLEFT'},\n",
              "     'charspan': [0, 12]}],\n",
              "   'orig': 'PDF Pipeline',\n",
              "   'text': 'PDF Pipeline'},\n",
              "  {'self_ref': '#/texts/30',\n",
              "   'parent': {'$ref': '#/pictures/0'},\n",
              "   'children': [],\n",
              "   'content_layer': 'body',\n",
              "   'label': 'text',\n",
              "   'prov': [{'page_no': 2,\n",
              "     'bbox': {'l': 353.308,\n",
              "      't': 573.602,\n",
              "      'r': 385.872,\n",
              "      'b': 567.119,\n",
              "      'coord_origin': 'BOTTOMLEFT'},\n",
              "     'charspan': [0, 8]}],\n",
              "   'orig': 'Assemble',\n",
              "   'text': 'Assemble'},\n",
              "  {'self_ref': '#/texts/31',\n",
              "   'parent': {'$ref': '#/pictures/0'},\n",
              "   'children': [],\n",
              "   'content_layer': 'body',\n",
              "   'label': 'text',\n",
              "   'prov': [{'page_no': 2,\n",
              "     'bbox': {'l': 353.427,\n",
              "      't': 565.167,\n",
              "      'r': 385.806,\n",
              "      'b': 558.684,\n",
              "      'coord_origin': 'BOTTOMLEFT'},\n",
              "     'charspan': [0, 8]}],\n",
              "   'orig': 'Document',\n",
              "   'text': 'Document'},\n",
              "  {'self_ref': '#/texts/32',\n",
              "   'parent': {'$ref': '#/pictures/0'},\n",
              "   'children': [],\n",
              "   'content_layer': 'body',\n",
              "   'label': 'text',\n",
              "   'prov': [{'page_no': 2,\n",
              "     'bbox': {'l': 256.545,\n",
              "      't': 671.327,\n",
              "      'r': 277.915,\n",
              "      'b': 664.844,\n",
              "      'coord_origin': 'BOTTOMLEFT'},\n",
              "     'charspan': [0, 6]}],\n",
              "   'orig': 'Layout',\n",
              "   'text': 'Layout'},\n",
              "  {'self_ref': '#/texts/33',\n",
              "   'parent': {'$ref': '#/pictures/0'},\n",
              "   'children': [],\n",
              "   'content_layer': 'body',\n",
              "   'label': 'text',\n",
              "   'prov': [{'page_no': 2,\n",
              "     'bbox': {'l': 254.011,\n",
              "      't': 662.906,\n",
              "      'r': 279.89,\n",
              "      'b': 656.423,\n",
              "      'coord_origin': 'BOTTOMLEFT'},\n",
              "     'charspan': [0, 8]}],\n",
              "   'orig': 'Analysis',\n",
              "   'text': 'Analysis'},\n",
              "  {'self_ref': '#/texts/34',\n",
              "   'parent': {'$ref': '#/pictures/0'},\n",
              "   'children': [],\n",
              "   'content_layer': 'body',\n",
              "   'label': 'text',\n",
              "   'prov': [{'page_no': 2,\n",
              "     'bbox': {'l': 142.024,\n",
              "      't': 671.656,\n",
              "      'r': 176.148,\n",
              "      'b': 665.173,\n",
              "      'coord_origin': 'BOTTOMLEFT'},\n",
              "     'charspan': [0, 9]}],\n",
              "   'orig': 'Parse PDF',\n",
              "   'text': 'Parse PDF'},\n",
              "  {'self_ref': '#/texts/35',\n",
              "   'parent': {'$ref': '#/pictures/0'},\n",
              "   'children': [],\n",
              "   'content_layer': 'body',\n",
              "   'label': 'text',\n",
              "   'prov': [{'page_no': 2,\n",
              "     'bbox': {'l': 149.654,\n",
              "      't': 663.242,\n",
              "      'r': 168.19,\n",
              "      'b': 656.759,\n",
              "      'coord_origin': 'BOTTOMLEFT'},\n",
              "     'charspan': [0, 5]}],\n",
              "   'orig': 'pages',\n",
              "   'text': 'pages'},\n",
              "  {'self_ref': '#/texts/36',\n",
              "   'parent': {'$ref': '#/pictures/0'},\n",
              "   'children': [],\n",
              "   'content_layer': 'body',\n",
              "   'label': 'text',\n",
              "   'prov': [{'page_no': 2,\n",
              "     'bbox': {'l': 308.136,\n",
              "      't': 669.906,\n",
              "      'r': 327.576,\n",
              "      'b': 663.423,\n",
              "      'coord_origin': 'BOTTOMLEFT'},\n",
              "     'charspan': [0, 5]}],\n",
              "   'orig': 'Table',\n",
              "   'text': 'Table'},\n",
              "  {'self_ref': '#/texts/37',\n",
              "   'parent': {'$ref': '#/pictures/0'},\n",
              "   'children': [],\n",
              "   'content_layer': 'body',\n",
              "   'label': 'text',\n",
              "   'prov': [{'page_no': 2,\n",
              "     'bbox': {'l': 303.131,\n",
              "      't': 661.471,\n",
              "      'r': 332.123,\n",
              "      'b': 654.988,\n",
              "      'coord_origin': 'BOTTOMLEFT'},\n",
              "     'charspan': [0, 9]}],\n",
              "   'orig': 'Structure',\n",
              "   'text': 'Structure'},\n",
              "  {'self_ref': '#/texts/38',\n",
              "   'parent': {'$ref': '#/pictures/0'},\n",
              "   'children': [],\n",
              "   'content_layer': 'body',\n",
              "   'label': 'text',\n",
              "   'prov': [{'page_no': 2,\n",
              "     'bbox': {'l': 206.656,\n",
              "      't': 667.967,\n",
              "      'r': 220.478,\n",
              "      'b': 661.484,\n",
              "      'coord_origin': 'BOTTOMLEFT'},\n",
              "     'charspan': [0, 3]}],\n",
              "   'orig': 'OCR',\n",
              "   'text': 'OCR'},\n",
              "  {'self_ref': '#/texts/39',\n",
              "   'parent': {'$ref': '#/pictures/0'},\n",
              "   'children': [],\n",
              "   'content_layer': 'body',\n",
              "   'label': 'text',\n",
              "   'prov': [{'page_no': 2,\n",
              "     'bbox': {'l': 476.383,\n",
              "      't': 550.688,\n",
              "      'r': 490.791,\n",
              "      'b': 540.388,\n",
              "      'coord_origin': 'BOTTOMLEFT'},\n",
              "     'charspan': [0, 3]}],\n",
              "   'orig': 'Use',\n",
              "   'text': 'Use'},\n",
              "  {'self_ref': '#/texts/40',\n",
              "   'parent': {'$ref': '#/pictures/0'},\n",
              "   'children': [],\n",
              "   'content_layer': 'body',\n",
              "   'label': 'text',\n",
              "   'prov': [{'page_no': 2,\n",
              "     'bbox': {'l': 252.926,\n",
              "      't': 650.059,\n",
              "      'r': 271.807,\n",
              "      'b': 639.781,\n",
              "      'coord_origin': 'BOTTOMLEFT'},\n",
              "     'charspan': [0, 5]}],\n",
              "   'orig': 'Build',\n",
              "   'text': 'Build'},\n",
              "  {'self_ref': '#/texts/41',\n",
              "   'parent': {'$ref': '#/pictures/0'},\n",
              "   'children': [],\n",
              "   'content_layer': 'body',\n",
              "   'label': 'text',\n",
              "   'prov': [{'page_no': 2,\n",
              "     'bbox': {'l': 354.862,\n",
              "      't': 670.991,\n",
              "      'r': 385.893,\n",
              "      'b': 664.508,\n",
              "      'coord_origin': 'BOTTOMLEFT'},\n",
              "     'charspan': [0, 8]}],\n",
              "   'orig': 'Assemble',\n",
              "   'text': 'Assemble'},\n",
              "  {'self_ref': '#/texts/42',\n",
              "   'parent': {'$ref': '#/pictures/0'},\n",
              "   'children': [],\n",
              "   'content_layer': 'body',\n",
              "   'label': 'text',\n",
              "   'prov': [{'page_no': 2,\n",
              "     'bbox': {'l': 354.162,\n",
              "      't': 662.577,\n",
              "      'r': 386.466,\n",
              "      'b': 656.094,\n",
              "      'coord_origin': 'BOTTOMLEFT'},\n",
              "     'charspan': [0, 8]}],\n",
              "   'orig': 'Document',\n",
              "   'text': 'Document'},\n",
              "  {'self_ref': '#/texts/43',\n",
              "   'parent': {'$ref': '#/pictures/0'},\n",
              "   'children': [],\n",
              "   'content_layer': 'body',\n",
              "   'label': 'text',\n",
              "   'prov': [{'page_no': 2,\n",
              "     'bbox': {'l': 460.794,\n",
              "      't': 690.227,\n",
              "      'r': 504.361,\n",
              "      'b': 683.745,\n",
              "      'coord_origin': 'BOTTOMLEFT'},\n",
              "     'charspan': [0, 12]}],\n",
              "   'orig': 'Export JSON,',\n",
              "   'text': 'Export JSON,'},\n",
              "  {'self_ref': '#/texts/44',\n",
              "   'parent': {'$ref': '#/pictures/0'},\n",
              "   'children': [],\n",
              "   'content_layer': 'body',\n",
              "   'label': 'text',\n",
              "   'prov': [{'page_no': 2,\n",
              "     'bbox': {'l': 465.134,\n",
              "      't': 681.806,\n",
              "      'r': 500.032,\n",
              "      'b': 675.323,\n",
              "      'coord_origin': 'BOTTOMLEFT'},\n",
              "     'charspan': [0, 9]}],\n",
              "   'orig': 'Markdown,',\n",
              "   'text': 'Markdown,'},\n",
              "  {'self_ref': '#/texts/45',\n",
              "   'parent': {'$ref': '#/pictures/0'},\n",
              "   'children': [],\n",
              "   'content_layer': 'body',\n",
              "   'label': 'text',\n",
              "   'prov': [{'page_no': 2,\n",
              "     'bbox': {'l': 472.484,\n",
              "      't': 673.392,\n",
              "      'r': 492.697,\n",
              "      'b': 666.909,\n",
              "      'coord_origin': 'BOTTOMLEFT'},\n",
              "     'charspan': [0, 5]}],\n",
              "   'orig': 'HTML,',\n",
              "   'text': 'HTML,'},\n",
              "  {'self_ref': '#/texts/46',\n",
              "   'parent': {'$ref': '#/pictures/0'},\n",
              "   'children': [],\n",
              "   'content_layer': 'body',\n",
              "   'label': 'text',\n",
              "   'prov': [{'page_no': 2,\n",
              "     'bbox': {'l': 470.034,\n",
              "      't': 664.95,\n",
              "      'r': 494.969,\n",
              "      'b': 658.467,\n",
              "      'coord_origin': 'BOTTOMLEFT'},\n",
              "     'charspan': [0, 8]}],\n",
              "   'orig': 'Figures,',\n",
              "   'text': 'Figures,'},\n",
              "  {'self_ref': '#/texts/47',\n",
              "   'parent': {'$ref': '#/pictures/0'},\n",
              "   'children': [],\n",
              "   'content_layer': 'body',\n",
              "   'label': 'text',\n",
              "   'prov': [{'page_no': 2,\n",
              "     'bbox': {'l': 479.758,\n",
              "      't': 656.536,\n",
              "      'r': 485.252,\n",
              "      'b': 650.053,\n",
              "      'coord_origin': 'BOTTOMLEFT'},\n",
              "     'charspan': [0, 1]}],\n",
              "   'orig': '…',\n",
              "   'text': '…'},\n",
              "  {'self_ref': '#/texts/48',\n",
              "   'parent': {'$ref': '#/pictures/0'},\n",
              "   'children': [],\n",
              "   'content_layer': 'body',\n",
              "   'label': 'text',\n",
              "   'prov': [{'page_no': 2,\n",
              "     'bbox': {'l': 474.738,\n",
              "      't': 704.34,\n",
              "      'r': 488.818,\n",
              "      'b': 695.922,\n",
              "      'coord_origin': 'BOTTOMLEFT'},\n",
              "     'charspan': [0, 3]}],\n",
              "   'orig': '{;}',\n",
              "   'text': '{;}'},\n",
              "  {'self_ref': '#/texts/49',\n",
              "   'parent': {'$ref': '#/pictures/0'},\n",
              "   'children': [],\n",
              "   'content_layer': 'body',\n",
              "   'label': 'text',\n",
              "   'prov': [{'page_no': 2,\n",
              "     'bbox': {'l': 470.972,\n",
              "      't': 717.43,\n",
              "      'r': 480.345,\n",
              "      'b': 709.012,\n",
              "      'coord_origin': 'BOTTOMLEFT'},\n",
              "     'charspan': [0, 2]}],\n",
              "   'orig': '##',\n",
              "   'text': '##'},\n",
              "  {'self_ref': '#/texts/50',\n",
              "   'parent': {'$ref': '#/pictures/0'},\n",
              "   'children': [],\n",
              "   'content_layer': 'body',\n",
              "   'label': 'text',\n",
              "   'prov': [{'page_no': 2,\n",
              "     'bbox': {'l': 478.799,\n",
              "      't': 570.459,\n",
              "      'r': 486.823,\n",
              "      'b': 560.992,\n",
              "      'coord_origin': 'BOTTOMLEFT'},\n",
              "     'charspan': [0, 1]}],\n",
              "   'orig': '…',\n",
              "   'text': '…'},\n",
              "  {'self_ref': '#/texts/51',\n",
              "   'parent': {'$ref': '#/pictures/0'},\n",
              "   'children': [],\n",
              "   'content_layer': 'body',\n",
              "   'label': 'text',\n",
              "   'prov': [{'page_no': 2,\n",
              "     'bbox': {'l': 467.633,\n",
              "      't': 593.36,\n",
              "      'r': 496.947,\n",
              "      'b': 586.877,\n",
              "      'coord_origin': 'BOTTOMLEFT'},\n",
              "     'charspan': [0, 8]}],\n",
              "   'orig': 'Chunking',\n",
              "   'text': 'Chunking'},\n",
              "  {'self_ref': '#/texts/52',\n",
              "   'parent': {'$ref': '#/pictures/0'},\n",
              "   'children': [],\n",
              "   'content_layer': 'body',\n",
              "   'label': 'text',\n",
              "   'prov': [{'page_no': 2,\n",
              "     'bbox': {'l': 470.118,\n",
              "      't': 584.925,\n",
              "      'r': 494.375,\n",
              "      'b': 578.442,\n",
              "      'coord_origin': 'BOTTOMLEFT'},\n",
              "     'charspan': [0, 7]}],\n",
              "   'orig': 'for RAG',\n",
              "   'text': 'for RAG'},\n",
              "  {'self_ref': '#/texts/53',\n",
              "   'parent': {'$ref': '#/pictures/0'},\n",
              "   'children': [],\n",
              "   'content_layer': 'body',\n",
              "   'label': 'text',\n",
              "   'prov': [{'page_no': 2,\n",
              "     'bbox': {'l': 414.153,\n",
              "      't': 622.179,\n",
              "      'r': 437.787,\n",
              "      'b': 615.697,\n",
              "      'coord_origin': 'BOTTOMLEFT'},\n",
              "     'charspan': [0, 7]}],\n",
              "   'orig': 'Docling',\n",
              "   'text': 'Docling'},\n",
              "  {'self_ref': '#/texts/54',\n",
              "   'parent': {'$ref': '#/pictures/0'},\n",
              "   'children': [],\n",
              "   'content_layer': 'body',\n",
              "   'label': 'text',\n",
              "   'prov': [{'page_no': 2,\n",
              "     'bbox': {'l': 409.659,\n",
              "      't': 613.765,\n",
              "      'r': 441.962,\n",
              "      'b': 607.282,\n",
              "      'coord_origin': 'BOTTOMLEFT'},\n",
              "     'charspan': [0, 8]}],\n",
              "   'orig': 'Document',\n",
              "   'text': 'Document'},\n",
              "  {'self_ref': '#/texts/55',\n",
              "   'parent': {'$ref': '#/pictures/0'},\n",
              "   'children': [],\n",
              "   'content_layer': 'body',\n",
              "   'label': 'text',\n",
              "   'prov': [{'page_no': 2,\n",
              "     'bbox': {'l': 257.385,\n",
              "      't': 619.312,\n",
              "      'r': 272.649,\n",
              "      'b': 613.519,\n",
              "      'coord_origin': 'BOTTOMLEFT'},\n",
              "     'charspan': [0, 5]}],\n",
              "   'orig': 'ascii',\n",
              "   'text': 'ascii'},\n",
              "  {'self_ref': '#/texts/56',\n",
              "   'parent': {'$ref': '#/pictures/0'},\n",
              "   'children': [],\n",
              "   'content_layer': 'body',\n",
              "   'label': 'text',\n",
              "   'prov': [{'page_no': 2,\n",
              "     'bbox': {'l': 203.926,\n",
              "      't': 565.608,\n",
              "      'r': 218.487,\n",
              "      'b': 557.253,\n",
              "      'coord_origin': 'BOTTOMLEFT'},\n",
              "     'charspan': [0, 4]}],\n",
              "   'orig': 'docx',\n",
              "   'text': 'docx'},\n",
              "  {'self_ref': '#/texts/57',\n",
              "   'parent': {'$ref': '#/pictures/0'},\n",
              "   'children': [],\n",
              "   'content_layer': 'body',\n",
              "   'label': 'text',\n",
              "   'prov': [{'page_no': 2,\n",
              "     'bbox': {'l': 231.156,\n",
              "      't': 565.608,\n",
              "      'r': 244.15,\n",
              "      'b': 557.253,\n",
              "      'coord_origin': 'BOTTOMLEFT'},\n",
              "     'charspan': [0, 4]}],\n",
              "   'orig': 'pptx',\n",
              "   'text': 'pptx'},\n",
              "  {'self_ref': '#/texts/58',\n",
              "   'parent': {'$ref': '#/pictures/0'},\n",
              "   'children': [],\n",
              "   'content_layer': 'body',\n",
              "   'label': 'text',\n",
              "   'prov': [{'page_no': 2,\n",
              "     'bbox': {'l': 258.316,\n",
              "      't': 565.608,\n",
              "      'r': 269.723,\n",
              "      'b': 557.253,\n",
              "      'coord_origin': 'BOTTOMLEFT'},\n",
              "     'charspan': [0, 4]}],\n",
              "   'orig': 'xlsx',\n",
              "   'text': 'xlsx'},\n",
              "  {'self_ref': '#/texts/59',\n",
              "   'parent': {'$ref': '#/pictures/0'},\n",
              "   'children': [],\n",
              "   'content_layer': 'body',\n",
              "   'label': 'text',\n",
              "   'prov': [{'page_no': 2,\n",
              "     'bbox': {'l': 206.075,\n",
              "      't': 604.738,\n",
              "      'r': 215.688,\n",
              "      'b': 596.383,\n",
              "      'coord_origin': 'BOTTOMLEFT'},\n",
              "     'charspan': [0, 2]}],\n",
              "   'orig': 'md',\n",
              "   'text': 'md'},\n",
              "  {'self_ref': '#/texts/60',\n",
              "   'parent': {'$ref': '#/pictures/0'},\n",
              "   'children': [],\n",
              "   'content_layer': 'body',\n",
              "   'label': 'text',\n",
              "   'prov': [{'page_no': 2,\n",
              "     'bbox': {'l': 231.73,\n",
              "      't': 604.178,\n",
              "      'r': 245.579,\n",
              "      'b': 595.823,\n",
              "      'coord_origin': 'BOTTOMLEFT'},\n",
              "     'charspan': [0, 4]}],\n",
              "   'orig': 'html',\n",
              "   'text': 'html'},\n",
              "  {'self_ref': '#/texts/61',\n",
              "   'parent': {'$ref': '#/pictures/0'},\n",
              "   'children': [],\n",
              "   'content_layer': 'body',\n",
              "   'label': 'text',\n",
              "   'prov': [{'page_no': 2,\n",
              "     'bbox': {'l': 253.325,\n",
              "      't': 603.682,\n",
              "      'r': 274.775,\n",
              "      'b': 596.609,\n",
              "      'coord_origin': 'BOTTOMLEFT'},\n",
              "     'charspan': [0, 8]}],\n",
              "   'orig': 'AsciiDoc',\n",
              "   'text': 'AsciiDoc'},\n",
              "  {'self_ref': '#/texts/62',\n",
              "   'parent': {'$ref': '#/pictures/0'},\n",
              "   'children': [],\n",
              "   'content_layer': 'body',\n",
              "   'label': 'text',\n",
              "   'prov': [{'page_no': 2,\n",
              "     'bbox': {'l': 103.681,\n",
              "      't': 700.779,\n",
              "      'r': 113.609,\n",
              "      'b': 692.425,\n",
              "      'coord_origin': 'BOTTOMLEFT'},\n",
              "     'charspan': [0, 3]}],\n",
              "   'orig': 'pdf',\n",
              "   'text': 'pdf'},\n",
              "  {'self_ref': '#/texts/63',\n",
              "   'parent': {'$ref': '#/pictures/0'},\n",
              "   'children': [],\n",
              "   'content_layer': 'body',\n",
              "   'label': 'text',\n",
              "   'prov': [{'page_no': 2,\n",
              "     'bbox': {'l': 98.938,\n",
              "      't': 661.194,\n",
              "      'r': 120.711,\n",
              "      'b': 652.839,\n",
              "      'coord_origin': 'BOTTOMLEFT'},\n",
              "     'charspan': [0, 6]}],\n",
              "   'orig': 'images',\n",
              "   'text': 'images'},\n",
              "  {'self_ref': '#/texts/64',\n",
              "   'parent': {'$ref': '#/body'},\n",
              "   'children': [],\n",
              "   'content_layer': 'body',\n",
              "   'label': 'text',\n",
              "   'prov': [{'page_no': 2,\n",
              "     'bbox': {'l': 54.0,\n",
              "      't': 470.156,\n",
              "      'r': 292.505,\n",
              "      'b': 450.645,\n",
              "      'coord_origin': 'BOTTOMLEFT'},\n",
              "     'charspan': [0, 91]}],\n",
              "   'orig': 'to hallucinations, conversion quality, time-to-solution, and compute resource requirements.',\n",
              "   'text': 'to hallucinations, conversion quality, time-to-solution, and compute resource requirements.'},\n",
              "  {'self_ref': '#/texts/65',\n",
              "   'parent': {'$ref': '#/body'},\n",
              "   'children': [],\n",
              "   'content_layer': 'body',\n",
              "   'label': 'text',\n",
              "   'prov': [{'page_no': 2,\n",
              "     'bbox': {'l': 54.0,\n",
              "      't': 447.882,\n",
              "      'r': 292.505,\n",
              "      'b': 274.947,\n",
              "      'coord_origin': 'BOTTOMLEFT'},\n",
              "     'charspan': [0, 851]}],\n",
              "   'orig': 'The most popular conversion tools today leverage visionlanguage models (VLMs), which process page images to text and markup directly. Among proprietary solutions, prominent examples include GPT-4o (OpenAI), Claude (Anthropic), and Gemini (Google). In the open-source domain, LLaVA-based models, such as LLaVA-next, are noteworthy. However, all generative AI-based models face two significant challenges. First, they are prone to hallucinations, i.e., their output may contain false information which is not present in the source document - a critical issue when faithful transcription of document content is required. Second, these models demand substantial computational resources, making the conversion process expensive. Consequently, VLM-based tools are typically offered as SaaS, with compute-intensive operations performed remotely in the cloud.',\n",
              "   'text': 'The most popular conversion tools today leverage visionlanguage models (VLMs), which process page images to text and markup directly. Among proprietary solutions, prominent examples include GPT-4o (OpenAI), Claude (Anthropic), and Gemini (Google). In the open-source domain, LLaVA-based models, such as LLaVA-next, are noteworthy. However, all generative AI-based models face two significant challenges. First, they are prone to hallucinations, i.e., their output may contain false information which is not present in the source document - a critical issue when faithful transcription of document content is required. Second, these models demand substantial computational resources, making the conversion process expensive. Consequently, VLM-based tools are typically offered as SaaS, with compute-intensive operations performed remotely in the cloud.'},\n",
              "  {'self_ref': '#/texts/66',\n",
              "   'parent': {'$ref': '#/body'},\n",
              "   'children': [],\n",
              "   'content_layer': 'body',\n",
              "   'label': 'text',\n",
              "   'prov': [{'page_no': 2,\n",
              "     'bbox': {'l': 54.0,\n",
              "      't': 272.18399999999997,\n",
              "      'r': 292.505,\n",
              "      'b': 132.125,\n",
              "      'coord_origin': 'BOTTOMLEFT'},\n",
              "     'charspan': [0, 731]}],\n",
              "   'orig': 'A second category of solutions prioritizes on-premises deployment, either as Web APIs or as libraries. Examples include Adobe Acrobat, Grobid, Marker, MinerU, Unstructured, and others. These solutions often rely on multiple specialized models, such as OCR, layout analysis, and table recognition models. Docling falls into this category, leveraging modular, task-specific models which recover document structures and features only. All text content is taken from the programmatic PDF or transcribed through OCR methods. This design ensures faithful conversion, without the risk of generating false content. However, it necessitates maintaining a diverse set of models for different document components, such as formulas or figures.',\n",
              "   'text': 'A second category of solutions prioritizes on-premises deployment, either as Web APIs or as libraries. Examples include Adobe Acrobat, Grobid, Marker, MinerU, Unstructured, and others. These solutions often rely on multiple specialized models, such as OCR, layout analysis, and table recognition models. Docling falls into this category, leveraging modular, task-specific models which recover document structures and features only. All text content is taken from the programmatic PDF or transcribed through OCR methods. This design ensures faithful conversion, without the risk of generating false content. However, it necessitates maintaining a diverse set of models for different document components, such as formulas or figures.'},\n",
              "  {'self_ref': '#/texts/67',\n",
              "   'parent': {'$ref': '#/body'},\n",
              "   'children': [],\n",
              "   'content_layer': 'body',\n",
              "   'label': 'text',\n",
              "   'prov': [{'page_no': 2,\n",
              "     'bbox': {'l': 54.0,\n",
              "      't': 129.36300000000006,\n",
              "      'r': 292.505,\n",
              "      'b': 87.93399999999997,\n",
              "      'coord_origin': 'BOTTOMLEFT'},\n",
              "     'charspan': [0, 236]},\n",
              "    {'page_no': 2,\n",
              "     'bbox': {'l': 319.5,\n",
              "      't': 470.156,\n",
              "      'r': 558.005,\n",
              "      'b': 439.686,\n",
              "      'coord_origin': 'BOTTOMLEFT'},\n",
              "     'charspan': [237, 384]}],\n",
              "   'orig': 'Within this category, Docling distinguishes itself through its permissive MIT license, allowing organizations to integrate Docling into their solutions without incurring licensing fees or adopting restrictive licenses (e.g., GPL). Addi- tionally, Docling offers highly accurate, resource-efficient, and fast models, making it well-suited for integration with many standard frameworks.',\n",
              "   'text': 'Within this category, Docling distinguishes itself through its permissive MIT license, allowing organizations to integrate Docling into their solutions without incurring licensing fees or adopting restrictive licenses (e.g., GPL). Addi- tionally, Docling offers highly accurate, resource-efficient, and fast models, making it well-suited for integration with many standard frameworks.'},\n",
              "  {'self_ref': '#/texts/68',\n",
              "   'parent': {'$ref': '#/body'},\n",
              "   'children': [],\n",
              "   'content_layer': 'body',\n",
              "   'label': 'text',\n",
              "   'prov': [{'page_no': 2,\n",
              "     'bbox': {'l': 319.5,\n",
              "      't': 436.28,\n",
              "      'r': 558.005,\n",
              "      'b': 394.851,\n",
              "      'coord_origin': 'BOTTOMLEFT'},\n",
              "     'charspan': [0, 190]}],\n",
              "   'orig': 'In summary, Docling stands out as a cost-effective, accurate and transparent open-source library with a permissive license, offering a reliable and flexible solution for document conversion.',\n",
              "   'text': 'In summary, Docling stands out as a cost-effective, accurate and transparent open-source library with a permissive license, offering a reliable and flexible solution for document conversion.'},\n",
              "  {'self_ref': '#/texts/69',\n",
              "   'parent': {'$ref': '#/body'},\n",
              "   'children': [],\n",
              "   'content_layer': 'body',\n",
              "   'label': 'section_header',\n",
              "   'prov': [{'page_no': 2,\n",
              "     'bbox': {'l': 367.576,\n",
              "      't': 379.005,\n",
              "      'r': 509.927,\n",
              "      'b': 368.257,\n",
              "      'coord_origin': 'BOTTOMLEFT'},\n",
              "     'charspan': [0, 25]}],\n",
              "   'orig': '3 Design and Architecture',\n",
              "   'text': '3 Design and Architecture',\n",
              "   'level': 1},\n",
              "  {'self_ref': '#/texts/70',\n",
              "   'parent': {'$ref': '#/body'},\n",
              "   'children': [],\n",
              "   'content_layer': 'body',\n",
              "   'label': 'text',\n",
              "   'prov': [{'page_no': 2,\n",
              "     'bbox': {'l': 319.5,\n",
              "      't': 360.296,\n",
              "      'r': 558.005,\n",
              "      'b': 264.073,\n",
              "      'coord_origin': 'BOTTOMLEFT'},\n",
              "     'charspan': [0, 492]}],\n",
              "   'orig': 'Docling is designed in a modular fashion with extensibility in mind, and it builds on three main concepts: pipelines, parser backends, and the DoclingDocument data model as its centerpiece (see Figure 1). Pipelines and parser backends share the responsibility of constructing and enriching a DoclingDocument representation from any supported input format. The DoclingDocument data model with its APIs enable inspection, export, and downstream processing for various applications, such as RAG.',\n",
              "   'text': 'Docling is designed in a modular fashion with extensibility in mind, and it builds on three main concepts: pipelines, parser backends, and the DoclingDocument data model as its centerpiece (see Figure 1). Pipelines and parser backends share the responsibility of constructing and enriching a DoclingDocument representation from any supported input format. The DoclingDocument data model with its APIs enable inspection, export, and downstream processing for various applications, such as RAG.'},\n",
              "  {'self_ref': '#/texts/71',\n",
              "   'parent': {'$ref': '#/body'},\n",
              "   'children': [],\n",
              "   'content_layer': 'body',\n",
              "   'label': 'section_header',\n",
              "   'prov': [{'page_no': 2,\n",
              "     'bbox': {'l': 319.5,\n",
              "      't': 249.49700000000007,\n",
              "      'r': 430.402,\n",
              "      'b': 239.69000000000005,\n",
              "      'coord_origin': 'BOTTOMLEFT'},\n",
              "     'charspan': [0, 20]}],\n",
              "   'orig': '3.1 Docling Document',\n",
              "   'text': '3.1 Docling Document',\n",
              "   'level': 1},\n",
              "  {'self_ref': '#/texts/72',\n",
              "   'parent': {'$ref': '#/body'},\n",
              "   'children': [],\n",
              "   'content_layer': 'body',\n",
              "   'label': 'text',\n",
              "   'prov': [{'page_no': 2,\n",
              "     'bbox': {'l': 319.5,\n",
              "      't': 231.51099999999997,\n",
              "      'r': 558.005,\n",
              "      'b': 201.04099999999994,\n",
              "      'coord_origin': 'BOTTOMLEFT'},\n",
              "     'charspan': [0, 159]}],\n",
              "   'orig': 'Docling v2 introduces a unified document representation, DoclingDocument , as a Pydantic data model that can express various common document features, such as:',\n",
              "   'text': 'Docling v2 introduces a unified document representation, DoclingDocument , as a Pydantic data model that can express various common document features, such as:'},\n",
              "  {'self_ref': '#/texts/73',\n",
              "   'parent': {'$ref': '#/groups/1'},\n",
              "   'children': [],\n",
              "   'content_layer': 'body',\n",
              "   'label': 'list_item',\n",
              "   'prov': [{'page_no': 2,\n",
              "     'bbox': {'l': 323.983,\n",
              "      't': 191.15499999999997,\n",
              "      'r': 527.28,\n",
              "      'b': 182.60300000000007,\n",
              "      'coord_origin': 'BOTTOMLEFT'},\n",
              "     'charspan': [0, 52]}],\n",
              "   'orig': '· Text, Tables, Pictures, Captions, Lists, and more.',\n",
              "   'text': 'Text, Tables, Pictures, Captions, Lists, and more.',\n",
              "   'enumerated': False,\n",
              "   'marker': '·'},\n",
              "  {'self_ref': '#/texts/74',\n",
              "   'parent': {'$ref': '#/groups/1'},\n",
              "   'children': [],\n",
              "   'content_layer': 'body',\n",
              "   'label': 'list_item',\n",
              "   'prov': [{'page_no': 2,\n",
              "     'bbox': {'l': 323.983,\n",
              "      't': 175.707,\n",
              "      'r': 517.785,\n",
              "      'b': 167.15499999999997,\n",
              "      'coord_origin': 'BOTTOMLEFT'},\n",
              "     'charspan': [0, 46]}],\n",
              "   'orig': '· Document hierarchy with sections and groups.',\n",
              "   'text': 'Document hierarchy with sections and groups.',\n",
              "   'enumerated': False,\n",
              "   'marker': '·'},\n",
              "  {'self_ref': '#/texts/75',\n",
              "   'parent': {'$ref': '#/groups/1'},\n",
              "   'children': [],\n",
              "   'content_layer': 'body',\n",
              "   'label': 'list_item',\n",
              "   'prov': [{'page_no': 2,\n",
              "     'bbox': {'l': 323.983,\n",
              "      't': 160.25900000000001,\n",
              "      'r': 558.004,\n",
              "      'b': 140.74800000000005,\n",
              "      'coord_origin': 'BOTTOMLEFT'},\n",
              "     'charspan': [0, 68]}],\n",
              "   'orig': '· Disambiguation between main body and headers, footers (furniture).',\n",
              "   'text': 'Disambiguation between main body and headers, footers (furniture).',\n",
              "   'enumerated': False,\n",
              "   'marker': '·'},\n",
              "  {'self_ref': '#/texts/76',\n",
              "   'parent': {'$ref': '#/groups/1'},\n",
              "   'children': [],\n",
              "   'content_layer': 'body',\n",
              "   'label': 'list_item',\n",
              "   'prov': [{'page_no': 2,\n",
              "     'bbox': {'l': 323.983,\n",
              "      't': 133.85199999999998,\n",
              "      'r': 558.004,\n",
              "      'b': 114.34100000000001,\n",
              "      'coord_origin': 'BOTTOMLEFT'},\n",
              "     'charspan': [0, 72]}],\n",
              "   'orig': '· Layout information (i.e., bounding boxes) for all items, if available.',\n",
              "   'text': 'Layout information (i.e., bounding boxes) for all items, if available.',\n",
              "   'enumerated': False,\n",
              "   'marker': '·'},\n",
              "  {'self_ref': '#/texts/77',\n",
              "   'parent': {'$ref': '#/groups/1'},\n",
              "   'children': [],\n",
              "   'content_layer': 'body',\n",
              "   'label': 'list_item',\n",
              "   'prov': [{'page_no': 2,\n",
              "     'bbox': {'l': 323.983,\n",
              "      't': 107.44499999999994,\n",
              "      'r': 558.004,\n",
              "      'b': 87.93399999999997,\n",
              "      'coord_origin': 'BOTTOMLEFT'},\n",
              "     'charspan': [0, 63]}],\n",
              "   'orig': '· Provenance information (i.e., page numbers, document origin).',\n",
              "   'text': 'Provenance information (i.e., page numbers, document origin).',\n",
              "   'enumerated': False,\n",
              "   'marker': '·'},\n",
              "  {'self_ref': '#/texts/78',\n",
              "   'parent': {'$ref': '#/body'},\n",
              "   'children': [],\n",
              "   'content_layer': 'body',\n",
              "   'label': 'text',\n",
              "   'prov': [{'page_no': 3,\n",
              "     'bbox': {'l': 54.0,\n",
              "      't': 734.523,\n",
              "      'r': 292.505,\n",
              "      'b': 704.054,\n",
              "      'coord_origin': 'BOTTOMLEFT'},\n",
              "     'charspan': [0, 136]}],\n",
              "   'orig': 'With this data model, Docling enables representing document content in a unified manner, i.e., regardless of the source document format.',\n",
              "   'text': 'With this data model, Docling enables representing document content in a unified manner, i.e., regardless of the source document format.'},\n",
              "  {'self_ref': '#/texts/79',\n",
              "   'parent': {'$ref': '#/body'},\n",
              "   'children': [],\n",
              "   'content_layer': 'body',\n",
              "   'label': 'text',\n",
              "   'prov': [{'page_no': 3,\n",
              "     'bbox': {'l': 54.0,\n",
              "      't': 700.669,\n",
              "      'r': 292.505,\n",
              "      'b': 593.487,\n",
              "      'coord_origin': 'BOTTOMLEFT'},\n",
              "     'charspan': [0, 483]}],\n",
              "   'orig': 'Besides specifying the data model, the DoclingDocument class defines APIs encompassing document construction, inspection, and export. Using the respective methods, users can incrementally build a DoclingDocument , traverse its contents in reading order, or export to commonly used formats. Docling supports lossless serialization to (and deserialization from) JSON, and lossy export formats such as Markdown and HTML, which, unlike JSON, cannot retain all available meta information.',\n",
              "   'text': 'Besides specifying the data model, the DoclingDocument class defines APIs encompassing document construction, inspection, and export. Using the respective methods, users can incrementally build a DoclingDocument , traverse its contents in reading order, or export to commonly used formats. Docling supports lossless serialization to (and deserialization from) JSON, and lossy export formats such as Markdown and HTML, which, unlike JSON, cannot retain all available meta information.'},\n",
              "  {'self_ref': '#/texts/80',\n",
              "   'parent': {'$ref': '#/body'},\n",
              "   'children': [],\n",
              "   'content_layer': 'body',\n",
              "   'label': 'text',\n",
              "   'prov': [{'page_no': 3,\n",
              "     'bbox': {'l': 54.0,\n",
              "      't': 590.102,\n",
              "      'r': 292.505,\n",
              "      'b': 461.002,\n",
              "      'coord_origin': 'BOTTOMLEFT'},\n",
              "     'charspan': [0, 671]}],\n",
              "   'orig': 'A DoclingDocument can additionally be passed to a chunker class, an abstraction that returns a stream of chunks, each of which captures some part of the document as a string accompanied by respective metadata. To enable both flexibility for downstream applications and out-of-the-box utility, Docling defines a chunker class hierarchy, providing a base type as well as specific subclasses. By using the base chunker type, downstream applications can leverage popular frameworks like LangChain or LlamaIndex, which provide a high degree of flexibility in the chunking approach. Users can therefore plug in any built-in, self-defined, or third-party chunker implementation.',\n",
              "   'text': 'A DoclingDocument can additionally be passed to a chunker class, an abstraction that returns a stream of chunks, each of which captures some part of the document as a string accompanied by respective metadata. To enable both flexibility for downstream applications and out-of-the-box utility, Docling defines a chunker class hierarchy, providing a base type as well as specific subclasses. By using the base chunker type, downstream applications can leverage popular frameworks like LangChain or LlamaIndex, which provide a high degree of flexibility in the chunking approach. Users can therefore plug in any built-in, self-defined, or third-party chunker implementation.'},\n",
              "  {'self_ref': '#/texts/81',\n",
              "   'parent': {'$ref': '#/body'},\n",
              "   'children': [],\n",
              "   'content_layer': 'body',\n",
              "   'label': 'section_header',\n",
              "   'prov': [{'page_no': 3,\n",
              "     'bbox': {'l': 54.0,\n",
              "      't': 446.496,\n",
              "      'r': 156.807,\n",
              "      'b': 436.689,\n",
              "      'coord_origin': 'BOTTOMLEFT'},\n",
              "     'charspan': [0, 19]}],\n",
              "   'orig': '3.2 Parser Backends',\n",
              "   'text': '3.2 Parser Backends',\n",
              "   'level': 1},\n",
              "  {'self_ref': '#/texts/82',\n",
              "   'parent': {'$ref': '#/body'},\n",
              "   'children': [],\n",
              "   'content_layer': 'body',\n",
              "   'label': 'text',\n",
              "   'prov': [{'page_no': 3,\n",
              "     'bbox': {'l': 54.0,\n",
              "      't': 428.574,\n",
              "      'r': 292.505,\n",
              "      'b': 409.063,\n",
              "      'coord_origin': 'BOTTOMLEFT'},\n",
              "     'charspan': [0, 59]}],\n",
              "   'orig': 'Document formats can be broadly categorized into two types:',\n",
              "   'text': 'Document formats can be broadly categorized into two types:'},\n",
              "  {'self_ref': '#/texts/83',\n",
              "   'parent': {'$ref': '#/groups/2'},\n",
              "   'children': [],\n",
              "   'content_layer': 'body',\n",
              "   'label': 'list_item',\n",
              "   'prov': [{'page_no': 3,\n",
              "     'bbox': {'l': 54.498,\n",
              "      't': 401.103,\n",
              "      'r': 292.504,\n",
              "      'b': 326.41,\n",
              "      'coord_origin': 'BOTTOMLEFT'},\n",
              "     'charspan': [0, 395]}],\n",
              "   'orig': '1. Low-level formats , like PDF files or scanned images. These formats primarily encode the visual representation of the document, containing instructions for rendering text cells and lines or defining image pixels. Most semantics of the represented content are typically lost and need to be recovered through specialized AI methods, such as OCR, layout analysis, or table structure recognition.',\n",
              "   'text': 'Low-level formats , like PDF files or scanned images. These formats primarily encode the visual representation of the document, containing instructions for rendering text cells and lines or defining image pixels. Most semantics of the represented content are typically lost and need to be recovered through specialized AI methods, such as OCR, layout analysis, or table structure recognition.',\n",
              "   'enumerated': True,\n",
              "   'marker': '1.'},\n",
              "  {'self_ref': '#/texts/84',\n",
              "   'parent': {'$ref': '#/groups/2'},\n",
              "   'children': [],\n",
              "   'content_layer': 'body',\n",
              "   'label': 'list_item',\n",
              "   'prov': [{'page_no': 3,\n",
              "     'bbox': {'l': 54.498,\n",
              "      't': 319.945,\n",
              "      'r': 292.504,\n",
              "      'b': 278.12799999999993,\n",
              "      'coord_origin': 'BOTTOMLEFT'},\n",
              "     'charspan': [0, 215]}],\n",
              "   'orig': '2. Markup-based formats , including MS Office, HTML, Markdown, and others. These formats preserve the semantics of the content (e.g., sections, lists, tables, and figures) and are comparatively inexpensive to parse.',\n",
              "   'text': 'Markup-based formats , including MS Office, HTML, Markdown, and others. These formats preserve the semantics of the content (e.g., sections, lists, tables, and figures) and are comparatively inexpensive to parse.',\n",
              "   'enumerated': True,\n",
              "   'marker': '2.'},\n",
              "  {'self_ref': '#/texts/85',\n",
              "   'parent': {'$ref': '#/body'},\n",
              "   'children': [],\n",
              "   'content_layer': 'body',\n",
              "   'label': 'text',\n",
              "   'prov': [{'page_no': 3,\n",
              "     'bbox': {'l': 54.0,\n",
              "      't': 269.78099999999995,\n",
              "      'r': 292.505,\n",
              "      'b': 129.72199999999998,\n",
              "      'coord_origin': 'BOTTOMLEFT'},\n",
              "     'charspan': [0, 742]}],\n",
              "   'orig': 'Docling implements several parser backends to read and interpret different formats and it routes their output to a fitting processing pipeline. For PDFs Docling provides backends which: a) retrieve all text content and their geometric properties, b) render the visual representation of each page as it would appear in a PDF viewer. For markup-based formats, the respective backends carry the responsibility of creating a DoclingDocument representation directly. For some formats, such as PowerPoint slides, element locations and page provenance are available, whereas in other formats (for example, MS Word or HTML), this information is unknown unless rendered in a Word viewer or a browser. The DoclingDocument data model handles both cases.',\n",
              "   'text': 'Docling implements several parser backends to read and interpret different formats and it routes their output to a fitting processing pipeline. For PDFs Docling provides backends which: a) retrieve all text content and their geometric properties, b) render the visual representation of each page as it would appear in a PDF viewer. For markup-based formats, the respective backends carry the responsibility of creating a DoclingDocument representation directly. For some formats, such as PowerPoint slides, element locations and page provenance are available, whereas in other formats (for example, MS Word or HTML), this information is unknown unless rendered in a Word viewer or a browser. The DoclingDocument data model handles both cases.'},\n",
              "  {'self_ref': '#/texts/86',\n",
              "   'parent': {'$ref': '#/body'},\n",
              "   'children': [],\n",
              "   'content_layer': 'body',\n",
              "   'label': 'text',\n",
              "   'prov': [{'page_no': 3,\n",
              "     'bbox': {'l': 54.0,\n",
              "      't': 118.79200000000003,\n",
              "      'r': 292.505,\n",
              "      'b': 87.93399999999997,\n",
              "      'coord_origin': 'BOTTOMLEFT'},\n",
              "     'charspan': [0, 172]},\n",
              "    {'page_no': 3,\n",
              "     'bbox': {'l': 319.5,\n",
              "      't': 734.523,\n",
              "      'r': 558.005,\n",
              "      'b': 693.095,\n",
              "      'coord_origin': 'BOTTOMLEFT'},\n",
              "     'charspan': [173, 374]}],\n",
              "   'orig': 'PDF Backends While several open-source PDF parsing Python libraries are available, in practice we ran into various limitations, among which are restrictive licensing (e.g., pymupdf (pym 2024)), poor speed, or unrecoverable quality issues, such as merged text cells across far-apart text tokens or table columns (pypdfium, PyPDF) (PyPDFium Team 2024; pypdf Maintainers 2024).',\n",
              "   'text': 'PDF Backends While several open-source PDF parsing Python libraries are available, in practice we ran into various limitations, among which are restrictive licensing (e.g., pymupdf (pym 2024)), poor speed, or unrecoverable quality issues, such as merged text cells across far-apart text tokens or table columns (pypdfium, PyPDF) (PyPDFium Team 2024; pypdf Maintainers 2024).'},\n",
              "  {'self_ref': '#/texts/87',\n",
              "   'parent': {'$ref': '#/body'},\n",
              "   'children': [],\n",
              "   'content_layer': 'body',\n",
              "   'label': 'text',\n",
              "   'prov': [{'page_no': 3,\n",
              "     'bbox': {'l': 319.5,\n",
              "      't': 690.615,\n",
              "      'r': 558.005,\n",
              "      'b': 627.268,\n",
              "      'coord_origin': 'BOTTOMLEFT'},\n",
              "     'charspan': [0, 322]}],\n",
              "   'orig': 'We therefore developed a custom-built PDF parser, which is based on the low-level library qpdf (Berkenbilt 2024). Our PDF parser is made available in a separate package named docling-parse and acts as the default PDF backend in Docling. As an alternative, we provide a PDF backend relying on pypdfium (PyPDFium Team 2024).',\n",
              "   'text': 'We therefore developed a custom-built PDF parser, which is based on the low-level library qpdf (Berkenbilt 2024). Our PDF parser is made available in a separate package named docling-parse and acts as the default PDF backend in Docling. As an alternative, we provide a PDF backend relying on pypdfium (PyPDFium Team 2024).'},\n",
              "  {'self_ref': '#/texts/88',\n",
              "   'parent': {'$ref': '#/body'},\n",
              "   'children': [],\n",
              "   'content_layer': 'body',\n",
              "   'label': 'text',\n",
              "   'prov': [{'page_no': 3,\n",
              "     'bbox': {'l': 319.5,\n",
              "      't': 619.053,\n",
              "      'r': 558.005,\n",
              "      'b': 445.729,\n",
              "      'coord_origin': 'BOTTOMLEFT'},\n",
              "     'charspan': [0, 843]}],\n",
              "   'orig': 'Other Backends Markup-based formats like HTML, Markdown, or Microsoft Office (Word, PowerPoint, Excel) as well as plain formats like AsciiDoc can be transformed directly to a DoclingDocument representation with the help of several third-party format parsing libraries. For HTML documents we utilize BeautifulSoup (Richardson 2004-2024), for Markdown we use the Marko library (Ming 2019-2024), and for Office XML-based formats (Word, PowerPoint, Excel) we implement custom extensions on top of the python-docx (Canny and contributors 2013-2024a), python-pptx (Canny and contributors 20132024b), and openpyxl (Eric Gazoni 2010-2024) libraries, respectively. During parsing, we identify and extract common document elements (e.g., title, headings, paragraphs, tables, lists, figures, and code) and reflect the correct hierarchy level if possible.',\n",
              "   'text': 'Other Backends Markup-based formats like HTML, Markdown, or Microsoft Office (Word, PowerPoint, Excel) as well as plain formats like AsciiDoc can be transformed directly to a DoclingDocument representation with the help of several third-party format parsing libraries. For HTML documents we utilize BeautifulSoup (Richardson 2004-2024), for Markdown we use the Marko library (Ming 2019-2024), and for Office XML-based formats (Word, PowerPoint, Excel) we implement custom extensions on top of the python-docx (Canny and contributors 2013-2024a), python-pptx (Canny and contributors 20132024b), and openpyxl (Eric Gazoni 2010-2024) libraries, respectively. During parsing, we identify and extract common document elements (e.g., title, headings, paragraphs, tables, lists, figures, and code) and reflect the correct hierarchy level if possible.'},\n",
              "  {'self_ref': '#/texts/89',\n",
              "   'parent': {'$ref': '#/body'},\n",
              "   'children': [],\n",
              "   'content_layer': 'body',\n",
              "   'label': 'section_header',\n",
              "   'prov': [{'page_no': 3,\n",
              "     'bbox': {'l': 319.5,\n",
              "      't': 434.163,\n",
              "      'r': 385.871,\n",
              "      'b': 424.356,\n",
              "      'coord_origin': 'BOTTOMLEFT'},\n",
              "     'charspan': [0, 13]}],\n",
              "   'orig': '3.3 Pipelines',\n",
              "   'text': '3.3 Pipelines',\n",
              "   'level': 1},\n",
              "  {'self_ref': '#/texts/90',\n",
              "   'parent': {'$ref': '#/body'},\n",
              "   'children': [],\n",
              "   'content_layer': 'body',\n",
              "   'label': 'text',\n",
              "   'prov': [{'page_no': 3,\n",
              "     'bbox': {'l': 319.5,\n",
              "      't': 418.955,\n",
              "      'r': 558.005,\n",
              "      'b': 366.568,\n",
              "      'coord_origin': 'BOTTOMLEFT'},\n",
              "     'charspan': [0, 284]}],\n",
              "   'orig': 'Pipelines in Docling serve as an orchestration layer which iterates through documents, gathers the extracted data from a parser backend, and applies a chain of models to: a) build up the DoclingDocument representation and b) enrich this representation further (e.g., classify images).',\n",
              "   'text': 'Pipelines in Docling serve as an orchestration layer which iterates through documents, gathers the extracted data from a parser backend, and applies a chain of models to: a) build up the DoclingDocument representation and b) enrich this representation further (e.g., classify images).'},\n",
              "  {'self_ref': '#/texts/91',\n",
              "   'parent': {'$ref': '#/body'},\n",
              "   'children': [],\n",
              "   'content_layer': 'body',\n",
              "   'label': 'text',\n",
              "   'prov': [{'page_no': 3,\n",
              "     'bbox': {'l': 319.5,\n",
              "      't': 364.257,\n",
              "      'r': 558.005,\n",
              "      'b': 289.782,\n",
              "      'coord_origin': 'BOTTOMLEFT'},\n",
              "     'charspan': [0, 348]}],\n",
              "   'orig': 'Docling provides two standard pipelines. The StandardPdfPipeline leverages several state-of-the-art AI models to reconstruct a high-quality DoclingDocument representation from PDF or image input, as described in section 4. The SimplePipeline handles all markup-based formats (Office, HTML, AsciiDoc) and may apply further enrichment models as well.',\n",
              "   'text': 'Docling provides two standard pipelines. The StandardPdfPipeline leverages several state-of-the-art AI models to reconstruct a high-quality DoclingDocument representation from PDF or image input, as described in section 4. The SimplePipeline handles all markup-based formats (Office, HTML, AsciiDoc) and may apply further enrichment models as well.'},\n",
              "  {'self_ref': '#/texts/92',\n",
              "   'parent': {'$ref': '#/body'},\n",
              "   'children': [],\n",
              "   'content_layer': 'body',\n",
              "   'label': 'text',\n",
              "   'prov': [{'page_no': 3,\n",
              "     'bbox': {'l': 319.5,\n",
              "      't': 287.302,\n",
              "      'r': 558.005,\n",
              "      'b': 212.99700000000007,\n",
              "      'coord_origin': 'BOTTOMLEFT'},\n",
              "     'charspan': [0, 398]}],\n",
              "   'orig': 'Pipelines can be fully customized by sub-classing from an abstract base class or cloning the default model pipeline. This effectively allows to fully customize the chain of models, add or replace models, and introduce additional pipeline configuration parameters. To create and use a custom model pipeline, you can provide a custom pipeline class as an argument to the main document conversion API.',\n",
              "   'text': 'Pipelines can be fully customized by sub-classing from an abstract base class or cloning the default model pipeline. This effectively allows to fully customize the chain of models, add or replace models, and introduce additional pipeline configuration parameters. To create and use a custom model pipeline, you can provide a custom pipeline class as an argument to the main document conversion API.'},\n",
              "  {'self_ref': '#/texts/93',\n",
              "   'parent': {'$ref': '#/body'},\n",
              "   'children': [],\n",
              "   'content_layer': 'body',\n",
              "   'label': 'section_header',\n",
              "   'prov': [{'page_no': 3,\n",
              "     'bbox': {'l': 365.657,\n",
              "      't': 200.15999999999997,\n",
              "      'r': 511.845,\n",
              "      'b': 189.41200000000003,\n",
              "      'coord_origin': 'BOTTOMLEFT'},\n",
              "     'charspan': [0, 25]}],\n",
              "   'orig': '4 PDF Conversion Pipeline',\n",
              "   'text': '4 PDF Conversion Pipeline',\n",
              "   'level': 1},\n",
              "  {'self_ref': '#/texts/94',\n",
              "   'parent': {'$ref': '#/body'},\n",
              "   'children': [],\n",
              "   'content_layer': 'body',\n",
              "   'label': 'text',\n",
              "   'prov': [{'page_no': 3,\n",
              "     'bbox': {'l': 319.5,\n",
              "      't': 184.231,\n",
              "      'r': 558.005,\n",
              "      'b': 142.80200000000002,\n",
              "      'coord_origin': 'BOTTOMLEFT'},\n",
              "     'charspan': [0, 205]}],\n",
              "   'orig': \"The capability to recover detailed structure and content from PDF and image files is one of Docling's defining features. In this section, we outline the underlying methods and models that drive the system.\",\n",
              "   'text': \"The capability to recover detailed structure and content from PDF and image files is one of Docling's defining features. In this section, we outline the underlying methods and models that drive the system.\"},\n",
              "  {'self_ref': '#/texts/95',\n",
              "   'parent': {'$ref': '#/body'},\n",
              "   'children': [],\n",
              "   'content_layer': 'body',\n",
              "   'label': 'text',\n",
              "   'prov': [{'page_no': 3,\n",
              "     'bbox': {'l': 319.5,\n",
              "      't': 140.322,\n",
              "      'r': 558.005,\n",
              "      'b': 87.93399999999997,\n",
              "      'coord_origin': 'BOTTOMLEFT'},\n",
              "     'charspan': [0, 287]},\n",
              "    {'page_no': 4,\n",
              "     'bbox': {'l': 54.0,\n",
              "      't': 734.523,\n",
              "      'r': 292.505,\n",
              "      'b': 649.259,\n",
              "      'coord_origin': 'BOTTOMLEFT'},\n",
              "     'charspan': [288, 696]}],\n",
              "   'orig': 'Each document is first parsed by a PDF backend, which retrieves the programmatic text tokens, consisting of string content and its coordinates on the page, and also renders a bitmap image of each page to support downstream operations. Any image format input is wrapped in a PDF container on the fly, and proceeds through the pipeline as a scanned PDF document. Then, the standard PDF pipeline applies a sequence of AI models independently on every page of the document to extract features and content, such as layout and table structures. Finally, the results from all pages are aggregated and passed through a post-processing stage, which eventually assembles the DoclingDocument representation.',\n",
              "   'text': 'Each document is first parsed by a PDF backend, which retrieves the programmatic text tokens, consisting of string content and its coordinates on the page, and also renders a bitmap image of each page to support downstream operations. Any image format input is wrapped in a PDF container on the fly, and proceeds through the pipeline as a scanned PDF document. Then, the standard PDF pipeline applies a sequence of AI models independently on every page of the document to extract features and content, such as layout and table structures. Finally, the results from all pages are aggregated and passed through a post-processing stage, which eventually assembles the DoclingDocument representation.'},\n",
              "  {'self_ref': '#/texts/96',\n",
              "   'parent': {'$ref': '#/body'},\n",
              "   'children': [],\n",
              "   'content_layer': 'body',\n",
              "   'label': 'section_header',\n",
              "   'prov': [{'page_no': 4,\n",
              "     'bbox': {'l': 54.0,\n",
              "      't': 632.266,\n",
              "      'r': 127.331,\n",
              "      'b': 622.459,\n",
              "      'coord_origin': 'BOTTOMLEFT'},\n",
              "     'charspan': [0, 13]}],\n",
              "   'orig': '4.1 AI Models',\n",
              "   'text': '4.1 AI Models',\n",
              "   'level': 1},\n",
              "  {'self_ref': '#/texts/97',\n",
              "   'parent': {'$ref': '#/body'},\n",
              "   'children': [],\n",
              "   'content_layer': 'body',\n",
              "   'label': 'text',\n",
              "   'prov': [{'page_no': 4,\n",
              "     'bbox': {'l': 54.0,\n",
              "      't': 612.049,\n",
              "      'r': 292.505,\n",
              "      'b': 504.867,\n",
              "      'coord_origin': 'BOTTOMLEFT'},\n",
              "     'charspan': [0, 529]}],\n",
              "   'orig': 'As part of Docling, we release two highly capable AI models to the open-source community, which have been developed and published recently by our team. The first model is a layout analysis model, an accurate object detector for page elements (Pfitzmann et al. 2022). The second model is TableFormer (Nassar et al. 2022; Lysak et al. 2023), a state-of-the-art table structure recognition model. We provide the pre-trained weights (hosted on Hugging Face) and a separate Python package for the inference code ( doclingibm-models ).',\n",
              "   'text': 'As part of Docling, we release two highly capable AI models to the open-source community, which have been developed and published recently by our team. The first model is a layout analysis model, an accurate object detector for page elements (Pfitzmann et al. 2022). The second model is TableFormer (Nassar et al. 2022; Lysak et al. 2023), a state-of-the-art table structure recognition model. We provide the pre-trained weights (hosted on Hugging Face) and a separate Python package for the inference code ( doclingibm-models ).'},\n",
              "  {'self_ref': '#/texts/98',\n",
              "   'parent': {'$ref': '#/body'},\n",
              "   'children': [],\n",
              "   'content_layer': 'body',\n",
              "   'label': 'text',\n",
              "   'prov': [{'page_no': 4,\n",
              "     'bbox': {'l': 54.0,\n",
              "      't': 491.642,\n",
              "      'r': 292.505,\n",
              "      'b': 329.277,\n",
              "      'coord_origin': 'BOTTOMLEFT'},\n",
              "     'charspan': [0, 832]}],\n",
              "   'orig': 'Layout Analysis Model Our layout analysis model is an object detector which predicts the bounding-boxes and classes of various elements on the image of a given page. Its architecture is derived from RT-DETR (Zhao et al. 2023) and re-trained on DocLayNet (Pfitzmann et al. 2022), our popular human-annotated dataset for document-layout analysis, among other proprietary datasets. For inference, our implementation relies on the Hugging Face transformers (Wolf et al. 2020) library and the Safetensors file format. All predicted bounding-box proposals for document elements are post-processed to remove overlapping proposals based on confidence and size, and then intersected with the text tokens in the PDF to group them into meaningful and complete units such as paragraphs, section titles, list items, captions, figures, or tables.',\n",
              "   'text': 'Layout Analysis Model Our layout analysis model is an object detector which predicts the bounding-boxes and classes of various elements on the image of a given page. Its architecture is derived from RT-DETR (Zhao et al. 2023) and re-trained on DocLayNet (Pfitzmann et al. 2022), our popular human-annotated dataset for document-layout analysis, among other proprietary datasets. For inference, our implementation relies on the Hugging Face transformers (Wolf et al. 2020) library and the Safetensors file format. All predicted bounding-box proposals for document elements are post-processed to remove overlapping proposals based on confidence and size, and then intersected with the text tokens in the PDF to group them into meaningful and complete units such as paragraphs, section titles, list items, captions, figures, or tables.'},\n",
              "  {'self_ref': '#/texts/99',\n",
              "   'parent': {'$ref': '#/body'},\n",
              "   'children': [],\n",
              "   'content_layer': 'body',\n",
              "   'label': 'text',\n",
              "   'prov': [{'page_no': 4,\n",
              "     'bbox': {'l': 54.0,\n",
              "      't': 316.052,\n",
              "      'r': 292.505,\n",
              "      'b': 87.93399999999997,\n",
              "      'coord_origin': 'BOTTOMLEFT'},\n",
              "     'charspan': [0, 1165]}],\n",
              "   'orig': 'Table Structure Recognition The TableFormer model (Nassar et al. 2022), first published in 2022 and since refined with a custom structure token language (Lysak et al. 2023), is a vision-transformer model for table structure recovery. It can predict the logical row and column structure of a given table based on an input image, and determine which table cells belong to column headers, row headers or the table body. Compared to earlier approaches, TableFormer handles many characteristics of tables like partial or no borderlines, empty cells, rows or columns, cell spans and hierarchy on both column-heading and row-heading level, tables with inconsistent indentation or alignment and other complexities. For inference, our implementation relies on PyTorch (Ansel et al. 2024). The PDF pipeline feeds all table objects detected in the layout analysis to the TableFormer model, by providing an image-crop of the table and the included text cells. TableFormer structure predictions are matched back to the PDF cells during a post-processing step, to avoid expensive re-transcription of the table image-crop, which also makes the TableFormer model language agnostic.',\n",
              "   'text': 'Table Structure Recognition The TableFormer model (Nassar et al. 2022), first published in 2022 and since refined with a custom structure token language (Lysak et al. 2023), is a vision-transformer model for table structure recovery. It can predict the logical row and column structure of a given table based on an input image, and determine which table cells belong to column headers, row headers or the table body. Compared to earlier approaches, TableFormer handles many characteristics of tables like partial or no borderlines, empty cells, rows or columns, cell spans and hierarchy on both column-heading and row-heading level, tables with inconsistent indentation or alignment and other complexities. For inference, our implementation relies on PyTorch (Ansel et al. 2024). The PDF pipeline feeds all table objects detected in the layout analysis to the TableFormer model, by providing an image-crop of the table and the included text cells. TableFormer structure predictions are matched back to the PDF cells during a post-processing step, to avoid expensive re-transcription of the table image-crop, which also makes the TableFormer model language agnostic.'},\n",
              "  {'self_ref': '#/texts/100',\n",
              "   'parent': {'$ref': '#/body'},\n",
              "   'children': [],\n",
              "   'content_layer': 'body',\n",
              "   'label': 'text',\n",
              "   'prov': [{'page_no': 4,\n",
              "     'bbox': {'l': 319.5,\n",
              "      't': 734.911,\n",
              "      'r': 558.005,\n",
              "      'b': 649.259,\n",
              "      'coord_origin': 'BOTTOMLEFT'},\n",
              "     'charspan': [0, 455]}],\n",
              "   'orig': 'OCR Docling utilizes OCR to convert scanned PDFs and extract content from bitmaps images embedded in a page. Currently, we provide integration with EasyOCR (eas 2024), a popular third-party OCR library with support for many languages, and Tesseract as a widely available alternative. While EasyOCR delivers reasonable transcription quality, we observe that it runs fairly slow on CPU (see section 5), making it the biggest compute expense in the pipeline.',\n",
              "   'text': 'OCR Docling utilizes OCR to convert scanned PDFs and extract content from bitmaps images embedded in a page. Currently, we provide integration with EasyOCR (eas 2024), a popular third-party OCR library with support for many languages, and Tesseract as a widely available alternative. While EasyOCR delivers reasonable transcription quality, we observe that it runs fairly slow on CPU (see section 5), making it the biggest compute expense in the pipeline.'},\n",
              "  {'self_ref': '#/texts/101',\n",
              "   'parent': {'$ref': '#/body'},\n",
              "   'children': [],\n",
              "   'content_layer': 'body',\n",
              "   'label': 'text',\n",
              "   'prov': [{'page_no': 4,\n",
              "     'bbox': {'l': 319.5,\n",
              "      't': 640.126,\n",
              "      'r': 558.005,\n",
              "      'b': 565.433,\n",
              "      'coord_origin': 'BOTTOMLEFT'},\n",
              "     'charspan': [0, 399]}],\n",
              "   'orig': 'Assembly In the final pipeline stage, Docling assembles all prediction results produced on each page into the DoclingDocument representation, as defined in the auxiliary Python package docling-core . The generated document object is passed through a post-processing model which leverages several algorithms to augment features, such as correcting the reading order or matching figures with captions.',\n",
              "   'text': 'Assembly In the final pipeline stage, Docling assembles all prediction results produced on each page into the DoclingDocument representation, as defined in the auxiliary Python package docling-core . The generated document object is passed through a post-processing model which leverages several algorithms to augment features, such as correcting the reading order or matching figures with captions.'},\n",
              "  {'self_ref': '#/texts/102',\n",
              "   'parent': {'$ref': '#/body'},\n",
              "   'children': [],\n",
              "   'content_layer': 'body',\n",
              "   'label': 'section_header',\n",
              "   'prov': [{'page_no': 4,\n",
              "     'bbox': {'l': 396.859,\n",
              "      't': 551.603,\n",
              "      'r': 480.641,\n",
              "      'b': 540.855,\n",
              "      'coord_origin': 'BOTTOMLEFT'},\n",
              "     'charspan': [0, 13]}],\n",
              "   'orig': '5 Performance',\n",
              "   'text': '5 Performance',\n",
              "   'level': 1},\n",
              "  {'self_ref': '#/texts/103',\n",
              "   'parent': {'$ref': '#/body'},\n",
              "   'children': [],\n",
              "   'content_layer': 'body',\n",
              "   'label': 'text',\n",
              "   'prov': [{'page_no': 4,\n",
              "     'bbox': {'l': 319.5,\n",
              "      't': 534.756,\n",
              "      'r': 558.005,\n",
              "      'b': 504.286,\n",
              "      'coord_origin': 'BOTTOMLEFT'},\n",
              "     'charspan': [0, 167]}],\n",
              "   'orig': 'In this section, we characterize the conversion speed of PDF documents with Docling in a given resource budget for different scenarios and establish reference numbers.',\n",
              "   'text': 'In this section, we characterize the conversion speed of PDF documents with Docling in a given resource budget for different scenarios and establish reference numbers.'},\n",
              "  {'self_ref': '#/texts/104',\n",
              "   'parent': {'$ref': '#/body'},\n",
              "   'children': [],\n",
              "   'content_layer': 'body',\n",
              "   'label': 'text',\n",
              "   'prov': [{'page_no': 4,\n",
              "     'bbox': {'l': 319.5,\n",
              "      't': 501.501,\n",
              "      'r': 558.005,\n",
              "      'b': 383.36,\n",
              "      'coord_origin': 'BOTTOMLEFT'},\n",
              "     'charspan': [0, 618]}],\n",
              "   'orig': 'Further, we compare the conversion speed to three popular contenders in the open-source space, namely unstructured.io (Unstructured.io Team 2024), Marker (Paruchuri 2024), and MinerU (Wang et al. 2024). All aforementioned solutions can universally convert PDF documents to Markdown or similar representations and offer a library-style interface to run the document processing entirely locally. We exclude SaaS offerings and remote services for document conversion from this comparison, since the latter do not provide any possibility to control the system resources they run on, rendering any speed comparison invalid.',\n",
              "   'text': 'Further, we compare the conversion speed to three popular contenders in the open-source space, namely unstructured.io (Unstructured.io Team 2024), Marker (Paruchuri 2024), and MinerU (Wang et al. 2024). All aforementioned solutions can universally convert PDF documents to Markdown or similar representations and offer a library-style interface to run the document processing entirely locally. We exclude SaaS offerings and remote services for document conversion from this comparison, since the latter do not provide any possibility to control the system resources they run on, rendering any speed comparison invalid.'},\n",
              "  {'self_ref': '#/texts/105',\n",
              "   'parent': {'$ref': '#/body'},\n",
              "   'children': [],\n",
              "   'content_layer': 'body',\n",
              "   'label': 'section_header',\n",
              "   'prov': [{'page_no': 4,\n",
              "     'bbox': {'l': 319.5,\n",
              "      't': 370.8,\n",
              "      'r': 436.456,\n",
              "      'b': 360.993,\n",
              "      'coord_origin': 'BOTTOMLEFT'},\n",
              "     'charspan': [0, 21]}],\n",
              "   'orig': '5.1 Benchmark Dataset',\n",
              "   'text': '5.1 Benchmark Dataset',\n",
              "   'level': 1},\n",
              "  {'self_ref': '#/texts/106',\n",
              "   'parent': {'$ref': '#/body'},\n",
              "   'children': [],\n",
              "   'content_layer': 'body',\n",
              "   'label': 'text',\n",
              "   'prov': [{'page_no': 4,\n",
              "     'bbox': {'l': 319.5,\n",
              "      't': 354.675,\n",
              "      'r': 558.005,\n",
              "      'b': 258.452,\n",
              "      'coord_origin': 'BOTTOMLEFT'},\n",
              "     'charspan': [0, 522]}],\n",
              "   'orig': 'To enable a meaningful benchmark, we composed a test set of 89 PDF files covering a large variety of styles, features, content, and length (see Figure 2). This dataset is based to a large extend on our DocLayNet (Pfitzmann et al. 2022) dataset and augmented with additional samples from CCpdf (Turski et al. 2023) to increase the variety. Overall, it includes 4008 pages, 56246 text items, 1842 tables and 4676 pictures. As such, it is large enough to provide variety without requiring excessively long benchmarking times.',\n",
              "   'text': 'To enable a meaningful benchmark, we composed a test set of 89 PDF files covering a large variety of styles, features, content, and length (see Figure 2). This dataset is based to a large extend on our DocLayNet (Pfitzmann et al. 2022) dataset and augmented with additional samples from CCpdf (Turski et al. 2023) to increase the variety. Overall, it includes 4008 pages, 56246 text items, 1842 tables and 4676 pictures. As such, it is large enough to provide variety without requiring excessively long benchmarking times.'},\n",
              "  {'self_ref': '#/texts/107',\n",
              "   'parent': {'$ref': '#/body'},\n",
              "   'children': [],\n",
              "   'content_layer': 'body',\n",
              "   'label': 'section_header',\n",
              "   'prov': [{'page_no': 4,\n",
              "     'bbox': {'l': 319.5,\n",
              "      't': 245.89200000000005,\n",
              "      'r': 449.809,\n",
              "      'b': 236.08500000000004,\n",
              "      'coord_origin': 'BOTTOMLEFT'},\n",
              "     'charspan': [0, 25]}],\n",
              "   'orig': '5.2 System Configurations',\n",
              "   'text': '5.2 System Configurations',\n",
              "   'level': 1},\n",
              "  {'self_ref': '#/texts/108',\n",
              "   'parent': {'$ref': '#/body'},\n",
              "   'children': [],\n",
              "   'content_layer': 'body',\n",
              "   'label': 'text',\n",
              "   'prov': [{'page_no': 4,\n",
              "     'bbox': {'l': 319.5,\n",
              "      't': 229.76700000000005,\n",
              "      'r': 558.005,\n",
              "      'b': 210.25700000000006,\n",
              "      'coord_origin': 'BOTTOMLEFT'},\n",
              "     'charspan': [0, 96]}],\n",
              "   'orig': 'We schedule our benchmark experiments each on two different systems to create reference numbers:',\n",
              "   'text': 'We schedule our benchmark experiments each on two different systems to create reference numbers:'},\n",
              "  {'self_ref': '#/texts/109',\n",
              "   'parent': {'$ref': '#/groups/3'},\n",
              "   'children': [],\n",
              "   'content_layer': 'body',\n",
              "   'label': 'list_item',\n",
              "   'prov': [{'page_no': 4,\n",
              "     'bbox': {'l': 323.983,\n",
              "      't': 203.10699999999997,\n",
              "      'r': 558.004,\n",
              "      'b': 161.678,\n",
              "      'coord_origin': 'BOTTOMLEFT'},\n",
              "     'charspan': [0, 148]}],\n",
              "   'orig': '· AWS EC2 VM (g6.xlarge), 8 virtual cores (AMD EPYC 7R13, x86), 32 GB RAM, Nvidia L4 GPU (24 GB VRAM), on Ubuntu 22.04 with Nvidia CUDA 12.4 drivers',\n",
              "   'text': 'AWS EC2 VM (g6.xlarge), 8 virtual cores (AMD EPYC 7R13, x86), 32 GB RAM, Nvidia L4 GPU (24 GB VRAM), on Ubuntu 22.04 with Nvidia CUDA 12.4 drivers',\n",
              "   'enumerated': False,\n",
              "   'marker': '·'},\n",
              "  {'self_ref': '#/texts/110',\n",
              "   'parent': {'$ref': '#/groups/3'},\n",
              "   'children': [],\n",
              "   'content_layer': 'body',\n",
              "   'label': 'list_item',\n",
              "   'prov': [{'page_no': 4,\n",
              "     'bbox': {'l': 323.983,\n",
              "      't': 156.02300000000002,\n",
              "      'r': 558.004,\n",
              "      'b': 136.51199999999994,\n",
              "      'coord_origin': 'BOTTOMLEFT'},\n",
              "     'charspan': [0, 51]}],\n",
              "   'orig': '· MacBook Pro M3 Max (ARM), 64GB RAM, on macOS 14.7',\n",
              "   'text': 'MacBook Pro M3 Max (ARM), 64GB RAM, on macOS 14.7',\n",
              "   'enumerated': False,\n",
              "   'marker': '·'},\n",
              "  {'self_ref': '#/texts/111',\n",
              "   'parent': {'$ref': '#/body'},\n",
              "   'children': [],\n",
              "   'content_layer': 'body',\n",
              "   'label': 'text',\n",
              "   'prov': [{'page_no': 4,\n",
              "     'bbox': {'l': 319.5,\n",
              "      't': 129.36300000000006,\n",
              "      'r': 558.005,\n",
              "      'b': 87.93399999999997,\n",
              "      'coord_origin': 'BOTTOMLEFT'},\n",
              "     'charspan': [0, 217]}],\n",
              "   'orig': 'All experiments on the AWS EC2 VM are carried out once with GPU acceleration enabled and once purely on the x86 CPU, resulting in three total system configurations which we refer to as M3 Max SoC, L4 GPU, and x86 CPU.',\n",
              "   'text': 'All experiments on the AWS EC2 VM are carried out once with GPU acceleration enabled and once purely on the x86 CPU, resulting in three total system configurations which we refer to as M3 Max SoC, L4 GPU, and x86 CPU.'},\n",
              "  {'self_ref': '#/texts/112',\n",
              "   'parent': {'$ref': '#/tables/0'},\n",
              "   'children': [],\n",
              "   'content_layer': 'body',\n",
              "   'label': 'caption',\n",
              "   'prov': [{'page_no': 5,\n",
              "     'bbox': {'l': 96.244,\n",
              "      't': 737.784,\n",
              "      'r': 515.757,\n",
              "      'b': 727.563,\n",
              "      'coord_origin': 'BOTTOMLEFT'},\n",
              "     'charspan': [0, 108]}],\n",
              "   'orig': 'Table 1: Versions and configuration options considered for each tested asset. * denotes the default setting.',\n",
              "   'text': 'Table 1: Versions and configuration options considered for each tested asset. * denotes the default setting.'},\n",
              "  {'self_ref': '#/texts/113',\n",
              "   'parent': {'$ref': '#/pictures/1'},\n",
              "   'children': [],\n",
              "   'content_layer': 'body',\n",
              "   'label': 'caption',\n",
              "   'prov': [{'page_no': 5,\n",
              "     'bbox': {'l': 54.0,\n",
              "      't': 311.938,\n",
              "      'r': 292.505,\n",
              "      'b': 292.428,\n",
              "      'coord_origin': 'BOTTOMLEFT'},\n",
              "     'charspan': [0, 71]}],\n",
              "   'orig': 'Figure 2: Dataset categories and sample counts for documents and pages.',\n",
              "   'text': 'Figure 2: Dataset categories and sample counts for documents and pages.'},\n",
              "  {'self_ref': '#/texts/114',\n",
              "   'parent': {'$ref': '#/pictures/1'},\n",
              "   'children': [],\n",
              "   'content_layer': 'body',\n",
              "   'label': 'text',\n",
              "   'prov': [{'page_no': 5,\n",
              "     'bbox': {'l': 72.644,\n",
              "      't': 551.301,\n",
              "      'r': 119.507,\n",
              "      'b': 544.148,\n",
              "      'coord_origin': 'BOTTOMLEFT'},\n",
              "     'charspan': [0, 14]}],\n",
              "   'orig': 'Annual Reports',\n",
              "   'text': 'Annual Reports'},\n",
              "  {'self_ref': '#/texts/115',\n",
              "   'parent': {'$ref': '#/pictures/1'},\n",
              "   'children': [],\n",
              "   'content_layer': 'body',\n",
              "   'label': 'text',\n",
              "   'prov': [{'page_no': 5,\n",
              "     'bbox': {'l': 138.163,\n",
              "      't': 551.478,\n",
              "      'r': 145.973,\n",
              "      'b': 544.326,\n",
              "      'coord_origin': 'BOTTOMLEFT'},\n",
              "     'charspan': [0, 2]}],\n",
              "   'orig': '20',\n",
              "   'text': '20'},\n",
              "  {'self_ref': '#/texts/116',\n",
              "   'parent': {'$ref': '#/pictures/1'},\n",
              "   'children': [],\n",
              "   'content_layer': 'body',\n",
              "   'label': 'text',\n",
              "   'prov': [{'page_no': 5,\n",
              "     'bbox': {'l': 193.822,\n",
              "      't': 508.587,\n",
              "      'r': 233.16,\n",
              "      'b': 501.434,\n",
              "      'coord_origin': 'BOTTOMLEFT'},\n",
              "     'charspan': [0, 12]}],\n",
              "   'orig': 'CCPdf (misc)',\n",
              "   'text': 'CCPdf (misc)'},\n",
              "  {'self_ref': '#/texts/117',\n",
              "   'parent': {'$ref': '#/pictures/1'},\n",
              "   'children': [],\n",
              "   'content_layer': 'body',\n",
              "   'label': 'text',\n",
              "   'prov': [{'page_no': 5,\n",
              "     'bbox': {'l': 178.701,\n",
              "      't': 528.18,\n",
              "      'r': 186.51,\n",
              "      'b': 521.027,\n",
              "      'coord_origin': 'BOTTOMLEFT'},\n",
              "     'charspan': [0, 2]}],\n",
              "   'orig': '39',\n",
              "   'text': '39'},\n",
              "  {'self_ref': '#/texts/118',\n",
              "   'parent': {'$ref': '#/pictures/1'},\n",
              "   'children': [],\n",
              "   'content_layer': 'body',\n",
              "   'label': 'text',\n",
              "   'prov': [{'page_no': 5,\n",
              "     'bbox': {'l': 213.51,\n",
              "      't': 574.036,\n",
              "      'r': 277.177,\n",
              "      'b': 566.883,\n",
              "      'coord_origin': 'BOTTOMLEFT'},\n",
              "     'charspan': [0, 19]}],\n",
              "   'orig': 'Law and Regulations',\n",
              "   'text': 'Law and Regulations'},\n",
              "  {'self_ref': '#/texts/119',\n",
              "   'parent': {'$ref': '#/pictures/1'},\n",
              "   'children': [],\n",
              "   'content_layer': 'body',\n",
              "   'label': 'text',\n",
              "   'prov': [{'page_no': 5,\n",
              "     'bbox': {'l': 191.395,\n",
              "      't': 563.879,\n",
              "      'r': 195.3,\n",
              "      'b': 556.726,\n",
              "      'coord_origin': 'BOTTOMLEFT'},\n",
              "     'charspan': [0, 1]}],\n",
              "   'orig': '4',\n",
              "   'text': '4'},\n",
              "  {'self_ref': '#/texts/120',\n",
              "   'parent': {'$ref': '#/pictures/1'},\n",
              "   'children': [],\n",
              "   'content_layer': 'body',\n",
              "   'label': 'text',\n",
              "   'prov': [{'page_no': 5,\n",
              "     'bbox': {'l': 200.406,\n",
              "      't': 590.29,\n",
              "      'r': 225.923,\n",
              "      'b': 583.137,\n",
              "      'coord_origin': 'BOTTOMLEFT'},\n",
              "     'charspan': [0, 7]}],\n",
              "   'orig': 'Manuals',\n",
              "   'text': 'Manuals'},\n",
              "  {'self_ref': '#/texts/121',\n",
              "   'parent': {'$ref': '#/pictures/1'},\n",
              "   'children': [],\n",
              "   'content_layer': 'body',\n",
              "   'label': 'text',\n",
              "   'prov': [{'page_no': 5,\n",
              "     'bbox': {'l': 184.248,\n",
              "      't': 572.745,\n",
              "      'r': 188.152,\n",
              "      'b': 565.592,\n",
              "      'coord_origin': 'BOTTOMLEFT'},\n",
              "     'charspan': [0, 1]}],\n",
              "   'orig': '8',\n",
              "   'text': '8'},\n",
              "  {'self_ref': '#/texts/122',\n",
              "   'parent': {'$ref': '#/pictures/1'},\n",
              "   'children': [],\n",
              "   'content_layer': 'body',\n",
              "   'label': 'text',\n",
              "   'prov': [{'page_no': 5,\n",
              "     'bbox': {'l': 180.076,\n",
              "      't': 600.136,\n",
              "      'r': 202.956,\n",
              "      'b': 592.983,\n",
              "      'coord_origin': 'BOTTOMLEFT'},\n",
              "     'charspan': [0, 7]}],\n",
              "   'orig': 'Patents',\n",
              "   'text': 'Patents'},\n",
              "  {'self_ref': '#/texts/123',\n",
              "   'parent': {'$ref': '#/pictures/1'},\n",
              "   'children': [],\n",
              "   'content_layer': 'body',\n",
              "   'label': 'text',\n",
              "   'prov': [{'page_no': 5,\n",
              "     'bbox': {'l': 173.159,\n",
              "      't': 578.116,\n",
              "      'r': 177.064,\n",
              "      'b': 570.963,\n",
              "      'coord_origin': 'BOTTOMLEFT'},\n",
              "     'charspan': [0, 1]}],\n",
              "   'orig': '5',\n",
              "   'text': '5'},\n",
              "  {'self_ref': '#/texts/124',\n",
              "   'parent': {'$ref': '#/pictures/1'},\n",
              "   'children': [],\n",
              "   'content_layer': 'body',\n",
              "   'label': 'text',\n",
              "   'prov': [{'page_no': 5,\n",
              "     'bbox': {'l': 131.989,\n",
              "      't': 599.517,\n",
              "      'r': 155.793,\n",
              "      'b': 592.364,\n",
              "      'coord_origin': 'BOTTOMLEFT'},\n",
              "     'charspan': [0, 7]}],\n",
              "   'orig': 'Science',\n",
              "   'text': 'Science'},\n",
              "  {'self_ref': '#/texts/125',\n",
              "   'parent': {'$ref': '#/pictures/1'},\n",
              "   'children': [],\n",
              "   'content_layer': 'body',\n",
              "   'label': 'text',\n",
              "   'prov': [{'page_no': 5,\n",
              "     'bbox': {'l': 159.913,\n",
              "      't': 577.778,\n",
              "      'r': 163.818,\n",
              "      'b': 570.625,\n",
              "      'coord_origin': 'BOTTOMLEFT'},\n",
              "     'charspan': [0, 1]}],\n",
              "   'orig': '9',\n",
              "   'text': '9'},\n",
              "  {'self_ref': '#/texts/126',\n",
              "   'parent': {'$ref': '#/pictures/1'},\n",
              "   'children': [],\n",
              "   'content_layer': 'body',\n",
              "   'label': 'text',\n",
              "   'prov': [{'page_no': 5,\n",
              "     'bbox': {'l': 98.842,\n",
              "      't': 588.647,\n",
              "      'r': 135.994,\n",
              "      'b': 581.495,\n",
              "      'coord_origin': 'BOTTOMLEFT'},\n",
              "     'charspan': [0, 11]}],\n",
              "   'orig': 'Spec sheets',\n",
              "   'text': 'Spec sheets'},\n",
              "  {'self_ref': '#/texts/127',\n",
              "   'parent': {'$ref': '#/pictures/1'},\n",
              "   'children': [],\n",
              "   'content_layer': 'body',\n",
              "   'label': 'text',\n",
              "   'prov': [{'page_no': 5,\n",
              "     'bbox': {'l': 149.112,\n",
              "      't': 571.849,\n",
              "      'r': 153.017,\n",
              "      'b': 564.696,\n",
              "      'coord_origin': 'BOTTOMLEFT'},\n",
              "     'charspan': [0, 1]}],\n",
              "   'orig': '4',\n",
              "   'text': '4'},\n",
              "  {'self_ref': '#/texts/128',\n",
              "   'parent': {'$ref': '#/pictures/1'},\n",
              "   'children': [],\n",
              "   'content_layer': 'body',\n",
              "   'label': 'text',\n",
              "   'prov': [{'page_no': 5,\n",
              "     'bbox': {'l': 117.708,\n",
              "      't': 615.812,\n",
              "      'r': 220.587,\n",
              "      'b': 606.275,\n",
              "      'coord_origin': 'BOTTOMLEFT'},\n",
              "     'charspan': [0, 22]}],\n",
              "   'orig': 'Documents per Category',\n",
              "   'text': 'Documents per Category'},\n",
              "  {'self_ref': '#/texts/129',\n",
              "   'parent': {'$ref': '#/pictures/1'},\n",
              "   'children': [],\n",
              "   'content_layer': 'body',\n",
              "   'label': 'text',\n",
              "   'prov': [{'page_no': 5,\n",
              "     'bbox': {'l': 79.205,\n",
              "      't': 405.166,\n",
              "      'r': 126.068,\n",
              "      'b': 398.013,\n",
              "      'coord_origin': 'BOTTOMLEFT'},\n",
              "     'charspan': [0, 14]}],\n",
              "   'orig': 'Annual Reports',\n",
              "   'text': 'Annual Reports'},\n",
              "  {'self_ref': '#/texts/130',\n",
              "   'parent': {'$ref': '#/pictures/1'},\n",
              "   'children': [],\n",
              "   'content_layer': 'body',\n",
              "   'label': 'text',\n",
              "   'prov': [{'page_no': 5,\n",
              "     'bbox': {'l': 137.83,\n",
              "      't': 416.381,\n",
              "      'r': 153.449,\n",
              "      'b': 409.228,\n",
              "      'coord_origin': 'BOTTOMLEFT'},\n",
              "     'charspan': [0, 4]}],\n",
              "   'orig': '1554',\n",
              "   'text': '1554'},\n",
              "  {'self_ref': '#/texts/131',\n",
              "   'parent': {'$ref': '#/pictures/1'},\n",
              "   'children': [],\n",
              "   'content_layer': 'body',\n",
              "   'label': 'text',\n",
              "   'prov': [{'page_no': 5,\n",
              "     'bbox': {'l': 211.518,\n",
              "      't': 403.915,\n",
              "      'r': 250.856,\n",
              "      'b': 396.763,\n",
              "      'coord_origin': 'BOTTOMLEFT'},\n",
              "     'charspan': [0, 12]}],\n",
              "   'orig': 'CCPdf (misc)',\n",
              "   'text': 'CCPdf (misc)'},\n",
              "  {'self_ref': '#/texts/132',\n",
              "   'parent': {'$ref': '#/pictures/1'},\n",
              "   'children': [],\n",
              "   'content_layer': 'body',\n",
              "   'label': 'text',\n",
              "   'prov': [{'page_no': 5,\n",
              "     'bbox': {'l': 184.441,\n",
              "      't': 415.699,\n",
              "      'r': 200.061,\n",
              "      'b': 408.546,\n",
              "      'coord_origin': 'BOTTOMLEFT'},\n",
              "     'charspan': [0, 4]}],\n",
              "   'orig': '1090',\n",
              "   'text': '1090'},\n",
              "  {'self_ref': '#/texts/133',\n",
              "   'parent': {'$ref': '#/pictures/1'},\n",
              "   'children': [],\n",
              "   'content_layer': 'body',\n",
              "   'label': 'text',\n",
              "   'prov': [{'page_no': 5,\n",
              "     'bbox': {'l': 215.664,\n",
              "      't': 447.261,\n",
              "      'r': 279.332,\n",
              "      'b': 440.108,\n",
              "      'coord_origin': 'BOTTOMLEFT'},\n",
              "     'charspan': [0, 19]}],\n",
              "   'orig': 'Law and Regulations',\n",
              "   'text': 'Law and Regulations'},\n",
              "  {'self_ref': '#/texts/134',\n",
              "   'parent': {'$ref': '#/pictures/1'},\n",
              "   'children': [],\n",
              "   'content_layer': 'body',\n",
              "   'label': 'text',\n",
              "   'prov': [{'page_no': 5,\n",
              "     'bbox': {'l': 190.615,\n",
              "      't': 439.342,\n",
              "      'r': 198.424,\n",
              "      'b': 432.189,\n",
              "      'coord_origin': 'BOTTOMLEFT'},\n",
              "     'charspan': [0, 2]}],\n",
              "   'orig': '68',\n",
              "   'text': '68'},\n",
              "  {'self_ref': '#/texts/135',\n",
              "   'parent': {'$ref': '#/pictures/1'},\n",
              "   'children': [],\n",
              "   'content_layer': 'body',\n",
              "   'label': 'text',\n",
              "   'prov': [{'page_no': 5,\n",
              "     'bbox': {'l': 187.757,\n",
              "      't': 475.885,\n",
              "      'r': 213.274,\n",
              "      'b': 468.732,\n",
              "      'coord_origin': 'BOTTOMLEFT'},\n",
              "     'charspan': [0, 7]}],\n",
              "   'orig': 'Manuals',\n",
              "   'text': 'Manuals'},\n",
              "  {'self_ref': '#/texts/136',\n",
              "   'parent': {'$ref': '#/pictures/1'},\n",
              "   'children': [],\n",
              "   'content_layer': 'body',\n",
              "   'label': 'text',\n",
              "   'prov': [{'page_no': 5,\n",
              "     'bbox': {'l': 173.436,\n",
              "      't': 454.955,\n",
              "      'r': 185.151,\n",
              "      'b': 447.802,\n",
              "      'coord_origin': 'BOTTOMLEFT'},\n",
              "     'charspan': [0, 3]}],\n",
              "   'orig': '989',\n",
              "   'text': '989'},\n",
              "  {'self_ref': '#/texts/137',\n",
              "   'parent': {'$ref': '#/pictures/1'},\n",
              "   'children': [],\n",
              "   'content_layer': 'body',\n",
              "   'label': 'text',\n",
              "   'prov': [{'page_no': 5,\n",
              "     'bbox': {'l': 122.044,\n",
              "      't': 473.185,\n",
              "      'r': 144.924,\n",
              "      'b': 466.032,\n",
              "      'coord_origin': 'BOTTOMLEFT'},\n",
              "     'charspan': [0, 7]}],\n",
              "   'orig': 'Patents',\n",
              "   'text': 'Patents'},\n",
              "  {'self_ref': '#/texts/138',\n",
              "   'parent': {'$ref': '#/pictures/1'},\n",
              "   'children': [],\n",
              "   'content_layer': 'body',\n",
              "   'label': 'text',\n",
              "   'prov': [{'page_no': 5,\n",
              "     'bbox': {'l': 150.076,\n",
              "      't': 453.482,\n",
              "      'r': 161.79,\n",
              "      'b': 446.329,\n",
              "      'coord_origin': 'BOTTOMLEFT'},\n",
              "     'charspan': [0, 3]}],\n",
              "   'orig': '151',\n",
              "   'text': '151'},\n",
              "  {'self_ref': '#/texts/139',\n",
              "   'parent': {'$ref': '#/pictures/1'},\n",
              "   'children': [],\n",
              "   'content_layer': 'body',\n",
              "   'label': 'text',\n",
              "   'prov': [{'page_no': 5,\n",
              "     'bbox': {'l': 112.184,\n",
              "      't': 466.791,\n",
              "      'r': 135.988,\n",
              "      'b': 459.638,\n",
              "      'coord_origin': 'BOTTOMLEFT'},\n",
              "     'charspan': [0, 7]}],\n",
              "   'orig': 'Science',\n",
              "   'text': 'Science'},\n",
              "  {'self_ref': '#/texts/140',\n",
              "   'parent': {'$ref': '#/pictures/1'},\n",
              "   'children': [],\n",
              "   'content_layer': 'body',\n",
              "   'label': 'text',\n",
              "   'prov': [{'page_no': 5,\n",
              "     'bbox': {'l': 145.198,\n",
              "      't': 449.994,\n",
              "      'r': 156.913,\n",
              "      'b': 442.842,\n",
              "      'coord_origin': 'BOTTOMLEFT'},\n",
              "     'charspan': [0, 3]}],\n",
              "   'orig': '132',\n",
              "   'text': '132'},\n",
              "  {'self_ref': '#/texts/141',\n",
              "   'parent': {'$ref': '#/pictures/1'},\n",
              "   'children': [],\n",
              "   'content_layer': 'body',\n",
              "   'label': 'text',\n",
              "   'prov': [{'page_no': 5,\n",
              "     'bbox': {'l': 94.579,\n",
              "      't': 462.469,\n",
              "      'r': 131.731,\n",
              "      'b': 455.316,\n",
              "      'coord_origin': 'BOTTOMLEFT'},\n",
              "     'charspan': [0, 11]}],\n",
              "   'orig': 'Spec sheets',\n",
              "   'text': 'Spec sheets'},\n",
              "  {'self_ref': '#/texts/142',\n",
              "   'parent': {'$ref': '#/pictures/1'},\n",
              "   'children': [],\n",
              "   'content_layer': 'body',\n",
              "   'label': 'text',\n",
              "   'prov': [{'page_no': 5,\n",
              "     'bbox': {'l': 144.83,\n",
              "      't': 447.637,\n",
              "      'r': 152.64,\n",
              "      'b': 440.484,\n",
              "      'coord_origin': 'BOTTOMLEFT'},\n",
              "     'charspan': [0, 2]}],\n",
              "   'orig': '24',\n",
              "   'text': '24'},\n",
              "  {'self_ref': '#/texts/143',\n",
              "   'parent': {'$ref': '#/pictures/1'},\n",
              "   'children': [],\n",
              "   'content_layer': 'body',\n",
              "   'label': 'text',\n",
              "   'prov': [{'page_no': 5,\n",
              "     'bbox': {'l': 128.986,\n",
              "      't': 493.959,\n",
              "      'r': 209.276,\n",
              "      'b': 484.422,\n",
              "      'coord_origin': 'BOTTOMLEFT'},\n",
              "     'charspan': [0, 18]}],\n",
              "   'orig': 'Pages per Category',\n",
              "   'text': 'Pages per Category'},\n",
              "  {'self_ref': '#/texts/144',\n",
              "   'parent': {'$ref': '#/pictures/1'},\n",
              "   'children': [],\n",
              "   'content_layer': 'body',\n",
              "   'label': 'text',\n",
              "   'prov': [{'page_no': 5,\n",
              "     'bbox': {'l': 154.857,\n",
              "      't': 377.018,\n",
              "      'r': 191.628,\n",
              "      'b': 369.07,\n",
              "      'coord_origin': 'BOTTOMLEFT'},\n",
              "     'charspan': [0, 10]}],\n",
              "   'orig': 'Categories',\n",
              "   'text': 'Categories'},\n",
              "  {'self_ref': '#/texts/145',\n",
              "   'parent': {'$ref': '#/pictures/1'},\n",
              "   'children': [],\n",
              "   'content_layer': 'body',\n",
              "   'label': 'text',\n",
              "   'prov': [{'page_no': 5,\n",
              "     'bbox': {'l': 110.413,\n",
              "      't': 367.009,\n",
              "      'r': 162.48,\n",
              "      'b': 359.061,\n",
              "      'coord_origin': 'BOTTOMLEFT'},\n",
              "     'charspan': [0, 14]}],\n",
              "   'orig': 'Annual Reports',\n",
              "   'text': 'Annual Reports'},\n",
              "  {'self_ref': '#/texts/146',\n",
              "   'parent': {'$ref': '#/pictures/1'},\n",
              "   'children': [],\n",
              "   'content_layer': 'body',\n",
              "   'label': 'text',\n",
              "   'prov': [{'page_no': 5,\n",
              "     'bbox': {'l': 110.413,\n",
              "      't': 356.999,\n",
              "      'r': 154.121,\n",
              "      'b': 349.052,\n",
              "      'coord_origin': 'BOTTOMLEFT'},\n",
              "     'charspan': [0, 12]}],\n",
              "   'orig': 'CCPdf (misc)',\n",
              "   'text': 'CCPdf (misc)'},\n",
              "  {'self_ref': '#/texts/147',\n",
              "   'parent': {'$ref': '#/pictures/1'},\n",
              "   'children': [],\n",
              "   'content_layer': 'body',\n",
              "   'label': 'text',\n",
              "   'prov': [{'page_no': 5,\n",
              "     'bbox': {'l': 110.413,\n",
              "      't': 346.99,\n",
              "      'r': 181.152,\n",
              "      'b': 339.043,\n",
              "      'coord_origin': 'BOTTOMLEFT'},\n",
              "     'charspan': [0, 19]}],\n",
              "   'orig': 'Law and Regulations',\n",
              "   'text': 'Law and Regulations'},\n",
              "  {'self_ref': '#/texts/148',\n",
              "   'parent': {'$ref': '#/pictures/1'},\n",
              "   'children': [],\n",
              "   'content_layer': 'body',\n",
              "   'label': 'text',\n",
              "   'prov': [{'page_no': 5,\n",
              "     'bbox': {'l': 110.413,\n",
              "      't': 336.981,\n",
              "      'r': 138.765,\n",
              "      'b': 329.034,\n",
              "      'coord_origin': 'BOTTOMLEFT'},\n",
              "     'charspan': [0, 7]}],\n",
              "   'orig': 'Manuals',\n",
              "   'text': 'Manuals'},\n",
              "  {'self_ref': '#/texts/149',\n",
              "   'parent': {'$ref': '#/pictures/1'},\n",
              "   'children': [],\n",
              "   'content_layer': 'body',\n",
              "   'label': 'text',\n",
              "   'prov': [{'page_no': 5,\n",
              "     'bbox': {'l': 213.883,\n",
              "      't': 367.009,\n",
              "      'r': 239.304,\n",
              "      'b': 359.061,\n",
              "      'coord_origin': 'BOTTOMLEFT'},\n",
              "     'charspan': [0, 7]}],\n",
              "   'orig': 'Patents',\n",
              "   'text': 'Patents'},\n",
              "  {'self_ref': '#/texts/150',\n",
              "   'parent': {'$ref': '#/pictures/1'},\n",
              "   'children': [],\n",
              "   'content_layer': 'body',\n",
              "   'label': 'text',\n",
              "   'prov': [{'page_no': 5,\n",
              "     'bbox': {'l': 213.883,\n",
              "      't': 356.999,\n",
              "      'r': 240.332,\n",
              "      'b': 349.052,\n",
              "      'coord_origin': 'BOTTOMLEFT'},\n",
              "     'charspan': [0, 7]}],\n",
              "   'orig': 'Science',\n",
              "   'text': 'Science'},\n",
              "  {'self_ref': '#/texts/151',\n",
              "   'parent': {'$ref': '#/pictures/1'},\n",
              "   'children': [],\n",
              "   'content_layer': 'body',\n",
              "   'label': 'text',\n",
              "   'prov': [{'page_no': 5,\n",
              "     'bbox': {'l': 213.883,\n",
              "      't': 346.99,\n",
              "      'r': 255.163,\n",
              "      'b': 339.043,\n",
              "      'coord_origin': 'BOTTOMLEFT'},\n",
              "     'charspan': [0, 11]}],\n",
              "   'orig': 'Spec sheets',\n",
              "   'text': 'Spec sheets'},\n",
              "  {'self_ref': '#/texts/152',\n",
              "   'parent': {'$ref': '#/body'},\n",
              "   'children': [],\n",
              "   'content_layer': 'body',\n",
              "   'label': 'section_header',\n",
              "   'prov': [{'page_no': 5,\n",
              "     'bbox': {'l': 54.0,\n",
              "      't': 266.972,\n",
              "      'r': 211.582,\n",
              "      'b': 257.16499999999996,\n",
              "      'coord_origin': 'BOTTOMLEFT'},\n",
              "     'charspan': [0, 28]}],\n",
              "   'orig': '5.3 Benchmarking Methodology',\n",
              "   'text': '5.3 Benchmarking Methodology',\n",
              "   'level': 1},\n",
              "  {'self_ref': '#/texts/153',\n",
              "   'parent': {'$ref': '#/body'},\n",
              "   'children': [],\n",
              "   'content_layer': 'body',\n",
              "   'label': 'text',\n",
              "   'prov': [{'page_no': 5,\n",
              "     'bbox': {'l': 54.0,\n",
              "      't': 249.17399999999998,\n",
              "      'r': 292.505,\n",
              "      'b': 218.70399999999995,\n",
              "      'coord_origin': 'BOTTOMLEFT'},\n",
              "     'charspan': [0, 174]}],\n",
              "   'orig': 'We implemented several measures to enable a fair and reproducible benchmark across all tested assets. Specifically, the experimental setup accounts for the following factors:',\n",
              "   'text': 'We implemented several measures to enable a fair and reproducible benchmark across all tested assets. Specifically, the experimental setup accounts for the following factors:'},\n",
              "  {'self_ref': '#/texts/154',\n",
              "   'parent': {'$ref': '#/groups/4'},\n",
              "   'children': [],\n",
              "   'content_layer': 'body',\n",
              "   'label': 'list_item',\n",
              "   'prov': [{'page_no': 5,\n",
              "     'bbox': {'l': 58.483,\n",
              "      't': 210.43899999999996,\n",
              "      'r': 292.504,\n",
              "      'b': 147.09199999999998,\n",
              "      'coord_origin': 'BOTTOMLEFT'},\n",
              "     'charspan': [0, 304]}],\n",
              "   'orig': '· All assets are installed in the latest available versions, in a clean Python environment, and configured to use the state-of-the-art processing options and models, where applicable. We selectively disabled non-essential functionalities to achieve a compatible feature-set across all compared libraries.',\n",
              "   'text': 'All assets are installed in the latest available versions, in a clean Python environment, and configured to use the state-of-the-art processing options and models, where applicable. We selectively disabled non-essential functionalities to achieve a compatible feature-set across all compared libraries.',\n",
              "   'enumerated': False,\n",
              "   'marker': '·'},\n",
              "  {'self_ref': '#/texts/155',\n",
              "   'parent': {'$ref': '#/groups/4'},\n",
              "   'children': [],\n",
              "   'content_layer': 'body',\n",
              "   'label': 'list_item',\n",
              "   'prov': [{'page_no': 5,\n",
              "     'bbox': {'l': 58.483,\n",
              "      't': 140.322,\n",
              "      'r': 292.504,\n",
              "      'b': 87.93399999999997,\n",
              "      'coord_origin': 'BOTTOMLEFT'},\n",
              "     'charspan': [0, 227]}],\n",
              "   'orig': '· When running experiments on CPU, we inform all assets of the desired CPU thread budget of 8 threads, via the OMP NUM THREADS environment variable and any accepted configuration options. The L4 GPU on our AWS EC2 VM is hidden.',\n",
              "   'text': 'When running experiments on CPU, we inform all assets of the desired CPU thread budget of 8 threads, via the OMP NUM THREADS environment variable and any accepted configuration options. The L4 GPU on our AWS EC2 VM is hidden.',\n",
              "   'enumerated': False,\n",
              "   'marker': '·'},\n",
              "  {'self_ref': '#/texts/156',\n",
              "   'parent': {'$ref': '#/groups/4'},\n",
              "   'children': [],\n",
              "   'content_layer': 'body',\n",
              "   'label': 'list_item',\n",
              "   'prov': [{'page_no': 5,\n",
              "     'bbox': {'l': 323.983,\n",
              "      't': 614.322,\n",
              "      'r': 558.004,\n",
              "      'b': 572.893,\n",
              "      'coord_origin': 'BOTTOMLEFT'},\n",
              "     'charspan': [0, 209]}],\n",
              "   'orig': '· When running experiments on the L4 GPU, we enable CUDAacceleration in all accepted configuration options, ensure the GPU is visible and all required runtimes for AI inference are installed with CUDA support.',\n",
              "   'text': 'When running experiments on the L4 GPU, we enable CUDAacceleration in all accepted configuration options, ensure the GPU is visible and all required runtimes for AI inference are installed with CUDA support.',\n",
              "   'enumerated': False,\n",
              "   'marker': '·'},\n",
              "  {'self_ref': '#/texts/157',\n",
              "   'parent': {'$ref': '#/body'},\n",
              "   'children': [],\n",
              "   'content_layer': 'body',\n",
              "   'label': 'text',\n",
              "   'prov': [{'page_no': 5,\n",
              "     'bbox': {'l': 319.5,\n",
              "      't': 565.817,\n",
              "      'r': 557.995,\n",
              "      'b': 546.306,\n",
              "      'coord_origin': 'BOTTOMLEFT'},\n",
              "     'charspan': [0, 100]}],\n",
              "   'orig': 'Table 1 provides an overview of the versions and configuration options we considered for each asset.',\n",
              "   'text': 'Table 1 provides an overview of the versions and configuration options we considered for each asset.'},\n",
              "  {'self_ref': '#/texts/158',\n",
              "   'parent': {'$ref': '#/body'},\n",
              "   'children': [],\n",
              "   'content_layer': 'body',\n",
              "   'label': 'section_header',\n",
              "   'prov': [{'page_no': 5,\n",
              "     'bbox': {'l': 319.5,\n",
              "      't': 533.867,\n",
              "      'r': 377.984,\n",
              "      'b': 524.06,\n",
              "      'coord_origin': 'BOTTOMLEFT'},\n",
              "     'charspan': [0, 11]}],\n",
              "   'orig': '5.4 Results',\n",
              "   'text': '5.4 Results',\n",
              "   'level': 1},\n",
              "  {'self_ref': '#/texts/159',\n",
              "   'parent': {'$ref': '#/pictures/2'},\n",
              "   'children': [],\n",
              "   'content_layer': 'body',\n",
              "   'label': 'caption',\n",
              "   'prov': [{'page_no': 5,\n",
              "     'bbox': {'l': 319.5,\n",
              "      't': 331.78,\n",
              "      'r': 558.005,\n",
              "      'b': 279.39200000000005,\n",
              "      'coord_origin': 'BOTTOMLEFT'},\n",
              "     'charspan': [0, 289]}],\n",
              "   'orig': 'Figure 3: Distribution of conversion times for all documents, ordered by number of pages in a document, on all system configurations. Every dot represents one document. Log/log scale is used to even the spacing, since both number of pages and conversion times have long-tail distributions.',\n",
              "   'text': 'Figure 3: Distribution of conversion times for all documents, ordered by number of pages in a document, on all system configurations. Every dot represents one document. Log/log scale is used to even the spacing, since both number of pages and conversion times have long-tail distributions.'},\n",
              "  {'self_ref': '#/texts/160',\n",
              "   'parent': {'$ref': '#/pictures/2'},\n",
              "   'children': [],\n",
              "   'content_layer': 'body',\n",
              "   'label': 'text',\n",
              "   'prov': [{'page_no': 5,\n",
              "     'bbox': {'l': 380.626,\n",
              "      't': 360.352,\n",
              "      'r': 390.638,\n",
              "      'b': 352.995,\n",
              "      'coord_origin': 'BOTTOMLEFT'},\n",
              "     'charspan': [0, 4]}],\n",
              "   'orig': '10 0',\n",
              "   'text': '10 0'},\n",
              "  {'self_ref': '#/texts/161',\n",
              "   'parent': {'$ref': '#/pictures/2'},\n",
              "   'children': [],\n",
              "   'content_layer': 'body',\n",
              "   'label': 'text',\n",
              "   'prov': [{'page_no': 5,\n",
              "     'bbox': {'l': 425.716,\n",
              "      't': 360.403,\n",
              "      'r': 435.728,\n",
              "      'b': 353.046,\n",
              "      'coord_origin': 'BOTTOMLEFT'},\n",
              "     'charspan': [0, 4]}],\n",
              "   'orig': '10 1',\n",
              "   'text': '10 1'},\n",
              "  {'self_ref': '#/texts/162',\n",
              "   'parent': {'$ref': '#/pictures/2'},\n",
              "   'children': [],\n",
              "   'content_layer': 'body',\n",
              "   'label': 'text',\n",
              "   'prov': [{'page_no': 5,\n",
              "     'bbox': {'l': 470.806,\n",
              "      't': 360.352,\n",
              "      'r': 480.818,\n",
              "      'b': 352.995,\n",
              "      'coord_origin': 'BOTTOMLEFT'},\n",
              "     'charspan': [0, 4]}],\n",
              "   'orig': '10 2',\n",
              "   'text': '10 2'},\n",
              "  {'self_ref': '#/texts/163',\n",
              "   'parent': {'$ref': '#/pictures/2'},\n",
              "   'children': [],\n",
              "   'content_layer': 'body',\n",
              "   'label': 'text',\n",
              "   'prov': [{'page_no': 5,\n",
              "     'bbox': {'l': 424.918,\n",
              "      't': 351.257,\n",
              "      'r': 474.979,\n",
              "      'b': 344.504,\n",
              "      'coord_origin': 'BOTTOMLEFT'},\n",
              "     'charspan': [0, 15]}],\n",
              "   'orig': 'Number of pages',\n",
              "   'text': 'Number of pages'},\n",
              "  {'self_ref': '#/texts/164',\n",
              "   'parent': {'$ref': '#/pictures/2'},\n",
              "   'children': [],\n",
              "   'content_layer': 'body',\n",
              "   'label': 'text',\n",
              "   'prov': [{'page_no': 5,\n",
              "     'bbox': {'l': 364.939,\n",
              "      't': 396.043,\n",
              "      'r': 374.952,\n",
              "      'b': 388.686,\n",
              "      'coord_origin': 'BOTTOMLEFT'},\n",
              "     'charspan': [0, 4]}],\n",
              "   'orig': '10 0',\n",
              "   'text': '10 0'},\n",
              "  {'self_ref': '#/texts/165',\n",
              "   'parent': {'$ref': '#/pictures/2'},\n",
              "   'children': [],\n",
              "   'content_layer': 'body',\n",
              "   'label': 'text',\n",
              "   'prov': [{'page_no': 5,\n",
              "     'bbox': {'l': 364.939,\n",
              "      't': 430.779,\n",
              "      'r': 374.952,\n",
              "      'b': 423.422,\n",
              "      'coord_origin': 'BOTTOMLEFT'},\n",
              "     'charspan': [0, 4]}],\n",
              "   'orig': '10 1',\n",
              "   'text': '10 1'},\n",
              "  {'self_ref': '#/texts/166',\n",
              "   'parent': {'$ref': '#/pictures/2'},\n",
              "   'children': [],\n",
              "   'content_layer': 'body',\n",
              "   'label': 'text',\n",
              "   'prov': [{'page_no': 5,\n",
              "     'bbox': {'l': 364.939,\n",
              "      't': 465.994,\n",
              "      'r': 374.952,\n",
              "      'b': 458.637,\n",
              "      'coord_origin': 'BOTTOMLEFT'},\n",
              "     'charspan': [0, 4]}],\n",
              "   'orig': '10 2',\n",
              "   'text': '10 2'},\n",
              "  {'self_ref': '#/texts/167',\n",
              "   'parent': {'$ref': '#/pictures/2'},\n",
              "   'children': [],\n",
              "   'content_layer': 'body',\n",
              "   'label': 'text',\n",
              "   'prov': [{'page_no': 5,\n",
              "     'bbox': {'l': 364.939,\n",
              "      't': 500.969,\n",
              "      'r': 374.952,\n",
              "      'b': 493.612,\n",
              "      'coord_origin': 'BOTTOMLEFT'},\n",
              "     'charspan': [0, 4]}],\n",
              "   'orig': '10 3',\n",
              "   'text': '10 3'},\n",
              "  {'self_ref': '#/texts/168',\n",
              "   'parent': {'$ref': '#/pictures/2'},\n",
              "   'children': [],\n",
              "   'content_layer': 'body',\n",
              "   'label': 'text',\n",
              "   'prov': [{'page_no': 5,\n",
              "     'bbox': {'l': 356.031,\n",
              "      't': 440.464,\n",
              "      'r': 362.784,\n",
              "      'b': 430.691,\n",
              "      'coord_origin': 'BOTTOMLEFT'},\n",
              "     'charspan': [0, 3]}],\n",
              "   'orig': 'sec',\n",
              "   'text': 'sec'},\n",
              "  {'self_ref': '#/texts/169',\n",
              "   'parent': {'$ref': '#/pictures/2'},\n",
              "   'children': [],\n",
              "   'content_layer': 'body',\n",
              "   'label': 'text',\n",
              "   'prov': [{'page_no': 5,\n",
              "     'bbox': {'l': 400.88,\n",
              "      't': 503.903,\n",
              "      'r': 425.313,\n",
              "      'b': 497.15,\n",
              "      'coord_origin': 'BOTTOMLEFT'},\n",
              "     'charspan': [0, 7]}],\n",
              "   'orig': 'x86 CPU',\n",
              "   'text': 'x86 CPU'},\n",
              "  {'self_ref': '#/texts/170',\n",
              "   'parent': {'$ref': '#/pictures/2'},\n",
              "   'children': [],\n",
              "   'content_layer': 'body',\n",
              "   'label': 'text',\n",
              "   'prov': [{'page_no': 5,\n",
              "     'bbox': {'l': 400.88,\n",
              "      't': 495.398,\n",
              "      'r': 423.4,\n",
              "      'b': 488.645,\n",
              "      'coord_origin': 'BOTTOMLEFT'},\n",
              "     'charspan': [0, 6]}],\n",
              "   'orig': 'M3 Max',\n",
              "   'text': 'M3 Max'},\n",
              "  {'self_ref': '#/texts/171',\n",
              "   'parent': {'$ref': '#/pictures/2'},\n",
              "   'children': [],\n",
              "   'content_layer': 'body',\n",
              "   'label': 'text',\n",
              "   'prov': [{'page_no': 5,\n",
              "     'bbox': {'l': 400.88,\n",
              "      't': 486.893,\n",
              "      'r': 421.87,\n",
              "      'b': 480.14,\n",
              "      'coord_origin': 'BOTTOMLEFT'},\n",
              "     'charspan': [0, 6]}],\n",
              "   'orig': 'L4 GPU',\n",
              "   'text': 'L4 GPU'},\n",
              "  {'self_ref': '#/texts/172',\n",
              "   'parent': {'$ref': '#/body'},\n",
              "   'children': [],\n",
              "   'content_layer': 'body',\n",
              "   'label': 'text',\n",
              "   'prov': [{'page_no': 5,\n",
              "     'bbox': {'l': 319.5,\n",
              "      't': 261.59899999999993,\n",
              "      'r': 558.005,\n",
              "      'b': 175.947,\n",
              "      'coord_origin': 'BOTTOMLEFT'},\n",
              "     'charspan': [0, 449]}],\n",
              "   'orig': \"Runtime Characteristics To analyze Docling's runtime characteristics, we begin by exploring the relationship between document length (in pages) and conversion time. As shown in Figure 3, this relationship is not strictly linear, as documents differ in their frequency of tables and bitmap elements (i.e., scanned content). This requires OCR or table structure recognition models to engage dynamically when layout analysis has detected such elements.\",\n",
              "   'text': \"Runtime Characteristics To analyze Docling's runtime characteristics, we begin by exploring the relationship between document length (in pages) and conversion time. As shown in Figure 3, this relationship is not strictly linear, as documents differ in their frequency of tables and bitmap elements (i.e., scanned content). This requires OCR or table structure recognition models to engage dynamically when layout analysis has detected such elements.\"},\n",
              "  {'self_ref': '#/texts/173',\n",
              "   'parent': {'$ref': '#/body'},\n",
              "   'children': [],\n",
              "   'content_layer': 'body',\n",
              "   'label': 'text',\n",
              "   'prov': [{'page_no': 5,\n",
              "     'bbox': {'l': 319.5,\n",
              "      't': 173.19799999999998,\n",
              "      'r': 558.005,\n",
              "      'b': 87.93399999999997,\n",
              "      'coord_origin': 'BOTTOMLEFT'},\n",
              "     'charspan': [0, 463]},\n",
              "    {'page_no': 6,\n",
              "     'bbox': {'l': 54.0,\n",
              "      't': 734.523,\n",
              "      'r': 292.505,\n",
              "      'b': 704.054,\n",
              "      'coord_origin': 'BOTTOMLEFT'},\n",
              "     'charspan': [464, 622]}],\n",
              "   'orig': 'By breaking down the runtimes to a page level, we receive a more intuitive measure for the conversion speed (see also Figure 4). Processing a page in our benchmark dataset requires between 0.6 sec (5 th percentile) and 16.3 sec (95 th percentile), with a median of 0.79 sec on the x86 CPU. On the M3 Max SoC, it achieves 0.26/0.32/6.48 seconds per page (.05/median/.95), and on the Nvidia L4 GPU it achieves 57/114/2081 milliseconds per page (.05/median/.95). The large range between 5 and 95 percentiles results from the highly different complexity of content across pages (i.e., almost empty pages vs. full-page tables).',\n",
              "   'text': 'By breaking down the runtimes to a page level, we receive a more intuitive measure for the conversion speed (see also Figure 4). Processing a page in our benchmark dataset requires between 0.6 sec (5 th percentile) and 16.3 sec (95 th percentile), with a median of 0.79 sec on the x86 CPU. On the M3 Max SoC, it achieves 0.26/0.32/6.48 seconds per page (.05/median/.95), and on the Nvidia L4 GPU it achieves 57/114/2081 milliseconds per page (.05/median/.95). The large range between 5 and 95 percentiles results from the highly different complexity of content across pages (i.e., almost empty pages vs. full-page tables).'},\n",
              "  {'self_ref': '#/texts/174',\n",
              "   'parent': {'$ref': '#/body'},\n",
              "   'children': [],\n",
              "   'content_layer': 'body',\n",
              "   'label': 'text',\n",
              "   'prov': [{'page_no': 6,\n",
              "     'bbox': {'l': 54.0,\n",
              "      't': 699.525,\n",
              "      'r': 292.505,\n",
              "      'b': 636.178,\n",
              "      'coord_origin': 'BOTTOMLEFT'},\n",
              "     'charspan': [0, 320]}],\n",
              "   'orig': 'Disabling OCR saves 60% of runtime on the x86 CPU and the M3 Max SoC, and 50% on the L4 GPU. Turning off table structure recognition saves 16% of runtime on the x86 CPU and the M3 Max SoC, and 24% on the L4 GPU. Disabling both OCR and table structure recognition saves around 75% of runtime on all system configurations.',\n",
              "   'text': 'Disabling OCR saves 60% of runtime on the x86 CPU and the M3 Max SoC, and 50% on the L4 GPU. Turning off table structure recognition saves 16% of runtime on the x86 CPU and the M3 Max SoC, and 24% on the L4 GPU. Disabling both OCR and table structure recognition saves around 75% of runtime on all system configurations.'},\n",
              "  {'self_ref': '#/texts/175',\n",
              "   'parent': {'$ref': '#/body'},\n",
              "   'children': [],\n",
              "   'content_layer': 'body',\n",
              "   'label': 'text',\n",
              "   'prov': [{'page_no': 6,\n",
              "     'bbox': {'l': 54.0,\n",
              "      't': 621.815,\n",
              "      'r': 292.505,\n",
              "      'b': 558.081,\n",
              "      'coord_origin': 'BOTTOMLEFT'},\n",
              "     'charspan': [0, 297]}],\n",
              "   'orig': \"Profiling Docling's AI Pipeline We analyzed the contributions of Docling's PDF backend and all AI models in the PDF pipeline to the total conversion time. The results are shown in Figure 4. On average, processing a page took 481 ms on the L4 GPU, 3.1 s on the x86 CPU and 1.26 s on the M3 Max SoC.\",\n",
              "   'text': \"Profiling Docling's AI Pipeline We analyzed the contributions of Docling's PDF backend and all AI models in the PDF pipeline to the total conversion time. The results are shown in Figure 4. On average, processing a page took 481 ms on the L4 GPU, 3.1 s on the x86 CPU and 1.26 s on the M3 Max SoC.\"},\n",
              "  {'self_ref': '#/texts/176',\n",
              "   'parent': {'$ref': '#/body'},\n",
              "   'children': [],\n",
              "   'content_layer': 'body',\n",
              "   'label': 'text',\n",
              "   'prov': [{'page_no': 6,\n",
              "     'bbox': {'l': 54.0,\n",
              "      't': 553.552,\n",
              "      'r': 292.505,\n",
              "      'b': 413.493,\n",
              "      'coord_origin': 'BOTTOMLEFT'},\n",
              "     'charspan': [0, 708]}],\n",
              "   'orig': 'It is evident that applying OCR is the most expensive operation. In our benchmark dataset, OCR engages in 578 pages. On average, transcribing a page with EasyOCR took 1.6 s on the L4 GPU, 13 s on the x86 CPU and 5 s on the M3 Max SoC. The layout model spent 44 ms on the L4 GPU, 633 ms on the x86 CPU and 271 ms on the M3 Max SoC on average for each page, making it the cheapest of the AI models, while TableFormer (fast flavour) spent 400 ms on the L4 GPU, 1.74 s on the x86 CPU and 704 ms on the M3 Max SoC on average per table. Regarding the total time spent converting our benchmark dataset, TableFormer had less impact than other AI models, since tables appeared on only 28% of all pages (see Figure 4).',\n",
              "   'text': 'It is evident that applying OCR is the most expensive operation. In our benchmark dataset, OCR engages in 578 pages. On average, transcribing a page with EasyOCR took 1.6 s on the L4 GPU, 13 s on the x86 CPU and 5 s on the M3 Max SoC. The layout model spent 44 ms on the L4 GPU, 633 ms on the x86 CPU and 271 ms on the M3 Max SoC on average for each page, making it the cheapest of the AI models, while TableFormer (fast flavour) spent 400 ms on the L4 GPU, 1.74 s on the x86 CPU and 704 ms on the M3 Max SoC on average per table. Regarding the total time spent converting our benchmark dataset, TableFormer had less impact than other AI models, since tables appeared on only 28% of all pages (see Figure 4).'},\n",
              "  {'self_ref': '#/texts/177',\n",
              "   'parent': {'$ref': '#/body'},\n",
              "   'children': [],\n",
              "   'content_layer': 'body',\n",
              "   'label': 'text',\n",
              "   'prov': [{'page_no': 6,\n",
              "     'bbox': {'l': 54.0,\n",
              "      't': 408.964,\n",
              "      'r': 292.505,\n",
              "      'b': 334.659,\n",
              "      'coord_origin': 'BOTTOMLEFT'},\n",
              "     'charspan': [0, 370]}],\n",
              "   'orig': 'On the L4 GPU, we observe a speedup of 8x (OCR), 14x (Layout model) and 4.3x (Table structure) compared to the x86 CPU and a speedup of 3x (OCR), 6x (Layout model) and 1.7x (Table structure) compared to the M3 Max CPU of our MacBook Pro. This shows that there is no equal benefit for all AI models from the GPU acceleration and there might be potential for optimization.',\n",
              "   'text': 'On the L4 GPU, we observe a speedup of 8x (OCR), 14x (Layout model) and 4.3x (Table structure) compared to the x86 CPU and a speedup of 3x (OCR), 6x (Layout model) and 1.7x (Table structure) compared to the M3 Max CPU of our MacBook Pro. This shows that there is no equal benefit for all AI models from the GPU acceleration and there might be potential for optimization.'},\n",
              "  {'self_ref': '#/texts/178',\n",
              "   'parent': {'$ref': '#/body'},\n",
              "   'children': [],\n",
              "   'content_layer': 'body',\n",
              "   'label': 'text',\n",
              "   'prov': [{'page_no': 6,\n",
              "     'bbox': {'l': 54.0,\n",
              "      't': 330.13,\n",
              "      'r': 292.505,\n",
              "      'b': 277.74199999999996,\n",
              "      'coord_origin': 'BOTTOMLEFT'},\n",
              "     'charspan': [0, 237]}],\n",
              "   'orig': 'The time spent in parsing a PDF page through our docling-parse backend is substantially lower in comparison to the AI models. On average, parsing a PDF page took 81 ms on the x86 CPU and 44 ms on the M3 Max SoC (there is no GPU support).',\n",
              "   'text': 'The time spent in parsing a PDF page through our docling-parse backend is substantially lower in comparison to the AI models. On average, parsing a PDF page took 81 ms on the x86 CPU and 44 ms on the M3 Max SoC (there is no GPU support).'},\n",
              "  {'self_ref': '#/texts/179',\n",
              "   'parent': {'$ref': '#/body'},\n",
              "   'children': [],\n",
              "   'content_layer': 'body',\n",
              "   'label': 'text',\n",
              "   'prov': [{'page_no': 6,\n",
              "     'bbox': {'l': 54.0,\n",
              "      't': 263.38,\n",
              "      'r': 292.505,\n",
              "      'b': 221.563,\n",
              "      'coord_origin': 'BOTTOMLEFT'},\n",
              "     'charspan': [0, 207]}],\n",
              "   'orig': 'Comparison to Other Tools We compare the average times to convert a page between Docling, Marker, MinerU, and Unstructured on the system configurations outlined in section 5.2. Results are shown in Figure 5.',\n",
              "   'text': 'Comparison to Other Tools We compare the average times to convert a page between Docling, Marker, MinerU, and Unstructured on the system configurations outlined in section 5.2. Results are shown in Figure 5.'},\n",
              "  {'self_ref': '#/texts/180',\n",
              "   'parent': {'$ref': '#/body'},\n",
              "   'children': [],\n",
              "   'content_layer': 'body',\n",
              "   'label': 'text',\n",
              "   'prov': [{'page_no': 6,\n",
              "     'bbox': {'l': 54.0,\n",
              "      't': 217.034,\n",
              "      'r': 292.505,\n",
              "      'b': 87.93399999999997,\n",
              "      'coord_origin': 'BOTTOMLEFT'},\n",
              "     'charspan': [0, 661]}],\n",
              "   'orig': 'Without GPU support, Docling leads with 3.1 sec/page (x86 CPU) and 1.27 sec/page (M3 Max SoC), followed closely by MinerU (3.3 sec/page on x86 CPU) and Unstructured (4.2 sec/page on x86 CPU, 2.7 sec/page on M3 Max SoC), while Marker needs over 16 sec/page (x86 CPU) and 4.2 sec/page (M3 Mac SoC). MinerU, despite several efforts to configure its environment, did not finish any run on our MacBook Pro M3 Max. With CUDA acceleration on the Nvidia L4 GPU, the picture changes and MinerU takes the lead over the contenders with 0.21 sec/page, compared to 0.49 sec/page with Docling and 0.86 sec/page with Marker. Unstructured does not profit from GPU acceleration.',\n",
              "   'text': 'Without GPU support, Docling leads with 3.1 sec/page (x86 CPU) and 1.27 sec/page (M3 Max SoC), followed closely by MinerU (3.3 sec/page on x86 CPU) and Unstructured (4.2 sec/page on x86 CPU, 2.7 sec/page on M3 Max SoC), while Marker needs over 16 sec/page (x86 CPU) and 4.2 sec/page (M3 Mac SoC). MinerU, despite several efforts to configure its environment, did not finish any run on our MacBook Pro M3 Max. With CUDA acceleration on the Nvidia L4 GPU, the picture changes and MinerU takes the lead over the contenders with 0.21 sec/page, compared to 0.49 sec/page with Docling and 0.86 sec/page with Marker. Unstructured does not profit from GPU acceleration.'},\n",
              "  {'self_ref': '#/texts/181',\n",
              "   'parent': {'$ref': '#/body'},\n",
              "   'children': [],\n",
              "   'content_layer': 'body',\n",
              "   'label': 'section_header',\n",
              "   'prov': [{'page_no': 6,\n",
              "     'bbox': {'l': 397.714,\n",
              "      't': 736.286,\n",
              "      'r': 479.786,\n",
              "      'b': 725.538,\n",
              "      'coord_origin': 'BOTTOMLEFT'},\n",
              "     'charspan': [0, 14]}],\n",
              "   'orig': '6 Applications',\n",
              "   'text': '6 Applications',\n",
              "   'level': 1},\n",
              "  {'self_ref': '#/texts/182',\n",
              "   'parent': {'$ref': '#/body'},\n",
              "   'children': [],\n",
              "   'content_layer': 'body',\n",
              "   'label': 'text',\n",
              "   'prov': [{'page_no': 6,\n",
              "     'bbox': {'l': 319.5,\n",
              "      't': 719.125,\n",
              "      'r': 558.005,\n",
              "      'b': 677.697,\n",
              "      'coord_origin': 'BOTTOMLEFT'},\n",
              "     'charspan': [0, 228]}],\n",
              "   'orig': \"Docling's document extraction capabilities make it naturally suitable for workflows like generative AI applications (e.g., RAG), data preparation for foundation model training, and fine-tuning, as well as information extraction.\",\n",
              "   'text': \"Docling's document extraction capabilities make it naturally suitable for workflows like generative AI applications (e.g., RAG), data preparation for foundation model training, and fine-tuning, as well as information extraction.\"},\n",
              "  {'self_ref': '#/texts/183',\n",
              "   'parent': {'$ref': '#/body'},\n",
              "   'children': [],\n",
              "   'content_layer': 'body',\n",
              "   'label': 'text',\n",
              "   'prov': [{'page_no': 6,\n",
              "     'bbox': {'l': 319.5,\n",
              "      't': 674.806,\n",
              "      'r': 558.005,\n",
              "      'b': 458.035,\n",
              "      'coord_origin': 'BOTTOMLEFT'},\n",
              "     'charspan': [0, 1104]}],\n",
              "   'orig': 'As far as RAG is concerned, users can leverage existing Docling extensions for popular frameworks like LlamaIndex and then harness framework capabilities for RAG components like embedding models, vector stores, etc. These Docling extensions typically provide two modes of operation: one using a lossy export, e.g., to Markdown, and one using lossless serialization via JSON. The former provides a simple starting point, upon which any text-based chunking method may be applied (e.g., also drawing from the framework library), while the latter, which uses a swappable Docling chunker type, can be the more powerful one, as it can provide document-native RAG grounding via rich metadata such as the page number and the bounding box of the supporting context. For usage outside of these frameworks, users can still employ Docling chunkers to accelerate and simplify the development of their custom pipelines. Besides strict RAG pipelines for Q&A, Docling can naturally be utilized in the context of broader agentic workflows for which it can provide document-based knowledge for agents to decide and act on.',\n",
              "   'text': 'As far as RAG is concerned, users can leverage existing Docling extensions for popular frameworks like LlamaIndex and then harness framework capabilities for RAG components like embedding models, vector stores, etc. These Docling extensions typically provide two modes of operation: one using a lossy export, e.g., to Markdown, and one using lossless serialization via JSON. The former provides a simple starting point, upon which any text-based chunking method may be applied (e.g., also drawing from the framework library), while the latter, which uses a swappable Docling chunker type, can be the more powerful one, as it can provide document-native RAG grounding via rich metadata such as the page number and the bounding box of the supporting context. For usage outside of these frameworks, users can still employ Docling chunkers to accelerate and simplify the development of their custom pipelines. Besides strict RAG pipelines for Q&A, Docling can naturally be utilized in the context of broader agentic workflows for which it can provide document-based knowledge for agents to decide and act on.'},\n",
              "  {'self_ref': '#/texts/184',\n",
              "   'parent': {'$ref': '#/body'},\n",
              "   'children': [],\n",
              "   'content_layer': 'body',\n",
              "   'label': 'text',\n",
              "   'prov': [{'page_no': 6,\n",
              "     'bbox': {'l': 319.5,\n",
              "      't': 455.145,\n",
              "      'r': 558.005,\n",
              "      'b': 413.716,\n",
              "      'coord_origin': 'BOTTOMLEFT'},\n",
              "     'charspan': [0, 202]}],\n",
              "   'orig': 'Moreover, Docling-enabled pipelines can generate ground truth data out of documents. Such domain-specific knowledge can make significant impact when infused to foundation model training and fine-tuning.',\n",
              "   'text': 'Moreover, Docling-enabled pipelines can generate ground truth data out of documents. Such domain-specific knowledge can make significant impact when infused to foundation model training and fine-tuning.'},\n",
              "  {'self_ref': '#/texts/185',\n",
              "   'parent': {'$ref': '#/body'},\n",
              "   'children': [],\n",
              "   'content_layer': 'body',\n",
              "   'label': 'text',\n",
              "   'prov': [{'page_no': 6,\n",
              "     'bbox': {'l': 319.5,\n",
              "      't': 410.826,\n",
              "      'r': 558.005,\n",
              "      'b': 336.52,\n",
              "      'coord_origin': 'BOTTOMLEFT'},\n",
              "     'charspan': [0, 382]}],\n",
              "   'orig': 'Last but not least, Docling can be used as a backbone for information extraction tasks. Users who seek to create structured representations out of unstructured documents can leverage Docling, which maps various document formats to the unified DoclingDocument format, as well as its strong table understanding capabilities that can help better analyze semi-structured document parts.',\n",
              "   'text': 'Last but not least, Docling can be used as a backbone for information extraction tasks. Users who seek to create structured representations out of unstructured documents can leverage Docling, which maps various document formats to the unified DoclingDocument format, as well as its strong table understanding capabilities that can help better analyze semi-structured document parts.'},\n",
              "  {'self_ref': '#/texts/186',\n",
              "   'parent': {'$ref': '#/body'},\n",
              "   'children': [],\n",
              "   'content_layer': 'body',\n",
              "   'label': 'section_header',\n",
              "   'prov': [{'page_no': 6,\n",
              "     'bbox': {'l': 402.891,\n",
              "      't': 322.35,\n",
              "      'r': 474.61,\n",
              "      'b': 311.602,\n",
              "      'coord_origin': 'BOTTOMLEFT'},\n",
              "     'charspan': [0, 11]}],\n",
              "   'orig': '7 Ecosystem',\n",
              "   'text': '7 Ecosystem',\n",
              "   'level': 1},\n",
              "  {'self_ref': '#/texts/187',\n",
              "   'parent': {'$ref': '#/body'},\n",
              "   'children': [],\n",
              "   'content_layer': 'body',\n",
              "   'label': 'text',\n",
              "   'prov': [{'page_no': 6,\n",
              "     'bbox': {'l': 319.5,\n",
              "      't': 305.189,\n",
              "      'r': 558.005,\n",
              "      'b': 219.92499999999995,\n",
              "      'coord_origin': 'BOTTOMLEFT'},\n",
              "     'charspan': [0, 414]}],\n",
              "   'orig': 'Docling is quickly evolving into a mainstream package for document conversion. The support for PDF, MS Office formats, Images, HTML, and more makes it a universal choice for downstream applications. Users appreciate the intuitiveness of the library, the high-quality, richly structured conversion output, as well as the permissive MIT license, and the possibility of running entirely locally on commodity hardware.',\n",
              "   'text': 'Docling is quickly evolving into a mainstream package for document conversion. The support for PDF, MS Office formats, Images, HTML, and more makes it a universal choice for downstream applications. Users appreciate the intuitiveness of the library, the high-quality, richly structured conversion output, as well as the permissive MIT license, and the possibility of running entirely locally on commodity hardware.'},\n",
              "  {'self_ref': '#/texts/188',\n",
              "   'parent': {'$ref': '#/body'},\n",
              "   'children': [],\n",
              "   'content_layer': 'body',\n",
              "   'label': 'text',\n",
              "   'prov': [{'page_no': 6,\n",
              "     'bbox': {'l': 319.5,\n",
              "      't': 217.034,\n",
              "      'r': 558.005,\n",
              "      'b': 87.93399999999997,\n",
              "      'coord_origin': 'BOTTOMLEFT'},\n",
              "     'charspan': [0, 676]}],\n",
              "   'orig': 'Among the integrations created by the Docling team and the growing community, a few are worth mentioning as depicted in Figure 6. For popular generative AI application patterns, we provide native integration within LangChain (Chase 2022) and LlamaIndex (Liu 2022) for reading documents and chunking. Processing and transforming documents at scale for building large-scale multi-modal training datasets are enabled by the integration in the open IBM data-prep-kit (Wood et al. 2024). Agentic workloads can leverage the integration with the Bee framework (IBM Research 2024). For the fine-tuning of language models, Docling is integrated in InstructLab (Sudalairaj et al. 2024),',\n",
              "   'text': 'Among the integrations created by the Docling team and the growing community, a few are worth mentioning as depicted in Figure 6. For popular generative AI application patterns, we provide native integration within LangChain (Chase 2022) and LlamaIndex (Liu 2022) for reading documents and chunking. Processing and transforming documents at scale for building large-scale multi-modal training datasets are enabled by the integration in the open IBM data-prep-kit (Wood et al. 2024). Agentic workloads can leverage the integration with the Bee framework (IBM Research 2024). For the fine-tuning of language models, Docling is integrated in InstructLab (Sudalairaj et al. 2024),'},\n",
              "  {'self_ref': '#/texts/189',\n",
              "   'parent': {'$ref': '#/pictures/3'},\n",
              "   'children': [],\n",
              "   'content_layer': 'body',\n",
              "   'label': 'caption',\n",
              "   'prov': [{'page_no': 7,\n",
              "     'bbox': {'l': 54.0,\n",
              "      't': 525.254,\n",
              "      'r': 557.998,\n",
              "      'b': 483.825,\n",
              "      'coord_origin': 'BOTTOMLEFT'},\n",
              "     'charspan': [0, 487]}],\n",
              "   'orig': 'Figure 4: Contributions of PDF backend and AI models to the conversion time of a page (in seconds per page). Lower is better. Left: Ranges of time contributions for each model to pages it was applied on (i.e., OCR was applied only on pages with bitmaps, table structure was applied only on pages with tables). Right: Average time contribution to a page in the benchmark dataset (factoring in zero-time contribution for OCR and table structure models on pages without bitmaps or tables) .',\n",
              "   'text': 'Figure 4: Contributions of PDF backend and AI models to the conversion time of a page (in seconds per page). Lower is better. Left: Ranges of time contributions for each model to pages it was applied on (i.e., OCR was applied only on pages with bitmaps, table structure was applied only on pages with tables). Right: Average time contribution to a page in the benchmark dataset (factoring in zero-time contribution for OCR and table structure models on pages without bitmaps or tables) .'},\n",
              "  {'self_ref': '#/texts/190',\n",
              "   'parent': {'$ref': '#/pictures/3'},\n",
              "   'children': [],\n",
              "   'content_layer': 'body',\n",
              "   'label': 'text',\n",
              "   'prov': [{'page_no': 7,\n",
              "     'bbox': {'l': 123.034,\n",
              "      't': 578.628,\n",
              "      'r': 153.088,\n",
              "      'b': 551.56,\n",
              "      'coord_origin': 'BOTTOMLEFT'},\n",
              "     'charspan': [0, 9]}],\n",
              "   'orig': 'Pdf Parse',\n",
              "   'text': 'Pdf Parse'},\n",
              "  {'self_ref': '#/texts/191',\n",
              "   'parent': {'$ref': '#/pictures/3'},\n",
              "   'children': [],\n",
              "   'content_layer': 'body',\n",
              "   'label': 'text',\n",
              "   'prov': [{'page_no': 7,\n",
              "     'bbox': {'l': 170.78,\n",
              "      't': 578.598,\n",
              "      'r': 187.712,\n",
              "      'b': 562.542,\n",
              "      'coord_origin': 'BOTTOMLEFT'},\n",
              "     'charspan': [0, 3]}],\n",
              "   'orig': 'OCR',\n",
              "   'text': 'OCR'},\n",
              "  {'self_ref': '#/texts/192',\n",
              "   'parent': {'$ref': '#/pictures/3'},\n",
              "   'children': [],\n",
              "   'content_layer': 'body',\n",
              "   'label': 'text',\n",
              "   'prov': [{'page_no': 7,\n",
              "     'bbox': {'l': 198.895,\n",
              "      't': 578.597,\n",
              "      'r': 222.369,\n",
              "      'b': 557.051,\n",
              "      'coord_origin': 'BOTTOMLEFT'},\n",
              "     'charspan': [0, 6]}],\n",
              "   'orig': 'Layout',\n",
              "   'text': 'Layout'},\n",
              "  {'self_ref': '#/texts/193',\n",
              "   'parent': {'$ref': '#/pictures/3'},\n",
              "   'children': [],\n",
              "   'content_layer': 'body',\n",
              "   'label': 'text',\n",
              "   'prov': [{'page_no': 7,\n",
              "     'bbox': {'l': 211.267,\n",
              "      't': 578.598,\n",
              "      'r': 257.029,\n",
              "      'b': 538.35,\n",
              "      'coord_origin': 'BOTTOMLEFT'},\n",
              "     'charspan': [0, 15]}],\n",
              "   'orig': 'Table Structure',\n",
              "   'text': 'Table Structure'},\n",
              "  {'self_ref': '#/texts/194',\n",
              "   'parent': {'$ref': '#/pictures/3'},\n",
              "   'children': [],\n",
              "   'content_layer': 'body',\n",
              "   'label': 'text',\n",
              "   'prov': [{'page_no': 7,\n",
              "     'bbox': {'l': 259.29,\n",
              "      't': 578.657,\n",
              "      'r': 291.759,\n",
              "      'b': 549.564,\n",
              "      'coord_origin': 'BOTTOMLEFT'},\n",
              "     'charspan': [0, 10]}],\n",
              "   'orig': 'Page Total',\n",
              "   'text': 'Page Total'},\n",
              "  {'self_ref': '#/texts/195',\n",
              "   'parent': {'$ref': '#/pictures/3'},\n",
              "   'children': [],\n",
              "   'content_layer': 'body',\n",
              "   'label': 'text',\n",
              "   'prov': [{'page_no': 7,\n",
              "     'bbox': {'l': 116.069,\n",
              "      't': 589.29,\n",
              "      'r': 124.975,\n",
              "      'b': 581.135,\n",
              "      'coord_origin': 'BOTTOMLEFT'},\n",
              "     'charspan': [0, 2]}],\n",
              "   'orig': '10',\n",
              "   'text': '10'},\n",
              "  {'self_ref': '#/texts/196',\n",
              "   'parent': {'$ref': '#/pictures/3'},\n",
              "   'children': [],\n",
              "   'content_layer': 'body',\n",
              "   'label': 'text',\n",
              "   'prov': [{'page_no': 7,\n",
              "     'bbox': {'l': 129.149,\n",
              "      't': 590.019,\n",
              "      'r': 132.266,\n",
              "      'b': 584.311,\n",
              "      'coord_origin': 'BOTTOMLEFT'},\n",
              "     'charspan': [0, 1]}],\n",
              "   'orig': '2',\n",
              "   'text': '2'},\n",
              "  {'self_ref': '#/texts/197',\n",
              "   'parent': {'$ref': '#/pictures/3'},\n",
              "   'children': [],\n",
              "   'content_layer': 'body',\n",
              "   'label': 'text',\n",
              "   'prov': [{'page_no': 7,\n",
              "     'bbox': {'l': 116.069,\n",
              "      't': 632.362,\n",
              "      'r': 124.975,\n",
              "      'b': 624.207,\n",
              "      'coord_origin': 'BOTTOMLEFT'},\n",
              "     'charspan': [0, 2]}],\n",
              "   'orig': '10',\n",
              "   'text': '10'},\n",
              "  {'self_ref': '#/texts/198',\n",
              "   'parent': {'$ref': '#/pictures/3'},\n",
              "   'children': [],\n",
              "   'content_layer': 'body',\n",
              "   'label': 'text',\n",
              "   'prov': [{'page_no': 7,\n",
              "     'bbox': {'l': 129.149,\n",
              "      't': 633.091,\n",
              "      'r': 132.266,\n",
              "      'b': 627.382,\n",
              "      'coord_origin': 'BOTTOMLEFT'},\n",
              "     'charspan': [0, 1]}],\n",
              "   'orig': '1',\n",
              "   'text': '1'},\n",
              "  {'self_ref': '#/texts/199',\n",
              "   'parent': {'$ref': '#/pictures/3'},\n",
              "   'children': [],\n",
              "   'content_layer': 'body',\n",
              "   'label': 'text',\n",
              "   'prov': [{'page_no': 7,\n",
              "     'bbox': {'l': 120.269,\n",
              "      't': 676.74,\n",
              "      'r': 132.36,\n",
              "      'b': 667.856,\n",
              "      'coord_origin': 'BOTTOMLEFT'},\n",
              "     'charspan': [0, 4]}],\n",
              "   'orig': '10 0',\n",
              "   'text': '10 0'},\n",
              "  {'self_ref': '#/texts/200',\n",
              "   'parent': {'$ref': '#/pictures/3'},\n",
              "   'children': [],\n",
              "   'content_layer': 'body',\n",
              "   'label': 'text',\n",
              "   'prov': [{'page_no': 7,\n",
              "     'bbox': {'l': 120.269,\n",
              "      't': 719.811,\n",
              "      'r': 132.36,\n",
              "      'b': 710.927,\n",
              "      'coord_origin': 'BOTTOMLEFT'},\n",
              "     'charspan': [0, 4]}],\n",
              "   'orig': '10 1',\n",
              "   'text': '10 1'},\n",
              "  {'self_ref': '#/texts/201',\n",
              "   'parent': {'$ref': '#/pictures/3'},\n",
              "   'children': [],\n",
              "   'content_layer': 'body',\n",
              "   'label': 'text',\n",
              "   'prov': [{'page_no': 7,\n",
              "     'bbox': {'l': 105.312,\n",
              "      't': 675.068,\n",
              "      'r': 113.467,\n",
              "      'b': 643.421,\n",
              "      'coord_origin': 'BOTTOMLEFT'},\n",
              "     'charspan': [0, 8]}],\n",
              "   'orig': 'sec/page',\n",
              "   'text': 'sec/page'},\n",
              "  {'self_ref': '#/texts/202',\n",
              "   'parent': {'$ref': '#/pictures/3'},\n",
              "   'children': [],\n",
              "   'content_layer': 'body',\n",
              "   'label': 'text',\n",
              "   'prov': [{'page_no': 7,\n",
              "     'bbox': {'l': 326.444,\n",
              "      't': 578.628,\n",
              "      'r': 356.499,\n",
              "      'b': 551.56,\n",
              "      'coord_origin': 'BOTTOMLEFT'},\n",
              "     'charspan': [0, 9]}],\n",
              "   'orig': 'Pdf Parse',\n",
              "   'text': 'Pdf Parse'},\n",
              "  {'self_ref': '#/texts/203',\n",
              "   'parent': {'$ref': '#/pictures/3'},\n",
              "   'children': [],\n",
              "   'content_layer': 'body',\n",
              "   'label': 'text',\n",
              "   'prov': [{'page_no': 7,\n",
              "     'bbox': {'l': 371.869,\n",
              "      't': 578.598,\n",
              "      'r': 388.801,\n",
              "      'b': 562.542,\n",
              "      'coord_origin': 'BOTTOMLEFT'},\n",
              "     'charspan': [0, 3]}],\n",
              "   'orig': 'OCR',\n",
              "   'text': 'OCR'},\n",
              "  {'self_ref': '#/texts/204',\n",
              "   'parent': {'$ref': '#/pictures/3'},\n",
              "   'children': [],\n",
              "   'content_layer': 'body',\n",
              "   'label': 'text',\n",
              "   'prov': [{'page_no': 7,\n",
              "     'bbox': {'l': 397.662,\n",
              "      't': 578.597,\n",
              "      'r': 421.136,\n",
              "      'b': 557.051,\n",
              "      'coord_origin': 'BOTTOMLEFT'},\n",
              "     'charspan': [0, 6]}],\n",
              "   'orig': 'Layout',\n",
              "   'text': 'Layout'},\n",
              "  {'self_ref': '#/texts/205',\n",
              "   'parent': {'$ref': '#/pictures/3'},\n",
              "   'children': [],\n",
              "   'content_layer': 'body',\n",
              "   'label': 'text',\n",
              "   'prov': [{'page_no': 7,\n",
              "     'bbox': {'l': 407.713,\n",
              "      't': 578.598,\n",
              "      'r': 453.475,\n",
              "      'b': 538.35,\n",
              "      'coord_origin': 'BOTTOMLEFT'},\n",
              "     'charspan': [0, 15]}],\n",
              "   'orig': 'Table Structure',\n",
              "   'text': 'Table Structure'},\n",
              "  {'self_ref': '#/texts/206',\n",
              "   'parent': {'$ref': '#/pictures/3'},\n",
              "   'children': [],\n",
              "   'content_layer': 'body',\n",
              "   'label': 'text',\n",
              "   'prov': [{'page_no': 7,\n",
              "     'bbox': {'l': 453.414,\n",
              "      't': 578.657,\n",
              "      'r': 485.883,\n",
              "      'b': 549.564,\n",
              "      'coord_origin': 'BOTTOMLEFT'},\n",
              "     'charspan': [0, 10]}],\n",
              "   'orig': 'Page Total',\n",
              "   'text': 'Page Total'},\n",
              "  {'self_ref': '#/texts/207',\n",
              "   'parent': {'$ref': '#/pictures/3'},\n",
              "   'children': [],\n",
              "   'content_layer': 'body',\n",
              "   'label': 'text',\n",
              "   'prov': [{'page_no': 7,\n",
              "     'bbox': {'l': 320.502,\n",
              "      't': 586.439,\n",
              "      'r': 331.632,\n",
              "      'b': 578.284,\n",
              "      'coord_origin': 'BOTTOMLEFT'},\n",
              "     'charspan': [0, 3]}],\n",
              "   'orig': '0.0',\n",
              "   'text': '0.0'},\n",
              "  {'self_ref': '#/texts/208',\n",
              "   'parent': {'$ref': '#/pictures/3'},\n",
              "   'children': [],\n",
              "   'content_layer': 'body',\n",
              "   'label': 'text',\n",
              "   'prov': [{'page_no': 7,\n",
              "     'bbox': {'l': 320.502,\n",
              "      't': 610.023,\n",
              "      'r': 331.632,\n",
              "      'b': 601.868,\n",
              "      'coord_origin': 'BOTTOMLEFT'},\n",
              "     'charspan': [0, 3]}],\n",
              "   'orig': '0.5',\n",
              "   'text': '0.5'},\n",
              "  {'self_ref': '#/texts/209',\n",
              "   'parent': {'$ref': '#/pictures/3'},\n",
              "   'children': [],\n",
              "   'content_layer': 'body',\n",
              "   'label': 'text',\n",
              "   'prov': [{'page_no': 7,\n",
              "     'bbox': {'l': 320.502,\n",
              "      't': 633.606,\n",
              "      'r': 331.632,\n",
              "      'b': 625.451,\n",
              "      'coord_origin': 'BOTTOMLEFT'},\n",
              "     'charspan': [0, 3]}],\n",
              "   'orig': '1.0',\n",
              "   'text': '1.0'},\n",
              "  {'self_ref': '#/texts/210',\n",
              "   'parent': {'$ref': '#/pictures/3'},\n",
              "   'children': [],\n",
              "   'content_layer': 'body',\n",
              "   'label': 'text',\n",
              "   'prov': [{'page_no': 7,\n",
              "     'bbox': {'l': 320.502,\n",
              "      't': 657.19,\n",
              "      'r': 331.632,\n",
              "      'b': 649.035,\n",
              "      'coord_origin': 'BOTTOMLEFT'},\n",
              "     'charspan': [0, 3]}],\n",
              "   'orig': '1.5',\n",
              "   'text': '1.5'},\n",
              "  {'self_ref': '#/texts/211',\n",
              "   'parent': {'$ref': '#/pictures/3'},\n",
              "   'children': [],\n",
              "   'content_layer': 'body',\n",
              "   'label': 'text',\n",
              "   'prov': [{'page_no': 7,\n",
              "     'bbox': {'l': 320.502,\n",
              "      't': 680.773,\n",
              "      'r': 331.632,\n",
              "      'b': 672.618,\n",
              "      'coord_origin': 'BOTTOMLEFT'},\n",
              "     'charspan': [0, 3]}],\n",
              "   'orig': '2.0',\n",
              "   'text': '2.0'},\n",
              "  {'self_ref': '#/texts/212',\n",
              "   'parent': {'$ref': '#/pictures/3'},\n",
              "   'children': [],\n",
              "   'content_layer': 'body',\n",
              "   'label': 'text',\n",
              "   'prov': [{'page_no': 7,\n",
              "     'bbox': {'l': 320.502,\n",
              "      't': 704.357,\n",
              "      'r': 331.632,\n",
              "      'b': 696.202,\n",
              "      'coord_origin': 'BOTTOMLEFT'},\n",
              "     'charspan': [0, 3]}],\n",
              "   'orig': '2.5',\n",
              "   'text': '2.5'},\n",
              "  {'self_ref': '#/texts/213',\n",
              "   'parent': {'$ref': '#/pictures/3'},\n",
              "   'children': [],\n",
              "   'content_layer': 'body',\n",
              "   'label': 'text',\n",
              "   'prov': [{'page_no': 7,\n",
              "     'bbox': {'l': 320.502,\n",
              "      't': 727.94,\n",
              "      'r': 331.632,\n",
              "      'b': 719.785,\n",
              "      'coord_origin': 'BOTTOMLEFT'},\n",
              "     'charspan': [0, 3]}],\n",
              "   'orig': '3.0',\n",
              "   'text': '3.0'},\n",
              "  {'self_ref': '#/texts/214',\n",
              "   'parent': {'$ref': '#/pictures/3'},\n",
              "   'children': [],\n",
              "   'content_layer': 'body',\n",
              "   'label': 'text',\n",
              "   'prov': [{'page_no': 7,\n",
              "     'bbox': {'l': 309.745,\n",
              "      't': 675.068,\n",
              "      'r': 317.9,\n",
              "      'b': 643.421,\n",
              "      'coord_origin': 'BOTTOMLEFT'},\n",
              "     'charspan': [0, 8]}],\n",
              "   'orig': 'sec/page',\n",
              "   'text': 'sec/page'},\n",
              "  {'self_ref': '#/texts/215',\n",
              "   'parent': {'$ref': '#/pictures/3'},\n",
              "   'children': [],\n",
              "   'content_layer': 'body',\n",
              "   'label': 'text',\n",
              "   'prov': [{'page_no': 7,\n",
              "     'bbox': {'l': 370.979,\n",
              "      't': 722.808,\n",
              "      'r': 400.484,\n",
              "      'b': 714.653,\n",
              "      'coord_origin': 'BOTTOMLEFT'},\n",
              "     'charspan': [0, 7]}],\n",
              "   'orig': 'x86 CPU',\n",
              "   'text': 'x86 CPU'},\n",
              "  {'self_ref': '#/texts/216',\n",
              "   'parent': {'$ref': '#/pictures/3'},\n",
              "   'children': [],\n",
              "   'content_layer': 'body',\n",
              "   'label': 'text',\n",
              "   'prov': [{'page_no': 7,\n",
              "     'bbox': {'l': 370.979,\n",
              "      't': 712.538,\n",
              "      'r': 398.174,\n",
              "      'b': 704.383,\n",
              "      'coord_origin': 'BOTTOMLEFT'},\n",
              "     'charspan': [0, 6]}],\n",
              "   'orig': 'M3 Max',\n",
              "   'text': 'M3 Max'},\n",
              "  {'self_ref': '#/texts/217',\n",
              "   'parent': {'$ref': '#/pictures/3'},\n",
              "   'children': [],\n",
              "   'content_layer': 'body',\n",
              "   'label': 'text',\n",
              "   'prov': [{'page_no': 7,\n",
              "     'bbox': {'l': 370.979,\n",
              "      't': 702.268,\n",
              "      'r': 396.326,\n",
              "      'b': 694.113,\n",
              "      'coord_origin': 'BOTTOMLEFT'},\n",
              "     'charspan': [0, 6]}],\n",
              "   'orig': 'L4 GPU',\n",
              "   'text': 'L4 GPU'},\n",
              "  {'self_ref': '#/texts/218',\n",
              "   'parent': {'$ref': '#/pictures/4'},\n",
              "   'children': [],\n",
              "   'content_layer': 'body',\n",
              "   'label': 'caption',\n",
              "   'prov': [{'page_no': 7,\n",
              "     'bbox': {'l': 54.0,\n",
              "      't': 260.72900000000004,\n",
              "      'r': 292.505,\n",
              "      'b': 197.38200000000006,\n",
              "      'coord_origin': 'BOTTOMLEFT'},\n",
              "     'charspan': [0, 300]}],\n",
              "   'orig': 'Figure 5: Conversion time in seconds per page on our dataset in three scenarios, across all assets and system configurations. Lower bars are better. The configuration includes OCR and table structure recognition ( fast table option on Docling and MinerU, hi res in unstructured, as shown in table 1).',\n",
              "   'text': 'Figure 5: Conversion time in seconds per page on our dataset in three scenarios, across all assets and system configurations. Lower bars are better. The configuration includes OCR and table structure recognition ( fast table option on Docling and MinerU, hi res in unstructured, as shown in table 1).'},\n",
              "  {'self_ref': '#/texts/219',\n",
              "   'parent': {'$ref': '#/pictures/4'},\n",
              "   'children': [],\n",
              "   'content_layer': 'body',\n",
              "   'label': 'text',\n",
              "   'prov': [{'page_no': 7,\n",
              "     'bbox': {'l': 100.506,\n",
              "      't': 307.477,\n",
              "      'r': 124.534,\n",
              "      'b': 285.565,\n",
              "      'coord_origin': 'BOTTOMLEFT'},\n",
              "     'charspan': [0, 7]}],\n",
              "   'orig': 'Docling',\n",
              "   'text': 'Docling'},\n",
              "  {'self_ref': '#/texts/220',\n",
              "   'parent': {'$ref': '#/pictures/4'},\n",
              "   'children': [],\n",
              "   'content_layer': 'body',\n",
              "   'label': 'text',\n",
              "   'prov': [{'page_no': 7,\n",
              "     'bbox': {'l': 141.973,\n",
              "      't': 307.493,\n",
              "      'r': 164.482,\n",
              "      'b': 286.856,\n",
              "      'coord_origin': 'BOTTOMLEFT'},\n",
              "     'charspan': [0, 6]}],\n",
              "   'orig': 'Marker',\n",
              "   'text': 'Marker'},\n",
              "  {'self_ref': '#/texts/221',\n",
              "   'parent': {'$ref': '#/pictures/4'},\n",
              "   'children': [],\n",
              "   'content_layer': 'body',\n",
              "   'label': 'text',\n",
              "   'prov': [{'page_no': 7,\n",
              "     'bbox': {'l': 181.996,\n",
              "      't': 307.476,\n",
              "      'r': 204.39,\n",
              "      'b': 286.936,\n",
              "      'coord_origin': 'BOTTOMLEFT'},\n",
              "     'charspan': [0, 6]}],\n",
              "   'orig': 'Mineru',\n",
              "   'text': 'Mineru'},\n",
              "  {'self_ref': '#/texts/222',\n",
              "   'parent': {'$ref': '#/pictures/4'},\n",
              "   'children': [],\n",
              "   'content_layer': 'body',\n",
              "   'label': 'text',\n",
              "   'prov': [{'page_no': 7,\n",
              "     'bbox': {'l': 206.176,\n",
              "      't': 307.481,\n",
              "      'r': 244.323,\n",
              "      'b': 273.722,\n",
              "      'coord_origin': 'BOTTOMLEFT'},\n",
              "     'charspan': [0, 12]}],\n",
              "   'orig': 'Unstructured',\n",
              "   'text': 'Unstructured'},\n",
              "  {'self_ref': '#/texts/223',\n",
              "   'parent': {'$ref': '#/pictures/4'},\n",
              "   'children': [],\n",
              "   'content_layer': 'body',\n",
              "   'label': 'text',\n",
              "   'prov': [{'page_no': 7,\n",
              "     'bbox': {'l': 93.108,\n",
              "      't': 314.896,\n",
              "      'r': 97.322,\n",
              "      'b': 307.178,\n",
              "      'coord_origin': 'BOTTOMLEFT'},\n",
              "     'charspan': [0, 1]}],\n",
              "   'orig': '0',\n",
              "   'text': '0'},\n",
              "  {'self_ref': '#/texts/224',\n",
              "   'parent': {'$ref': '#/pictures/4'},\n",
              "   'children': [],\n",
              "   'content_layer': 'body',\n",
              "   'label': 'text',\n",
              "   'prov': [{'page_no': 7,\n",
              "     'bbox': {'l': 93.108,\n",
              "      't': 332.324,\n",
              "      'r': 97.322,\n",
              "      'b': 324.605,\n",
              "      'coord_origin': 'BOTTOMLEFT'},\n",
              "     'charspan': [0, 1]}],\n",
              "   'orig': '2',\n",
              "   'text': '2'},\n",
              "  {'self_ref': '#/texts/225',\n",
              "   'parent': {'$ref': '#/pictures/4'},\n",
              "   'children': [],\n",
              "   'content_layer': 'body',\n",
              "   'label': 'text',\n",
              "   'prov': [{'page_no': 7,\n",
              "     'bbox': {'l': 93.108,\n",
              "      't': 349.751,\n",
              "      'r': 97.322,\n",
              "      'b': 342.033,\n",
              "      'coord_origin': 'BOTTOMLEFT'},\n",
              "     'charspan': [0, 1]}],\n",
              "   'orig': '4',\n",
              "   'text': '4'},\n",
              "  {'self_ref': '#/texts/226',\n",
              "   'parent': {'$ref': '#/pictures/4'},\n",
              "   'children': [],\n",
              "   'content_layer': 'body',\n",
              "   'label': 'text',\n",
              "   'prov': [{'page_no': 7,\n",
              "     'bbox': {'l': 93.108,\n",
              "      't': 367.178,\n",
              "      'r': 97.322,\n",
              "      'b': 359.46,\n",
              "      'coord_origin': 'BOTTOMLEFT'},\n",
              "     'charspan': [0, 1]}],\n",
              "   'orig': '6',\n",
              "   'text': '6'},\n",
              "  {'self_ref': '#/texts/227',\n",
              "   'parent': {'$ref': '#/pictures/4'},\n",
              "   'children': [],\n",
              "   'content_layer': 'body',\n",
              "   'label': 'text',\n",
              "   'prov': [{'page_no': 7,\n",
              "     'bbox': {'l': 93.108,\n",
              "      't': 384.606,\n",
              "      'r': 97.322,\n",
              "      'b': 376.887,\n",
              "      'coord_origin': 'BOTTOMLEFT'},\n",
              "     'charspan': [0, 1]}],\n",
              "   'orig': '8',\n",
              "   'text': '8'},\n",
              "  {'self_ref': '#/texts/228',\n",
              "   'parent': {'$ref': '#/pictures/4'},\n",
              "   'children': [],\n",
              "   'content_layer': 'body',\n",
              "   'label': 'text',\n",
              "   'prov': [{'page_no': 7,\n",
              "     'bbox': {'l': 88.895,\n",
              "      't': 402.033,\n",
              "      'r': 97.322,\n",
              "      'b': 394.315,\n",
              "      'coord_origin': 'BOTTOMLEFT'},\n",
              "     'charspan': [0, 2]}],\n",
              "   'orig': '10',\n",
              "   'text': '10'},\n",
              "  {'self_ref': '#/texts/229',\n",
              "   'parent': {'$ref': '#/pictures/4'},\n",
              "   'children': [],\n",
              "   'content_layer': 'body',\n",
              "   'label': 'text',\n",
              "   'prov': [{'page_no': 7,\n",
              "     'bbox': {'l': 88.895,\n",
              "      't': 419.46,\n",
              "      'r': 97.322,\n",
              "      'b': 411.742,\n",
              "      'coord_origin': 'BOTTOMLEFT'},\n",
              "     'charspan': [0, 2]}],\n",
              "   'orig': '12',\n",
              "   'text': '12'},\n",
              "  {'self_ref': '#/texts/230',\n",
              "   'parent': {'$ref': '#/pictures/4'},\n",
              "   'children': [],\n",
              "   'content_layer': 'body',\n",
              "   'label': 'text',\n",
              "   'prov': [{'page_no': 7,\n",
              "     'bbox': {'l': 88.895,\n",
              "      't': 436.887,\n",
              "      'r': 97.322,\n",
              "      'b': 429.169,\n",
              "      'coord_origin': 'BOTTOMLEFT'},\n",
              "     'charspan': [0, 2]}],\n",
              "   'orig': '14',\n",
              "   'text': '14'},\n",
              "  {'self_ref': '#/texts/231',\n",
              "   'parent': {'$ref': '#/pictures/4'},\n",
              "   'children': [],\n",
              "   'content_layer': 'body',\n",
              "   'label': 'text',\n",
              "   'prov': [{'page_no': 7,\n",
              "     'bbox': {'l': 88.895,\n",
              "      't': 454.315,\n",
              "      'r': 97.322,\n",
              "      'b': 446.597,\n",
              "      'coord_origin': 'BOTTOMLEFT'},\n",
              "     'charspan': [0, 2]}],\n",
              "   'orig': '16',\n",
              "   'text': '16'},\n",
              "  {'self_ref': '#/texts/232',\n",
              "   'parent': {'$ref': '#/pictures/4'},\n",
              "   'children': [],\n",
              "   'content_layer': 'body',\n",
              "   'label': 'text',\n",
              "   'prov': [{'page_no': 7,\n",
              "     'bbox': {'l': 78.714,\n",
              "      't': 400.946,\n",
              "      'r': 86.432,\n",
              "      'b': 370.994,\n",
              "      'coord_origin': 'BOTTOMLEFT'},\n",
              "     'charspan': [0, 8]}],\n",
              "   'orig': 'sec/page',\n",
              "   'text': 'sec/page'},\n",
              "  {'self_ref': '#/texts/233',\n",
              "   'parent': {'$ref': '#/pictures/4'},\n",
              "   'children': [],\n",
              "   'content_layer': 'body',\n",
              "   'label': 'text',\n",
              "   'prov': [{'page_no': 7,\n",
              "     'bbox': {'l': 232.761,\n",
              "      't': 455.851,\n",
              "      'r': 260.685,\n",
              "      'b': 448.132,\n",
              "      'coord_origin': 'BOTTOMLEFT'},\n",
              "     'charspan': [0, 7]}],\n",
              "   'orig': 'x86 CPU',\n",
              "   'text': 'x86 CPU'},\n",
              "  {'self_ref': '#/texts/234',\n",
              "   'parent': {'$ref': '#/pictures/4'},\n",
              "   'children': [],\n",
              "   'content_layer': 'body',\n",
              "   'label': 'text',\n",
              "   'prov': [{'page_no': 7,\n",
              "     'bbox': {'l': 232.761,\n",
              "      't': 446.13,\n",
              "      'r': 258.499,\n",
              "      'b': 438.412,\n",
              "      'coord_origin': 'BOTTOMLEFT'},\n",
              "     'charspan': [0, 6]}],\n",
              "   'orig': 'M3 Max',\n",
              "   'text': 'M3 Max'},\n",
              "  {'self_ref': '#/texts/235',\n",
              "   'parent': {'$ref': '#/pictures/4'},\n",
              "   'children': [],\n",
              "   'content_layer': 'body',\n",
              "   'label': 'text',\n",
              "   'prov': [{'page_no': 7,\n",
              "     'bbox': {'l': 232.761,\n",
              "      't': 436.41,\n",
              "      'r': 256.75,\n",
              "      'b': 428.692,\n",
              "      'coord_origin': 'BOTTOMLEFT'},\n",
              "     'charspan': [0, 6]}],\n",
              "   'orig': 'L4 GPU',\n",
              "   'text': 'L4 GPU'},\n",
              "  {'self_ref': '#/texts/236',\n",
              "   'parent': {'$ref': '#/body'},\n",
              "   'children': [],\n",
              "   'content_layer': 'body',\n",
              "   'label': 'text',\n",
              "   'prov': [{'page_no': 7,\n",
              "     'bbox': {'l': 54.0,\n",
              "      't': 165.74599999999998,\n",
              "      'r': 292.505,\n",
              "      'b': 146.235,\n",
              "      'coord_origin': 'BOTTOMLEFT'},\n",
              "     'charspan': [0, 60]}],\n",
              "   'orig': 'where it supports the enhancement of the knowledge taxonomy.',\n",
              "   'text': 'where it supports the enhancement of the knowledge taxonomy.'},\n",
              "  {'self_ref': '#/texts/237',\n",
              "   'parent': {'$ref': '#/body'},\n",
              "   'children': [],\n",
              "   'content_layer': 'body',\n",
              "   'label': 'text',\n",
              "   'prov': [{'page_no': 7,\n",
              "     'bbox': {'l': 54.0,\n",
              "      't': 140.322,\n",
              "      'r': 292.505,\n",
              "      'b': 87.93399999999997,\n",
              "      'coord_origin': 'BOTTOMLEFT'},\n",
              "     'charspan': [0, 257]}],\n",
              "   'orig': 'Docling is also available and officially maintained as a system package in the Red Hat ® Enterprise Linux ® AI (RHEL AI) distribution, which seamlessly allows to develop, test, and run the Granite family of large language models for enterprise applications.',\n",
              "   'text': 'Docling is also available and officially maintained as a system package in the Red Hat ® Enterprise Linux ® AI (RHEL AI) distribution, which seamlessly allows to develop, test, and run the Granite family of large language models for enterprise applications.'},\n",
              "  {'self_ref': '#/texts/238',\n",
              "   'parent': {'$ref': '#/pictures/5'},\n",
              "   'children': [],\n",
              "   'content_layer': 'body',\n",
              "   'label': 'caption',\n",
              "   'prov': [{'page_no': 7,\n",
              "     'bbox': {'l': 319.5,\n",
              "      't': 350.664,\n",
              "      'r': 558.005,\n",
              "      'b': 309.235,\n",
              "      'coord_origin': 'BOTTOMLEFT'},\n",
              "     'charspan': [0, 230]}],\n",
              "   'orig': 'Figure 6: Ecosystem of Docling integrations contributed by the Docling team or the broader community. Docling is already used for RAG, model fine-tuning, large-scale datasets creation, information extraction and agentic workflows.',\n",
              "   'text': 'Figure 6: Ecosystem of Docling integrations contributed by the Docling team or the broader community. Docling is already used for RAG, model fine-tuning, large-scale datasets creation, information extraction and agentic workflows.'},\n",
              "  {'self_ref': '#/texts/239',\n",
              "   'parent': {'$ref': '#/pictures/5'},\n",
              "   'children': [],\n",
              "   'content_layer': 'body',\n",
              "   'label': 'text',\n",
              "   'prov': [{'page_no': 7,\n",
              "     'bbox': {'l': 415.052,\n",
              "      't': 372.962,\n",
              "      'r': 460.836,\n",
              "      'b': 361.742,\n",
              "      'coord_origin': 'BOTTOMLEFT'},\n",
              "     'charspan': [0, 7]}],\n",
              "   'orig': 'Docling',\n",
              "   'text': 'Docling'},\n",
              "  {'self_ref': '#/texts/240',\n",
              "   'parent': {'$ref': '#/pictures/5'},\n",
              "   'children': [],\n",
              "   'content_layer': 'body',\n",
              "   'label': 'text',\n",
              "   'prov': [{'page_no': 7,\n",
              "     'bbox': {'l': 332.246,\n",
              "      't': 453.004,\n",
              "      'r': 381.124,\n",
              "      'b': 444.925,\n",
              "      'coord_origin': 'BOTTOMLEFT'},\n",
              "     'charspan': [0, 11]}],\n",
              "   'orig': 'InstructLab',\n",
              "   'text': 'InstructLab'},\n",
              "  {'self_ref': '#/texts/241',\n",
              "   'parent': {'$ref': '#/pictures/5'},\n",
              "   'children': [],\n",
              "   'content_layer': 'body',\n",
              "   'label': 'text',\n",
              "   'prov': [{'page_no': 7,\n",
              "     'bbox': {'l': 381.098,\n",
              "      't': 456.247,\n",
              "      'r': 390.554,\n",
              "      'b': 443.831,\n",
              "      'coord_origin': 'BOTTOMLEFT'},\n",
              "     'charspan': [0, 1]}],\n",
              "   'orig': '🐶',\n",
              "   'text': '🐶'},\n",
              "  {'self_ref': '#/texts/242',\n",
              "   'parent': {'$ref': '#/pictures/5'},\n",
              "   'children': [],\n",
              "   'content_layer': 'body',\n",
              "   'label': 'text',\n",
              "   'prov': [{'page_no': 7,\n",
              "     'bbox': {'l': 331.483,\n",
              "      't': 420.853,\n",
              "      'r': 372.613,\n",
              "      'b': 412.774,\n",
              "      'coord_origin': 'BOTTOMLEFT'},\n",
              "     'charspan': [0, 9]}],\n",
              "   'orig': 'Bee Agent',\n",
              "   'text': 'Bee Agent'},\n",
              "  {'self_ref': '#/texts/243',\n",
              "   'parent': {'$ref': '#/pictures/5'},\n",
              "   'children': [],\n",
              "   'content_layer': 'body',\n",
              "   'label': 'text',\n",
              "   'prov': [{'page_no': 7,\n",
              "     'bbox': {'l': 323.597,\n",
              "      't': 409.758,\n",
              "      'r': 371.087,\n",
              "      'b': 401.679,\n",
              "      'coord_origin': 'BOTTOMLEFT'},\n",
              "     'charspan': [0, 9]}],\n",
              "   'orig': 'Framework',\n",
              "   'text': 'Framework'},\n",
              "  {'self_ref': '#/texts/244',\n",
              "   'parent': {'$ref': '#/pictures/5'},\n",
              "   'children': [],\n",
              "   'content_layer': 'body',\n",
              "   'label': 'text',\n",
              "   'prov': [{'page_no': 7,\n",
              "     'bbox': {'l': 371.067,\n",
              "      't': 413.001,\n",
              "      'r': 380.523,\n",
              "      'b': 400.585,\n",
              "      'coord_origin': 'BOTTOMLEFT'},\n",
              "     'charspan': [0, 1]}],\n",
              "   'orig': '🐝',\n",
              "   'text': '🐝'},\n",
              "  {'self_ref': '#/texts/245',\n",
              "   'parent': {'$ref': '#/pictures/5'},\n",
              "   'children': [],\n",
              "   'content_layer': 'body',\n",
              "   'label': 'text',\n",
              "   'prov': [{'page_no': 7,\n",
              "     'bbox': {'l': 413.625,\n",
              "      't': 458.047,\n",
              "      'r': 462.88,\n",
              "      'b': 449.968,\n",
              "      'coord_origin': 'BOTTOMLEFT'},\n",
              "     'charspan': [0, 10]}],\n",
              "   'orig': 'LlamaIndex',\n",
              "   'text': 'LlamaIndex'},\n",
              "  {'self_ref': '#/texts/246',\n",
              "   'parent': {'$ref': '#/pictures/5'},\n",
              "   'children': [],\n",
              "   'content_layer': 'body',\n",
              "   'label': 'text',\n",
              "   'prov': [{'page_no': 7,\n",
              "     'bbox': {'l': 462.866,\n",
              "      't': 461.29,\n",
              "      'r': 472.322,\n",
              "      'b': 448.874,\n",
              "      'coord_origin': 'BOTTOMLEFT'},\n",
              "     'charspan': [0, 1]}],\n",
              "   'orig': '🦙',\n",
              "   'text': '🦙'},\n",
              "  {'self_ref': '#/texts/247',\n",
              "   'parent': {'$ref': '#/pictures/5'},\n",
              "   'children': [],\n",
              "   'content_layer': 'body',\n",
              "   'label': 'text',\n",
              "   'prov': [{'page_no': 7,\n",
              "     'bbox': {'l': 488.068,\n",
              "      't': 452.499,\n",
              "      'r': 533.881,\n",
              "      'b': 444.421,\n",
              "      'coord_origin': 'BOTTOMLEFT'},\n",
              "     'charspan': [0, 9]}],\n",
              "   'orig': 'LangChain',\n",
              "   'text': 'LangChain'},\n",
              "  {'self_ref': '#/texts/248',\n",
              "   'parent': {'$ref': '#/pictures/5'},\n",
              "   'children': [],\n",
              "   'content_layer': 'body',\n",
              "   'label': 'text',\n",
              "   'prov': [{'page_no': 7,\n",
              "     'bbox': {'l': 533.888,\n",
              "      't': 455.743,\n",
              "      'r': 552.8,\n",
              "      'b': 443.327,\n",
              "      'coord_origin': 'BOTTOMLEFT'},\n",
              "     'charspan': [0, 2]}],\n",
              "   'orig': '🦜🔗',\n",
              "   'text': '🦜🔗'},\n",
              "  {'self_ref': '#/texts/249',\n",
              "   'parent': {'$ref': '#/pictures/5'},\n",
              "   'children': [],\n",
              "   'content_layer': 'body',\n",
              "   'label': 'text',\n",
              "   'prov': [{'page_no': 7,\n",
              "     'bbox': {'l': 488.849,\n",
              "      't': 381.827,\n",
              "      'r': 497.444,\n",
              "      'b': 372.851,\n",
              "      'coord_origin': 'BOTTOMLEFT'},\n",
              "     'charspan': [0, 1]}],\n",
              "   'orig': '…',\n",
              "   'text': '…'},\n",
              "  {'self_ref': '#/texts/250',\n",
              "   'parent': {'$ref': '#/pictures/5'},\n",
              "   'children': [],\n",
              "   'content_layer': 'body',\n",
              "   'label': 'text',\n",
              "   'prov': [{'page_no': 7,\n",
              "     'bbox': {'l': 326.89,\n",
              "      't': 380.885,\n",
              "      'r': 377.758,\n",
              "      'b': 372.807,\n",
              "      'coord_origin': 'BOTTOMLEFT'},\n",
              "     'charspan': [0, 11]}],\n",
              "   'orig': 'DataPrepKit',\n",
              "   'text': 'DataPrepKit'},\n",
              "  {'self_ref': '#/texts/251',\n",
              "   'parent': {'$ref': '#/pictures/5'},\n",
              "   'children': [],\n",
              "   'content_layer': 'body',\n",
              "   'label': 'text',\n",
              "   'prov': [{'page_no': 7,\n",
              "     'bbox': {'l': 377.758,\n",
              "      't': 384.128,\n",
              "      'r': 387.215,\n",
              "      'b': 371.713,\n",
              "      'coord_origin': 'BOTTOMLEFT'},\n",
              "     'charspan': [0, 1]}],\n",
              "   'orig': '🧰',\n",
              "   'text': '🧰'},\n",
              "  {'self_ref': '#/texts/252',\n",
              "   'parent': {'$ref': '#/pictures/5'},\n",
              "   'children': [],\n",
              "   'content_layer': 'body',\n",
              "   'label': 'text',\n",
              "   'prov': [{'page_no': 7,\n",
              "     'bbox': {'l': 500.324,\n",
              "      't': 414.423,\n",
              "      'r': 526.134,\n",
              "      'b': 406.344,\n",
              "      'coord_origin': 'BOTTOMLEFT'},\n",
              "     'charspan': [0, 5]}],\n",
              "   'orig': 'spaCy',\n",
              "   'text': 'spaCy'},\n",
              "  {'self_ref': '#/texts/253',\n",
              "   'parent': {'$ref': '#/body'},\n",
              "   'children': [],\n",
              "   'content_layer': 'body',\n",
              "   'label': 'section_header',\n",
              "   'prov': [{'page_no': 7,\n",
              "     'bbox': {'l': 347.927,\n",
              "      't': 283.11,\n",
              "      'r': 529.574,\n",
              "      'b': 272.3620000000001,\n",
              "      'coord_origin': 'BOTTOMLEFT'},\n",
              "     'charspan': [0, 31]}],\n",
              "   'orig': '8 Future Work and Contributions',\n",
              "   'text': '8 Future Work and Contributions',\n",
              "   'level': 1},\n",
              "  {'self_ref': '#/texts/254',\n",
              "   'parent': {'$ref': '#/body'},\n",
              "   'children': [],\n",
              "   'content_layer': 'body',\n",
              "   'label': 'text',\n",
              "   'prov': [{'page_no': 7,\n",
              "     'bbox': {'l': 319.5,\n",
              "      't': 262.50199999999995,\n",
              "      'r': 558.005,\n",
              "      'b': 100.52499999999998,\n",
              "      'coord_origin': 'BOTTOMLEFT'},\n",
              "     'charspan': [0, 872]}],\n",
              "   'orig': \"Docling's modular architecture allows an easy extension of the model library and pipelines. In the future, we plan to extend Docling with several additional models, such as a figure-classifier model, an equation-recognition model and a code-recognition model. This will help improve the quality of conversion for specific types of content, as well as augment extracted document metadata with additional information. Furthermore, we will focus on building an opensource quality evaluation framework for the tasks performed by Docling, such as layout analysis, table structure recognition, reading order detection, text transcription, etc. This will allow transparent quality comparisons based on publicly available benchmarks such as DP-Bench (Zhong 2020), OmnidDocBench(Ouyang et al. 2024) and others. Results will be published in a future update of this technical report.\",\n",
              "   'text': \"Docling's modular architecture allows an easy extension of the model library and pipelines. In the future, we plan to extend Docling with several additional models, such as a figure-classifier model, an equation-recognition model and a code-recognition model. This will help improve the quality of conversion for specific types of content, as well as augment extracted document metadata with additional information. Furthermore, we will focus on building an opensource quality evaluation framework for the tasks performed by Docling, such as layout analysis, table structure recognition, reading order detection, text transcription, etc. This will allow transparent quality comparisons based on publicly available benchmarks such as DP-Bench (Zhong 2020), OmnidDocBench(Ouyang et al. 2024) and others. Results will be published in a future update of this technical report.\"},\n",
              "  {'self_ref': '#/texts/255',\n",
              "   'parent': {'$ref': '#/body'},\n",
              "   'children': [],\n",
              "   'content_layer': 'body',\n",
              "   'label': 'text',\n",
              "   'prov': [{'page_no': 7,\n",
              "     'bbox': {'l': 329.463,\n",
              "      't': 96.48599999999999,\n",
              "      'r': 557.995,\n",
              "      'b': 87.93399999999997,\n",
              "      'coord_origin': 'BOTTOMLEFT'},\n",
              "     'charspan': [0, 53]}],\n",
              "   'orig': 'The codebase of Docling is open for use under the MIT',\n",
              "   'text': 'The codebase of Docling is open for use under the MIT'},\n",
              "  {'self_ref': '#/texts/256',\n",
              "   'parent': {'$ref': '#/body'},\n",
              "   'children': [],\n",
              "   'content_layer': 'body',\n",
              "   'label': 'text',\n",
              "   'prov': [{'page_no': 8,\n",
              "     'bbox': {'l': 54.0,\n",
              "      't': 734.523,\n",
              "      'r': 292.505,\n",
              "      'b': 704.054,\n",
              "      'coord_origin': 'BOTTOMLEFT'},\n",
              "     'charspan': [0, 170]}],\n",
              "   'orig': 'license agreement and its roadmap is outlined in the discussions section 1 of our GitHub repository. We encourage everyone to propose improvements and make contributions.',\n",
              "   'text': 'license agreement and its roadmap is outlined in the discussions section 1 of our GitHub repository. We encourage everyone to propose improvements and make contributions.'},\n",
              "  {'self_ref': '#/texts/257',\n",
              "   'parent': {'$ref': '#/body'},\n",
              "   'children': [],\n",
              "   'content_layer': 'body',\n",
              "   'label': 'section_header',\n",
              "   'prov': [{'page_no': 8,\n",
              "     'bbox': {'l': 145.478,\n",
              "      't': 691.983,\n",
              "      'r': 201.022,\n",
              "      'b': 681.235,\n",
              "      'coord_origin': 'BOTTOMLEFT'},\n",
              "     'charspan': [0, 10]}],\n",
              "   'orig': 'References',\n",
              "   'text': 'References',\n",
              "   'level': 1},\n",
              "  {'self_ref': '#/texts/258',\n",
              "   'parent': {'$ref': '#/body'},\n",
              "   'children': [],\n",
              "   'content_layer': 'body',\n",
              "   'label': 'text',\n",
              "   'prov': [{'page_no': 8,\n",
              "     'bbox': {'l': 54.0,\n",
              "      't': 676.859,\n",
              "      'r': 292.505,\n",
              "      'b': 657.349,\n",
              "      'coord_origin': 'BOTTOMLEFT'},\n",
              "     'charspan': [0, 98]}],\n",
              "   'orig': '2024. EasyOCR: Ready-to-use OCR with 80+ supported languages. https://github.com/JaidedAI/EasyOCR.',\n",
              "   'text': '2024. EasyOCR: Ready-to-use OCR with 80+ supported languages. https://github.com/JaidedAI/EasyOCR.'},\n",
              "  {'self_ref': '#/texts/259',\n",
              "   'parent': {'$ref': '#/body'},\n",
              "   'children': [],\n",
              "   'content_layer': 'body',\n",
              "   'label': 'text',\n",
              "   'prov': [{'page_no': 8,\n",
              "     'bbox': {'l': 54.0,\n",
              "      't': 653.038,\n",
              "      'r': 286.846,\n",
              "      'b': 644.486,\n",
              "      'coord_origin': 'BOTTOMLEFT'},\n",
              "     'charspan': [0, 50]}],\n",
              "   'orig': '2024. PyMuPDF. https://github.com/pymupdf/PyMuPDF.',\n",
              "   'text': '2024. PyMuPDF. https://github.com/pymupdf/PyMuPDF.'},\n",
              "  {'self_ref': '#/texts/260',\n",
              "   'parent': {'$ref': '#/body'},\n",
              "   'children': [],\n",
              "   'content_layer': 'body',\n",
              "   'label': 'text',\n",
              "   'prov': [{'page_no': 8,\n",
              "     'bbox': {'l': 54.0,\n",
              "      't': 640.176,\n",
              "      'r': 292.505,\n",
              "      'b': 576.829,\n",
              "      'coord_origin': 'BOTTOMLEFT'},\n",
              "     'charspan': [0, 305]}],\n",
              "   'orig': \"Ansel, J.; Yang, E.; He, H.; et al. 2024. PyTorch 2: Faster Machine Learning Through Dynamic Python Bytecode Transformation and Graph Compilation. In Proceedings of the 29th ACM International Conference on Architectural Support for Programming Languages and Operating Systems, Volume 2 (ASPLOS '24) . ACM.\",\n",
              "   'text': \"Ansel, J.; Yang, E.; He, H.; et al. 2024. PyTorch 2: Faster Machine Learning Through Dynamic Python Bytecode Transformation and Graph Compilation. In Proceedings of the 29th ACM International Conference on Architectural Support for Programming Languages and Operating Systems, Volume 2 (ASPLOS '24) . ACM.\"},\n",
              "  {'self_ref': '#/texts/261',\n",
              "   'parent': {'$ref': '#/body'},\n",
              "   'children': [],\n",
              "   'content_layer': 'body',\n",
              "   'label': 'text',\n",
              "   'prov': [{'page_no': 8,\n",
              "     'bbox': {'l': 54.0,\n",
              "      't': 572.519,\n",
              "      'r': 292.505,\n",
              "      'b': 520.131,\n",
              "      'coord_origin': 'BOTTOMLEFT'},\n",
              "     'charspan': [0, 249]}],\n",
              "   'orig': 'Auer, C.; Dolfi, M.; Carvalho, A.; Ramis, C. B.; and Staar, P. W. 2022. Delivering Document Conversion as a Cloud Service with High Throughput and Responsiveness. In 2022 IEEE 15th International Conference on Cloud Computing (CLOUD) , 363-373. IEEE.',\n",
              "   'text': 'Auer, C.; Dolfi, M.; Carvalho, A.; Ramis, C. B.; and Staar, P. W. 2022. Delivering Document Conversion as a Cloud Service with High Throughput and Responsiveness. In 2022 IEEE 15th International Conference on Cloud Computing (CLOUD) , 363-373. IEEE.'},\n",
              "  {'self_ref': '#/texts/262',\n",
              "   'parent': {'$ref': '#/body'},\n",
              "   'children': [],\n",
              "   'content_layer': 'body',\n",
              "   'label': 'text',\n",
              "   'prov': [{'page_no': 8,\n",
              "     'bbox': {'l': 54.0,\n",
              "      't': 515.821,\n",
              "      'r': 292.505,\n",
              "      'b': 496.31,\n",
              "      'coord_origin': 'BOTTOMLEFT'},\n",
              "     'charspan': [0, 103]}],\n",
              "   'orig': 'Berkenbilt, J. 2024. QPDF: A Content-Preserving PDF Document Transformer. https://github.com/qpdf/qpdf.',\n",
              "   'text': 'Berkenbilt, J. 2024. QPDF: A Content-Preserving PDF Document Transformer. https://github.com/qpdf/qpdf.'},\n",
              "  {'self_ref': '#/texts/263',\n",
              "   'parent': {'$ref': '#/body'},\n",
              "   'children': [],\n",
              "   'content_layer': 'body',\n",
              "   'label': 'text',\n",
              "   'prov': [{'page_no': 8,\n",
              "     'bbox': {'l': 54.0,\n",
              "      't': 492.0,\n",
              "      'r': 292.505,\n",
              "      'b': 461.53,\n",
              "      'coord_origin': 'BOTTOMLEFT'},\n",
              "     'charspan': [0, 148]}],\n",
              "   'orig': 'Canny, S.; and contributors. 2013-2024a. python-docx: Create and update Microsoft Word .docx files with Python. https://python-docx.readthedocs.io/.',\n",
              "   'text': 'Canny, S.; and contributors. 2013-2024a. python-docx: Create and update Microsoft Word .docx files with Python. https://python-docx.readthedocs.io/.'},\n",
              "  {'self_ref': '#/texts/264',\n",
              "   'parent': {'$ref': '#/body'},\n",
              "   'children': [],\n",
              "   'content_layer': 'body',\n",
              "   'label': 'text',\n",
              "   'prov': [{'page_no': 8,\n",
              "     'bbox': {'l': 54.0,\n",
              "      't': 457.219,\n",
              "      'r': 292.505,\n",
              "      'b': 426.75,\n",
              "      'coord_origin': 'BOTTOMLEFT'},\n",
              "     'charspan': [0, 157]}],\n",
              "   'orig': 'Canny, S.; and contributors. 2013-2024b. python-pptx: Python library for creating and updating PowerPoint (.pptx) files. https://python-pptx.readthedocs.io/.',\n",
              "   'text': 'Canny, S.; and contributors. 2013-2024b. python-pptx: Python library for creating and updating PowerPoint (.pptx) files. https://python-pptx.readthedocs.io/.'},\n",
              "  {'self_ref': '#/texts/265',\n",
              "   'parent': {'$ref': '#/body'},\n",
              "   'children': [],\n",
              "   'content_layer': 'body',\n",
              "   'label': 'text',\n",
              "   'prov': [{'page_no': 8,\n",
              "     'bbox': {'l': 54.0,\n",
              "      't': 422.439,\n",
              "      'r': 292.505,\n",
              "      'b': 402.928,\n",
              "      'coord_origin': 'BOTTOMLEFT'},\n",
              "     'charspan': [0, 68]}],\n",
              "   'orig': 'Chase, H. 2022. LangChain. https://github.com/langchainai/langchain.',\n",
              "   'text': 'Chase, H. 2022. LangChain. https://github.com/langchainai/langchain.'},\n",
              "  {'self_ref': '#/texts/266',\n",
              "   'parent': {'$ref': '#/body'},\n",
              "   'children': [],\n",
              "   'content_layer': 'body',\n",
              "   'label': 'text',\n",
              "   'prov': [{'page_no': 8,\n",
              "     'bbox': {'l': 54.0,\n",
              "      't': 398.618,\n",
              "      'r': 292.505,\n",
              "      'b': 368.148,\n",
              "      'coord_origin': 'BOTTOMLEFT'},\n",
              "     'charspan': [0, 132]}],\n",
              "   'orig': 'Eric Gazoni, C. C. 2010-2024. openpyxl: A Python library to read/write Excel 2010 xlsx/xlsm files. https://openpyxl.readthedocs.io/.',\n",
              "   'text': 'Eric Gazoni, C. C. 2010-2024. openpyxl: A Python library to read/write Excel 2010 xlsx/xlsm files. https://openpyxl.readthedocs.io/.'},\n",
              "  {'self_ref': '#/texts/267',\n",
              "   'parent': {'$ref': '#/body'},\n",
              "   'children': [],\n",
              "   'content_layer': 'body',\n",
              "   'label': 'text',\n",
              "   'prov': [{'page_no': 8,\n",
              "     'bbox': {'l': 54.0,\n",
              "      't': 363.838,\n",
              "      'r': 292.505,\n",
              "      'b': 344.327,\n",
              "      'coord_origin': 'BOTTOMLEFT'},\n",
              "     'charspan': [0, 89]}],\n",
              "   'orig': 'IBM Research. 2024. Bee Agent Framework. https://github.com/i-am-bee/bee-agent-framework.',\n",
              "   'text': 'IBM Research. 2024. Bee Agent Framework. https://github.com/i-am-bee/bee-agent-framework.'},\n",
              "  {'self_ref': '#/texts/268',\n",
              "   'parent': {'$ref': '#/body'},\n",
              "   'children': [],\n",
              "   'content_layer': 'body',\n",
              "   'label': 'text',\n",
              "   'prov': [{'page_no': 8,\n",
              "     'bbox': {'l': 54.0,\n",
              "      't': 340.017,\n",
              "      'r': 292.505,\n",
              "      'b': 320.506,\n",
              "      'coord_origin': 'BOTTOMLEFT'},\n",
              "     'charspan': [0, 68]}],\n",
              "   'orig': 'Liu, J. 2022. LlamaIndex. https://github.com/jerryjliu/ llama index.',\n",
              "   'text': 'Liu, J. 2022. LlamaIndex. https://github.com/jerryjliu/ llama index.'},\n",
              "  {'self_ref': '#/texts/269',\n",
              "   'parent': {'$ref': '#/body'},\n",
              "   'children': [],\n",
              "   'content_layer': 'body',\n",
              "   'label': 'text',\n",
              "   'prov': [{'page_no': 8,\n",
              "     'bbox': {'l': 54.0,\n",
              "      't': 316.195,\n",
              "      'r': 292.505,\n",
              "      'b': 185.192,\n",
              "      'coord_origin': 'BOTTOMLEFT'},\n",
              "     'charspan': [0, 628]}],\n",
              "   'orig': 'Livathinos, N.; Berrospi, C.; Lysak, M.; Kuropiatnyk, V.; Nassar, A.; Carvalho, A.; Dolfi, M.; Auer, C.; Dinkla, K.; and Staar, P. 2021. Robust PDF Document Conversion using Recurrent Neural Networks. Proceedings of the AAAI Conference on Artificial Intelligence , 35(17): 15137-15145. Lysak, M.; Nassar, A.; Livathinos, N.; Auer, C.; and Staar, P. 2023. Optimized Table Tokenization for Table Structure Recognition. In Document Analysis and Recognition - ICDAR 2023: 17th International Conference, San Jos´ e, CA, USA, August 21-26, 2023, Proceedings, Part II , 3750. Berlin, Heidelberg: Springer-Verlag. ISBN 978-3-03141678-1.',\n",
              "   'text': 'Livathinos, N.; Berrospi, C.; Lysak, M.; Kuropiatnyk, V.; Nassar, A.; Carvalho, A.; Dolfi, M.; Auer, C.; Dinkla, K.; and Staar, P. 2021. Robust PDF Document Conversion using Recurrent Neural Networks. Proceedings of the AAAI Conference on Artificial Intelligence , 35(17): 15137-15145. Lysak, M.; Nassar, A.; Livathinos, N.; Auer, C.; and Staar, P. 2023. Optimized Table Tokenization for Table Structure Recognition. In Document Analysis and Recognition - ICDAR 2023: 17th International Conference, San Jos´ e, CA, USA, August 21-26, 2023, Proceedings, Part II , 3750. Berlin, Heidelberg: Springer-Verlag. ISBN 978-3-03141678-1.'},\n",
              "  {'self_ref': '#/texts/270',\n",
              "   'parent': {'$ref': '#/body'},\n",
              "   'children': [],\n",
              "   'content_layer': 'body',\n",
              "   'label': 'text',\n",
              "   'prov': [{'page_no': 8,\n",
              "     'bbox': {'l': 54.0,\n",
              "      't': 180.88200000000006,\n",
              "      'r': 292.505,\n",
              "      'b': 161.37099999999998,\n",
              "      'coord_origin': 'BOTTOMLEFT'},\n",
              "     'charspan': [0, 105]}],\n",
              "   'orig': 'Ming, F. 2019-2024. Marko: A markdown parser with high extensibility. https://github.com/frostming/marko.',\n",
              "   'text': 'Ming, F. 2019-2024. Marko: A markdown parser with high extensibility. https://github.com/frostming/marko.'},\n",
              "  {'self_ref': '#/texts/271',\n",
              "   'parent': {'$ref': '#/body'},\n",
              "   'children': [],\n",
              "   'content_layer': 'body',\n",
              "   'label': 'text',\n",
              "   'prov': [{'page_no': 8,\n",
              "     'bbox': {'l': 54.0,\n",
              "      't': 157.05999999999995,\n",
              "      'r': 292.505,\n",
              "      'b': 115.63200000000006,\n",
              "      'coord_origin': 'BOTTOMLEFT'},\n",
              "     'charspan': [0, 218]}],\n",
              "   'orig': 'Nassar, A.; Livathinos, N.; Lysak, M.; and Staar, P. 2022. Tableformer: Table structure understanding with transformers. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition , 4614-4623.',\n",
              "   'text': 'Nassar, A.; Livathinos, N.; Lysak, M.; and Staar, P. 2022. Tableformer: Table structure understanding with transformers. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition , 4614-4623.'},\n",
              "  {'self_ref': '#/texts/272',\n",
              "   'parent': {'$ref': '#/body'},\n",
              "   'children': [],\n",
              "   'content_layer': 'body',\n",
              "   'label': 'footnote',\n",
              "   'prov': [{'page_no': 8,\n",
              "     'bbox': {'l': 54.0,\n",
              "      't': 107.66300000000001,\n",
              "      'r': 279.129,\n",
              "      'b': 88.13999999999999,\n",
              "      'coord_origin': 'BOTTOMLEFT'},\n",
              "     'charspan': [0, 66]}],\n",
              "   'orig': '1 https://github.com/DS4SD/docling/discussions/categories/ roadmap',\n",
              "   'text': '1 https://github.com/DS4SD/docling/discussions/categories/ roadmap'},\n",
              "  {'self_ref': '#/texts/273',\n",
              "   'parent': {'$ref': '#/body'},\n",
              "   'children': [],\n",
              "   'content_layer': 'body',\n",
              "   'label': 'text',\n",
              "   'prov': [{'page_no': 8,\n",
              "     'bbox': {'l': 319.5,\n",
              "      't': 734.523,\n",
              "      'r': 558.005,\n",
              "      'b': 671.177,\n",
              "      'coord_origin': 'BOTTOMLEFT'},\n",
              "     'charspan': [0, 301]}],\n",
              "   'orig': 'Ouyang, L.; Qu, Y.; Zhou, H.; Zhu, J.; Zhang, R.; Lin, Q.; Wang, B.; Zhao, Z.; Jiang, M.; Zhao, X.; Shi, J.; Wu, F.; Chu, P.; Liu, M.; Li, Z.; Xu, C.; Zhang, B.; Shi, B.; Tu, Z.; and He, C. 2024. OmniDocBench: Benchmarking Diverse PDF Document Parsing with Comprehensive Annotations. arXiv:2412.07626.',\n",
              "   'text': 'Ouyang, L.; Qu, Y.; Zhou, H.; Zhu, J.; Zhang, R.; Lin, Q.; Wang, B.; Zhao, Z.; Jiang, M.; Zhao, X.; Shi, J.; Wu, F.; Chu, P.; Liu, M.; Li, Z.; Xu, C.; Zhang, B.; Shi, B.; Tu, Z.; and He, C. 2024. OmniDocBench: Benchmarking Diverse PDF Document Parsing with Comprehensive Annotations. arXiv:2412.07626.'},\n",
              "  {'self_ref': '#/texts/274',\n",
              "   'parent': {'$ref': '#/body'},\n",
              "   'children': [],\n",
              "   'content_layer': 'body',\n",
              "   'label': 'text',\n",
              "   'prov': [{'page_no': 8,\n",
              "     'bbox': {'l': 319.5,\n",
              "      't': 666.279,\n",
              "      'r': 558.005,\n",
              "      'b': 635.809,\n",
              "      'coord_origin': 'BOTTOMLEFT'},\n",
              "     'charspan': [0, 119]}],\n",
              "   'orig': 'Paruchuri, V. 2024. Marker: Convert PDF to Markdown Quickly with High Accuracy. https://github.com/VikParuchuri/marker.',\n",
              "   'text': 'Paruchuri, V. 2024. Marker: Convert PDF to Markdown Quickly with High Accuracy. https://github.com/VikParuchuri/marker.'},\n",
              "  {'self_ref': '#/texts/275',\n",
              "   'parent': {'$ref': '#/body'},\n",
              "   'children': [],\n",
              "   'content_layer': 'body',\n",
              "   'label': 'text',\n",
              "   'prov': [{'page_no': 8,\n",
              "     'bbox': {'l': 319.5,\n",
              "      't': 630.912,\n",
              "      'r': 558.005,\n",
              "      'b': 600.442,\n",
              "      'coord_origin': 'BOTTOMLEFT'},\n",
              "     'charspan': [0, 158]}],\n",
              "   'orig': 'Pfitzmann, B.; Auer, C.; Dolfi, M.; Nassar, A. S.; and Staar, P. 2022. DocLayNet: a large human-annotated dataset for document-layout segmentation. 3743-3751.',\n",
              "   'text': 'Pfitzmann, B.; Auer, C.; Dolfi, M.; Nassar, A. S.; and Staar, P. 2022. DocLayNet: a large human-annotated dataset for document-layout segmentation. 3743-3751.'},\n",
              "  {'self_ref': '#/texts/276',\n",
              "   'parent': {'$ref': '#/body'},\n",
              "   'children': [],\n",
              "   'content_layer': 'body',\n",
              "   'label': 'text',\n",
              "   'prov': [{'page_no': 8,\n",
              "     'bbox': {'l': 319.5,\n",
              "      't': 595.545,\n",
              "      'r': 558.005,\n",
              "      'b': 576.034,\n",
              "      'coord_origin': 'BOTTOMLEFT'},\n",
              "     'charspan': [0, 91]}],\n",
              "   'orig': 'pypdf Maintainers. 2024. pypdf: A Pure-Python PDF Library. https://github.com/py-pdf/pypdf.',\n",
              "   'text': 'pypdf Maintainers. 2024. pypdf: A Pure-Python PDF Library. https://github.com/py-pdf/pypdf.'},\n",
              "  {'self_ref': '#/texts/277',\n",
              "   'parent': {'$ref': '#/body'},\n",
              "   'children': [],\n",
              "   'content_layer': 'body',\n",
              "   'label': 'text',\n",
              "   'prov': [{'page_no': 8,\n",
              "     'bbox': {'l': 319.5,\n",
              "      't': 571.136,\n",
              "      'r': 558.005,\n",
              "      'b': 551.625,\n",
              "      'coord_origin': 'BOTTOMLEFT'},\n",
              "     'charspan': [0, 104]}],\n",
              "   'orig': 'PyPDFium Team. 2024. PyPDFium2: Python bindings for PDFium. https://github.com/pypdfium2-team/pypdfium2.',\n",
              "   'text': 'PyPDFium Team. 2024. PyPDFium2: Python bindings for PDFium. https://github.com/pypdfium2-team/pypdfium2.'},\n",
              "  {'self_ref': '#/texts/278',\n",
              "   'parent': {'$ref': '#/body'},\n",
              "   'children': [],\n",
              "   'content_layer': 'body',\n",
              "   'label': 'text',\n",
              "   'prov': [{'page_no': 8,\n",
              "     'bbox': {'l': 319.5,\n",
              "      't': 546.728,\n",
              "      'r': 558.005,\n",
              "      'b': 516.258,\n",
              "      'coord_origin': 'BOTTOMLEFT'},\n",
              "     'charspan': [0, 132]}],\n",
              "   'orig': 'Richardson, L. 2004-2024. Beautiful Soup: A Python library for parsing HTML and XML. https://www.crummy.com/software/BeautifulSoup/.',\n",
              "   'text': 'Richardson, L. 2004-2024. Beautiful Soup: A Python library for parsing HTML and XML. https://www.crummy.com/software/BeautifulSoup/.'},\n",
              "  {'self_ref': '#/texts/279',\n",
              "   'parent': {'$ref': '#/body'},\n",
              "   'children': [],\n",
              "   'content_layer': 'body',\n",
              "   'label': 'text',\n",
              "   'prov': [{'page_no': 8,\n",
              "     'bbox': {'l': 319.5,\n",
              "      't': 511.36,\n",
              "      'r': 558.005,\n",
              "      'b': 480.89,\n",
              "      'coord_origin': 'BOTTOMLEFT'},\n",
              "     'charspan': [0, 148]}],\n",
              "   'orig': 'Sudalairaj, S.; Bhandwaldar, A.; Pareja, A.; Xu, K.; Cox, D. D.; and Srivastava, A. 2024. LAB: Large-Scale Alignment for ChatBots. arXiv:2403.01081.',\n",
              "   'text': 'Sudalairaj, S.; Bhandwaldar, A.; Pareja, A.; Xu, K.; Cox, D. D.; and Srivastava, A. 2024. LAB: Large-Scale Alignment for ChatBots. arXiv:2403.01081.'},\n",
              "  {'self_ref': '#/texts/280',\n",
              "   'parent': {'$ref': '#/body'},\n",
              "   'children': [],\n",
              "   'content_layer': 'body',\n",
              "   'label': 'text',\n",
              "   'prov': [{'page_no': 8,\n",
              "     'bbox': {'l': 319.5,\n",
              "      't': 475.993,\n",
              "      'r': 558.005,\n",
              "      'b': 412.646,\n",
              "      'coord_origin': 'BOTTOMLEFT'},\n",
              "     'charspan': [0, 342]}],\n",
              "   'orig': 'Turski, M.; Stanisławek, T.; Kaczmarek, K.; Dyda, P.; and Grali´ nski, F. 2023. CCpdf: Building a High Quality Corpus for Visually Rich Documents from Web Crawl Data. In Fink, G. A.; Jain, R.; Kise, K.; and Zanibbi, R., eds., Document Analysis and Recognition - ICDAR 2023 , 348-365. Cham: Springer Nature Switzerland. ISBN 978-3-031-41682-8.',\n",
              "   'text': 'Turski, M.; Stanisławek, T.; Kaczmarek, K.; Dyda, P.; and Grali´ nski, F. 2023. CCpdf: Building a High Quality Corpus for Visually Rich Documents from Web Crawl Data. In Fink, G. A.; Jain, R.; Kise, K.; and Zanibbi, R., eds., Document Analysis and Recognition - ICDAR 2023 , 348-365. Cham: Springer Nature Switzerland. ISBN 978-3-031-41682-8.'},\n",
              "  {'self_ref': '#/texts/281',\n",
              "   'parent': {'$ref': '#/body'},\n",
              "   'children': [],\n",
              "   'content_layer': 'body',\n",
              "   'label': 'text',\n",
              "   'prov': [{'page_no': 8,\n",
              "     'bbox': {'l': 319.5,\n",
              "      't': 407.749,\n",
              "      'r': 558.005,\n",
              "      'b': 377.279,\n",
              "      'coord_origin': 'BOTTOMLEFT'},\n",
              "     'charspan': [0, 146]}],\n",
              "   'orig': 'Unstructured.io Team. 2024. Unstructured.io: OpenSource Pre-Processing Tools for Unstructured Data. https://unstructured.io. Accessed: 2024-11-19.',\n",
              "   'text': 'Unstructured.io Team. 2024. Unstructured.io: OpenSource Pre-Processing Tools for Unstructured Data. https://unstructured.io. Accessed: 2024-11-19.'},\n",
              "  {'self_ref': '#/texts/282',\n",
              "   'parent': {'$ref': '#/body'},\n",
              "   'children': [],\n",
              "   'content_layer': 'body',\n",
              "   'label': 'text',\n",
              "   'prov': [{'page_no': 8,\n",
              "     'bbox': {'l': 319.5,\n",
              "      't': 372.381,\n",
              "      'r': 558.005,\n",
              "      'b': 319.994,\n",
              "      'coord_origin': 'BOTTOMLEFT'},\n",
              "     'charspan': [0, 266]}],\n",
              "   'orig': 'Wang, B.; Xu, C.; Zhao, X.; Ouyang, L.; Wu, F.; Zhao, Z.; Xu, R.; Liu, K.; Qu, Y.; Shang, F.; Zhang, B.; Wei, L.; Sui, Z.; Li, W.; Shi, B.; Qiao, Y.; Lin, D.; and He, C. 2024. MinerU: An Open-Source Solution for Precise Document Content Extraction. arXiv:2409.18839.',\n",
              "   'text': 'Wang, B.; Xu, C.; Zhao, X.; Ouyang, L.; Wu, F.; Zhao, Z.; Xu, R.; Liu, K.; Qu, Y.; Shang, F.; Zhang, B.; Wei, L.; Sui, Z.; Li, W.; Shi, B.; Qiao, Y.; Lin, D.; and He, C. 2024. MinerU: An Open-Source Solution for Precise Document Content Extraction. arXiv:2409.18839.'},\n",
              "  {'self_ref': '#/texts/283',\n",
              "   'parent': {'$ref': '#/body'},\n",
              "   'children': [],\n",
              "   'content_layer': 'body',\n",
              "   'label': 'text',\n",
              "   'prov': [{'page_no': 8,\n",
              "     'bbox': {'l': 319.5,\n",
              "      't': 315.096,\n",
              "      'r': 558.005,\n",
              "      'b': 251.75,\n",
              "      'coord_origin': 'BOTTOMLEFT'},\n",
              "     'charspan': [0, 358]}],\n",
              "   'orig': \"Wolf, T.; Debut, L.; Sanh, V.; Chaumond, J.; Delangue, C.; Moi, A.; Cistac, P.; Rault, T.; Louf, R.; Funtowicz, M.; Davison, J.; Shleifer, S.; von Platen, P.; Ma, C.; Jernite, Y .; Plu, J.; Xu, C.; Scao, T. L.; Gugger, S.; Drame, M.; Lhoest, Q.; and Rush, A. M. 2020. HuggingFace's Transformers: Stateof-the-art Natural Language Processing. arXiv:1910.03771.\",\n",
              "   'text': \"Wolf, T.; Debut, L.; Sanh, V.; Chaumond, J.; Delangue, C.; Moi, A.; Cistac, P.; Rault, T.; Louf, R.; Funtowicz, M.; Davison, J.; Shleifer, S.; von Platen, P.; Ma, C.; Jernite, Y .; Plu, J.; Xu, C.; Scao, T. L.; Gugger, S.; Drame, M.; Lhoest, Q.; and Rush, A. M. 2020. HuggingFace's Transformers: Stateof-the-art Natural Language Processing. arXiv:1910.03771.\"},\n",
              "  {'self_ref': '#/texts/284',\n",
              "   'parent': {'$ref': '#/body'},\n",
              "   'children': [],\n",
              "   'content_layer': 'body',\n",
              "   'label': 'text',\n",
              "   'prov': [{'page_no': 8,\n",
              "     'bbox': {'l': 319.5,\n",
              "      't': 246.85199999999998,\n",
              "      'r': 558.005,\n",
              "      'b': 172.54700000000003,\n",
              "      'coord_origin': 'BOTTOMLEFT'},\n",
              "     'charspan': [0, 388]}],\n",
              "   'orig': 'Wood, D.; Lublinsky, B.; Roytman, A.; Singh, S.; Adam, C.; Adebayo, A.; An, S.; Chang, Y. C.; Dang, X.-H.; Desai, N.; Dolfi, M.; Emami-Gohari, H.; Eres, R.; Goto, T.; Joshi, D.; Koyfman, Y.; Nassar, M.; Patel, H.; Selvam, P.; Shah, Y.; Surendran, S.; Tsuzuku, D.; Zerfos, P.; and Daijavad, S. 2024. Data-Prep-Kit: getting your data ready for LLM application development. arXiv:2409.18164.',\n",
              "   'text': 'Wood, D.; Lublinsky, B.; Roytman, A.; Singh, S.; Adam, C.; Adebayo, A.; An, S.; Chang, Y. C.; Dang, X.-H.; Desai, N.; Dolfi, M.; Emami-Gohari, H.; Eres, R.; Goto, T.; Joshi, D.; Koyfman, Y.; Nassar, M.; Patel, H.; Selvam, P.; Shah, Y.; Surendran, S.; Tsuzuku, D.; Zerfos, P.; and Daijavad, S. 2024. Data-Prep-Kit: getting your data ready for LLM application development. arXiv:2409.18164.'},\n",
              "  {'self_ref': '#/texts/285',\n",
              "   'parent': {'$ref': '#/body'},\n",
              "   'children': [],\n",
              "   'content_layer': 'body',\n",
              "   'label': 'text',\n",
              "   'prov': [{'page_no': 8,\n",
              "     'bbox': {'l': 319.5,\n",
              "      't': 167.649,\n",
              "      'r': 558.005,\n",
              "      'b': 137.17899999999997,\n",
              "      'coord_origin': 'BOTTOMLEFT'},\n",
              "     'charspan': [0, 148]}],\n",
              "   'orig': 'Zhao, Y.; Lv, W.; Xu, S.; Wei, J.; Wang, G.; Dang, Q.; Liu, Y.; and Chen, J. 2023. DETRs Beat YOLOs on Real-time Object Detection. arXiv:2304.08069.',\n",
              "   'text': 'Zhao, Y.; Lv, W.; Xu, S.; Wei, J.; Wang, G.; Dang, Q.; Liu, Y.; and Chen, J. 2023. DETRs Beat YOLOs on Real-time Object Detection. arXiv:2304.08069.'},\n",
              "  {'self_ref': '#/texts/286',\n",
              "   'parent': {'$ref': '#/body'},\n",
              "   'children': [],\n",
              "   'content_layer': 'body',\n",
              "   'label': 'text',\n",
              "   'prov': [{'page_no': 8,\n",
              "     'bbox': {'l': 319.5,\n",
              "      't': 132.28200000000004,\n",
              "      'r': 558.005,\n",
              "      'b': 112.77099999999996,\n",
              "      'coord_origin': 'BOTTOMLEFT'},\n",
              "     'charspan': [0, 93]}],\n",
              "   'orig': 'Zhong, X. 2020. Image-based table recognition: data, model, and evaluation. arXiv:1911.10683.',\n",
              "   'text': 'Zhong, X. 2020. Image-based table recognition: data, model, and evaluation. arXiv:1911.10683.'}],\n",
              " 'pictures': [{'self_ref': '#/pictures/0',\n",
              "   'parent': {'$ref': '#/body'},\n",
              "   'children': [{'$ref': '#/texts/22'},\n",
              "    {'$ref': '#/texts/23'},\n",
              "    {'$ref': '#/texts/24'},\n",
              "    {'$ref': '#/texts/25'},\n",
              "    {'$ref': '#/texts/26'},\n",
              "    {'$ref': '#/texts/27'},\n",
              "    {'$ref': '#/texts/28'},\n",
              "    {'$ref': '#/texts/29'},\n",
              "    {'$ref': '#/texts/30'},\n",
              "    {'$ref': '#/texts/31'},\n",
              "    {'$ref': '#/texts/32'},\n",
              "    {'$ref': '#/texts/33'},\n",
              "    {'$ref': '#/texts/34'},\n",
              "    {'$ref': '#/texts/35'},\n",
              "    {'$ref': '#/texts/36'},\n",
              "    {'$ref': '#/texts/37'},\n",
              "    {'$ref': '#/texts/38'},\n",
              "    {'$ref': '#/texts/39'},\n",
              "    {'$ref': '#/texts/40'},\n",
              "    {'$ref': '#/texts/41'},\n",
              "    {'$ref': '#/texts/42'},\n",
              "    {'$ref': '#/texts/43'},\n",
              "    {'$ref': '#/texts/44'},\n",
              "    {'$ref': '#/texts/45'},\n",
              "    {'$ref': '#/texts/46'},\n",
              "    {'$ref': '#/texts/47'},\n",
              "    {'$ref': '#/texts/48'},\n",
              "    {'$ref': '#/texts/49'},\n",
              "    {'$ref': '#/texts/50'},\n",
              "    {'$ref': '#/texts/51'},\n",
              "    {'$ref': '#/texts/52'},\n",
              "    {'$ref': '#/texts/53'},\n",
              "    {'$ref': '#/texts/54'},\n",
              "    {'$ref': '#/texts/55'},\n",
              "    {'$ref': '#/texts/56'},\n",
              "    {'$ref': '#/texts/57'},\n",
              "    {'$ref': '#/texts/58'},\n",
              "    {'$ref': '#/texts/59'},\n",
              "    {'$ref': '#/texts/60'},\n",
              "    {'$ref': '#/texts/61'},\n",
              "    {'$ref': '#/texts/62'},\n",
              "    {'$ref': '#/texts/63'}],\n",
              "   'content_layer': 'body',\n",
              "   'label': 'picture',\n",
              "   'prov': [{'page_no': 2,\n",
              "     'bbox': {'l': 92.13404846191406,\n",
              "      't': 737.0841445922852,\n",
              "      'r': 514.7477416992188,\n",
              "      'b': 538.5709838867188,\n",
              "      'coord_origin': 'BOTTOMLEFT'},\n",
              "     'charspan': [0, 0]}],\n",
              "   'captions': [{'$ref': '#/texts/22'}],\n",
              "   'references': [],\n",
              "   'footnotes': [],\n",
              "   'annotations': []},\n",
              "  {'self_ref': '#/pictures/1',\n",
              "   'parent': {'$ref': '#/body'},\n",
              "   'children': [{'$ref': '#/texts/113'},\n",
              "    {'$ref': '#/texts/114'},\n",
              "    {'$ref': '#/texts/115'},\n",
              "    {'$ref': '#/texts/116'},\n",
              "    {'$ref': '#/texts/117'},\n",
              "    {'$ref': '#/texts/118'},\n",
              "    {'$ref': '#/texts/119'},\n",
              "    {'$ref': '#/texts/120'},\n",
              "    {'$ref': '#/texts/121'},\n",
              "    {'$ref': '#/texts/122'},\n",
              "    {'$ref': '#/texts/123'},\n",
              "    {'$ref': '#/texts/124'},\n",
              "    {'$ref': '#/texts/125'},\n",
              "    {'$ref': '#/texts/126'},\n",
              "    {'$ref': '#/texts/127'},\n",
              "    {'$ref': '#/texts/128'},\n",
              "    {'$ref': '#/texts/129'},\n",
              "    {'$ref': '#/texts/130'},\n",
              "    {'$ref': '#/texts/131'},\n",
              "    {'$ref': '#/texts/132'},\n",
              "    {'$ref': '#/texts/133'},\n",
              "    {'$ref': '#/texts/134'},\n",
              "    {'$ref': '#/texts/135'},\n",
              "    {'$ref': '#/texts/136'},\n",
              "    {'$ref': '#/texts/137'},\n",
              "    {'$ref': '#/texts/138'},\n",
              "    {'$ref': '#/texts/139'},\n",
              "    {'$ref': '#/texts/140'},\n",
              "    {'$ref': '#/texts/141'},\n",
              "    {'$ref': '#/texts/142'},\n",
              "    {'$ref': '#/texts/143'},\n",
              "    {'$ref': '#/texts/144'},\n",
              "    {'$ref': '#/texts/145'},\n",
              "    {'$ref': '#/texts/146'},\n",
              "    {'$ref': '#/texts/147'},\n",
              "    {'$ref': '#/texts/148'},\n",
              "    {'$ref': '#/texts/149'},\n",
              "    {'$ref': '#/texts/150'},\n",
              "    {'$ref': '#/texts/151'}],\n",
              "   'content_layer': 'body',\n",
              "   'label': 'picture',\n",
              "   'prov': [{'page_no': 5,\n",
              "     'bbox': {'l': 71.60702514648438,\n",
              "      't': 615.9085083007812,\n",
              "      'r': 278.9543151855469,\n",
              "      'b': 326.2925720214844,\n",
              "      'coord_origin': 'BOTTOMLEFT'},\n",
              "     'charspan': [0, 0]}],\n",
              "   'captions': [{'$ref': '#/texts/113'}],\n",
              "   'references': [],\n",
              "   'footnotes': [],\n",
              "   'annotations': []},\n",
              "  {'self_ref': '#/pictures/2',\n",
              "   'parent': {'$ref': '#/body'},\n",
              "   'children': [{'$ref': '#/texts/159'},\n",
              "    {'$ref': '#/texts/160'},\n",
              "    {'$ref': '#/texts/161'},\n",
              "    {'$ref': '#/texts/162'},\n",
              "    {'$ref': '#/texts/163'},\n",
              "    {'$ref': '#/texts/164'},\n",
              "    {'$ref': '#/texts/165'},\n",
              "    {'$ref': '#/texts/166'},\n",
              "    {'$ref': '#/texts/167'},\n",
              "    {'$ref': '#/texts/168'},\n",
              "    {'$ref': '#/texts/169'},\n",
              "    {'$ref': '#/texts/170'},\n",
              "    {'$ref': '#/texts/171'}],\n",
              "   'content_layer': 'body',\n",
              "   'label': 'picture',\n",
              "   'prov': [{'page_no': 5,\n",
              "     'bbox': {'l': 356.2509460449219,\n",
              "      't': 509.60369873046875,\n",
              "      'r': 521.4921264648438,\n",
              "      'b': 343.9695739746094,\n",
              "      'coord_origin': 'BOTTOMLEFT'},\n",
              "     'charspan': [0, 0]}],\n",
              "   'captions': [{'$ref': '#/texts/159'}],\n",
              "   'references': [],\n",
              "   'footnotes': [],\n",
              "   'annotations': []},\n",
              "  {'self_ref': '#/pictures/3',\n",
              "   'parent': {'$ref': '#/body'},\n",
              "   'children': [{'$ref': '#/texts/189'},\n",
              "    {'$ref': '#/texts/190'},\n",
              "    {'$ref': '#/texts/191'},\n",
              "    {'$ref': '#/texts/192'},\n",
              "    {'$ref': '#/texts/193'},\n",
              "    {'$ref': '#/texts/194'},\n",
              "    {'$ref': '#/texts/195'},\n",
              "    {'$ref': '#/texts/196'},\n",
              "    {'$ref': '#/texts/197'},\n",
              "    {'$ref': '#/texts/198'},\n",
              "    {'$ref': '#/texts/199'},\n",
              "    {'$ref': '#/texts/200'},\n",
              "    {'$ref': '#/texts/201'},\n",
              "    {'$ref': '#/texts/202'},\n",
              "    {'$ref': '#/texts/203'},\n",
              "    {'$ref': '#/texts/204'},\n",
              "    {'$ref': '#/texts/205'},\n",
              "    {'$ref': '#/texts/206'},\n",
              "    {'$ref': '#/texts/207'},\n",
              "    {'$ref': '#/texts/208'},\n",
              "    {'$ref': '#/texts/209'},\n",
              "    {'$ref': '#/texts/210'},\n",
              "    {'$ref': '#/texts/211'},\n",
              "    {'$ref': '#/texts/212'},\n",
              "    {'$ref': '#/texts/213'},\n",
              "    {'$ref': '#/texts/214'},\n",
              "    {'$ref': '#/texts/215'},\n",
              "    {'$ref': '#/texts/216'},\n",
              "    {'$ref': '#/texts/217'}],\n",
              "   'content_layer': 'body',\n",
              "   'label': 'picture',\n",
              "   'prov': [{'page_no': 7,\n",
              "     'bbox': {'l': 105.40738677978516,\n",
              "      't': 738.2883567810059,\n",
              "      'r': 506.916748046875,\n",
              "      'b': 540.9850769042969,\n",
              "      'coord_origin': 'BOTTOMLEFT'},\n",
              "     'charspan': [0, 0]}],\n",
              "   'captions': [{'$ref': '#/texts/189'}],\n",
              "   'references': [],\n",
              "   'footnotes': [],\n",
              "   'annotations': []},\n",
              "  {'self_ref': '#/pictures/4',\n",
              "   'parent': {'$ref': '#/body'},\n",
              "   'children': [{'$ref': '#/texts/218'},\n",
              "    {'$ref': '#/texts/219'},\n",
              "    {'$ref': '#/texts/220'},\n",
              "    {'$ref': '#/texts/221'},\n",
              "    {'$ref': '#/texts/222'},\n",
              "    {'$ref': '#/texts/223'},\n",
              "    {'$ref': '#/texts/224'},\n",
              "    {'$ref': '#/texts/225'},\n",
              "    {'$ref': '#/texts/226'},\n",
              "    {'$ref': '#/texts/227'},\n",
              "    {'$ref': '#/texts/228'},\n",
              "    {'$ref': '#/texts/229'},\n",
              "    {'$ref': '#/texts/230'},\n",
              "    {'$ref': '#/texts/231'},\n",
              "    {'$ref': '#/texts/232'},\n",
              "    {'$ref': '#/texts/233'},\n",
              "    {'$ref': '#/texts/234'},\n",
              "    {'$ref': '#/texts/235'}],\n",
              "   'content_layer': 'body',\n",
              "   'label': 'picture',\n",
              "   'prov': [{'page_no': 7,\n",
              "     'bbox': {'l': 79.11772155761719,\n",
              "      't': 462.92974853515625,\n",
              "      'r': 268.16009521484375,\n",
              "      'b': 275.2188720703125,\n",
              "      'coord_origin': 'BOTTOMLEFT'},\n",
              "     'charspan': [0, 0]}],\n",
              "   'captions': [{'$ref': '#/texts/218'}],\n",
              "   'references': [],\n",
              "   'footnotes': [],\n",
              "   'annotations': []},\n",
              "  {'self_ref': '#/pictures/5',\n",
              "   'parent': {'$ref': '#/body'},\n",
              "   'children': [{'$ref': '#/texts/238'},\n",
              "    {'$ref': '#/texts/239'},\n",
              "    {'$ref': '#/texts/240'},\n",
              "    {'$ref': '#/texts/241'},\n",
              "    {'$ref': '#/texts/242'},\n",
              "    {'$ref': '#/texts/243'},\n",
              "    {'$ref': '#/texts/244'},\n",
              "    {'$ref': '#/texts/245'},\n",
              "    {'$ref': '#/texts/246'},\n",
              "    {'$ref': '#/texts/247'},\n",
              "    {'$ref': '#/texts/248'},\n",
              "    {'$ref': '#/texts/249'},\n",
              "    {'$ref': '#/texts/250'},\n",
              "    {'$ref': '#/texts/251'},\n",
              "    {'$ref': '#/texts/252'}],\n",
              "   'content_layer': 'body',\n",
              "   'label': 'picture',\n",
              "   'prov': [{'page_no': 7,\n",
              "     'bbox': {'l': 322.7547912597656,\n",
              "      't': 460.4932861328125,\n",
              "      'r': 553.9041137695312,\n",
              "      'b': 361.5787353515625,\n",
              "      'coord_origin': 'BOTTOMLEFT'},\n",
              "     'charspan': [0, 0]}],\n",
              "   'captions': [{'$ref': '#/texts/238'}],\n",
              "   'references': [],\n",
              "   'footnotes': [],\n",
              "   'annotations': []}],\n",
              " 'tables': [{'self_ref': '#/tables/0',\n",
              "   'parent': {'$ref': '#/body'},\n",
              "   'children': [{'$ref': '#/texts/112'}],\n",
              "   'content_layer': 'body',\n",
              "   'label': 'table',\n",
              "   'prov': [{'page_no': 5,\n",
              "     'bbox': {'l': 155.46766662597656,\n",
              "      't': 717.3967056274414,\n",
              "      'r': 456.41375732421875,\n",
              "      'b': 637.3744354248047,\n",
              "      'coord_origin': 'BOTTOMLEFT'},\n",
              "     'charspan': [0, 0]}],\n",
              "   'captions': [{'$ref': '#/texts/112'}],\n",
              "   'references': [],\n",
              "   'footnotes': [],\n",
              "   'data': {'table_cells': [{'bbox': {'l': 188.384,\n",
              "       't': 79.99400000000003,\n",
              "       'r': 208.8,\n",
              "       'b': 88.05499999999995,\n",
              "       'coord_origin': 'TOPLEFT'},\n",
              "      'row_span': 1,\n",
              "      'col_span': 1,\n",
              "      'start_row_offset_idx': 0,\n",
              "      'end_row_offset_idx': 1,\n",
              "      'start_col_offset_idx': 0,\n",
              "      'end_col_offset_idx': 1,\n",
              "      'text': 'Asset',\n",
              "      'column_header': True,\n",
              "      'row_header': False,\n",
              "      'row_section': False,\n",
              "      'fillable': False},\n",
              "     {'bbox': {'l': 220.753,\n",
              "       't': 79.99400000000003,\n",
              "       'r': 249.741,\n",
              "       'b': 88.05499999999995,\n",
              "       'coord_origin': 'TOPLEFT'},\n",
              "      'row_span': 1,\n",
              "      'col_span': 1,\n",
              "      'start_row_offset_idx': 0,\n",
              "      'end_row_offset_idx': 1,\n",
              "      'start_col_offset_idx': 1,\n",
              "      'end_col_offset_idx': 2,\n",
              "      'text': 'Version',\n",
              "      'column_header': True,\n",
              "      'row_header': False,\n",
              "      'row_section': False,\n",
              "      'fillable': False},\n",
              "     {'bbox': {'l': 261.702,\n",
              "       't': 79.99400000000003,\n",
              "       'r': 281.626,\n",
              "       'b': 88.05499999999995,\n",
              "       'coord_origin': 'TOPLEFT'},\n",
              "      'row_span': 1,\n",
              "      'col_span': 1,\n",
              "      'start_row_offset_idx': 0,\n",
              "      'end_row_offset_idx': 1,\n",
              "      'start_col_offset_idx': 2,\n",
              "      'end_col_offset_idx': 3,\n",
              "      'text': 'OCR',\n",
              "      'column_header': True,\n",
              "      'row_header': False,\n",
              "      'row_section': False,\n",
              "      'fillable': False},\n",
              "     {'bbox': {'l': 313.008,\n",
              "       't': 79.99400000000003,\n",
              "       'r': 340.185,\n",
              "       'b': 88.05499999999995,\n",
              "       'coord_origin': 'TOPLEFT'},\n",
              "      'row_span': 1,\n",
              "      'col_span': 1,\n",
              "      'start_row_offset_idx': 0,\n",
              "      'end_row_offset_idx': 1,\n",
              "      'start_col_offset_idx': 3,\n",
              "      'end_col_offset_idx': 4,\n",
              "      'text': 'Layout',\n",
              "      'column_header': True,\n",
              "      'row_header': False,\n",
              "      'row_section': False,\n",
              "      'fillable': False},\n",
              "     {'bbox': {'l': 379.494,\n",
              "       't': 79.99400000000003,\n",
              "       'r': 404.08,\n",
              "       'b': 88.05499999999995,\n",
              "       'coord_origin': 'TOPLEFT'},\n",
              "      'row_span': 1,\n",
              "      'col_span': 1,\n",
              "      'start_row_offset_idx': 0,\n",
              "      'end_row_offset_idx': 1,\n",
              "      'start_col_offset_idx': 4,\n",
              "      'end_col_offset_idx': 5,\n",
              "      'text': 'Tables',\n",
              "      'column_header': True,\n",
              "      'row_header': False,\n",
              "      'row_section': False,\n",
              "      'fillable': False},\n",
              "     {'bbox': {'l': 179.911,\n",
              "       't': 96.22000000000003,\n",
              "       'r': 208.801,\n",
              "       'b': 103.91700000000003,\n",
              "       'coord_origin': 'TOPLEFT'},\n",
              "      'row_span': 1,\n",
              "      'col_span': 1,\n",
              "      'start_row_offset_idx': 1,\n",
              "      'end_row_offset_idx': 2,\n",
              "      'start_col_offset_idx': 0,\n",
              "      'end_col_offset_idx': 1,\n",
              "      'text': 'Docling',\n",
              "      'column_header': False,\n",
              "      'row_header': False,\n",
              "      'row_section': False,\n",
              "      'fillable': False},\n",
              "     {'bbox': {'l': 220.753,\n",
              "       't': 96.22000000000003,\n",
              "       'r': 238.686,\n",
              "       'b': 103.91700000000003,\n",
              "       'coord_origin': 'TOPLEFT'},\n",
              "      'row_span': 1,\n",
              "      'col_span': 1,\n",
              "      'start_row_offset_idx': 1,\n",
              "      'end_row_offset_idx': 2,\n",
              "      'start_col_offset_idx': 1,\n",
              "      'end_col_offset_idx': 2,\n",
              "      'text': '2.5.2',\n",
              "      'column_header': False,\n",
              "      'row_header': False,\n",
              "      'row_section': False,\n",
              "      'fillable': False},\n",
              "     {'bbox': {'l': 261.703,\n",
              "       't': 94.35699999999997,\n",
              "       'r': 300.553,\n",
              "       'b': 103.91700000000003,\n",
              "       'coord_origin': 'TOPLEFT'},\n",
              "      'row_span': 1,\n",
              "      'col_span': 1,\n",
              "      'start_row_offset_idx': 1,\n",
              "      'end_row_offset_idx': 2,\n",
              "      'start_col_offset_idx': 2,\n",
              "      'end_col_offset_idx': 3,\n",
              "      'text': 'EasyOCR *',\n",
              "      'column_header': False,\n",
              "      'row_header': False,\n",
              "      'row_section': False,\n",
              "      'fillable': False},\n",
              "     {'bbox': {'l': 313.006,\n",
              "       't': 96.22000000000003,\n",
              "       'r': 337.816,\n",
              "       'b': 103.91700000000003,\n",
              "       'coord_origin': 'TOPLEFT'},\n",
              "      'row_span': 1,\n",
              "      'col_span': 1,\n",
              "      'start_row_offset_idx': 1,\n",
              "      'end_row_offset_idx': 2,\n",
              "      'start_col_offset_idx': 3,\n",
              "      'end_col_offset_idx': 4,\n",
              "      'text': 'default',\n",
              "      'column_header': False,\n",
              "      'row_header': False,\n",
              "      'row_section': False,\n",
              "      'fillable': False},\n",
              "     {'bbox': {'l': 379.492,\n",
              "       't': 94.35699999999997,\n",
              "       'r': 449.515,\n",
              "       'b': 103.91700000000003,\n",
              "       'coord_origin': 'TOPLEFT'},\n",
              "      'row_span': 1,\n",
              "      'col_span': 1,\n",
              "      'start_row_offset_idx': 1,\n",
              "      'end_row_offset_idx': 2,\n",
              "      'start_col_offset_idx': 4,\n",
              "      'end_col_offset_idx': 5,\n",
              "      'text': 'TableFormer (fast) *',\n",
              "      'column_header': False,\n",
              "      'row_header': False,\n",
              "      'row_section': False,\n",
              "      'fillable': False},\n",
              "     {'bbox': {'l': 182.502,\n",
              "       't': 112.09699999999998,\n",
              "       'r': 208.8,\n",
              "       'b': 119.79399999999998,\n",
              "       'coord_origin': 'TOPLEFT'},\n",
              "      'row_span': 1,\n",
              "      'col_span': 1,\n",
              "      'start_row_offset_idx': 2,\n",
              "      'end_row_offset_idx': 3,\n",
              "      'start_col_offset_idx': 0,\n",
              "      'end_col_offset_idx': 1,\n",
              "      'text': 'Marker',\n",
              "      'column_header': False,\n",
              "      'row_header': False,\n",
              "      'row_section': False,\n",
              "      'fillable': False},\n",
              "     {'bbox': {'l': 220.753,\n",
              "       't': 112.09699999999998,\n",
              "       'r': 243.169,\n",
              "       'b': 119.79399999999998,\n",
              "       'coord_origin': 'TOPLEFT'},\n",
              "      'row_span': 1,\n",
              "      'col_span': 1,\n",
              "      'start_row_offset_idx': 2,\n",
              "      'end_row_offset_idx': 3,\n",
              "      'start_col_offset_idx': 1,\n",
              "      'end_col_offset_idx': 2,\n",
              "      'text': '0.3.10',\n",
              "      'column_header': False,\n",
              "      'row_header': False,\n",
              "      'row_section': False,\n",
              "      'fillable': False},\n",
              "     {'bbox': {'l': 261.702,\n",
              "       't': 110.23400000000004,\n",
              "       'r': 285.606,\n",
              "       'b': 119.79399999999998,\n",
              "       'coord_origin': 'TOPLEFT'},\n",
              "      'row_span': 1,\n",
              "      'col_span': 1,\n",
              "      'start_row_offset_idx': 2,\n",
              "      'end_row_offset_idx': 3,\n",
              "      'start_col_offset_idx': 2,\n",
              "      'end_col_offset_idx': 3,\n",
              "      'text': 'Surya *',\n",
              "      'column_header': False,\n",
              "      'row_header': False,\n",
              "      'row_section': False,\n",
              "      'fillable': False},\n",
              "     {'bbox': {'l': 313.006,\n",
              "       't': 112.09699999999998,\n",
              "       'r': 337.816,\n",
              "       'b': 119.79399999999998,\n",
              "       'coord_origin': 'TOPLEFT'},\n",
              "      'row_span': 1,\n",
              "      'col_span': 1,\n",
              "      'start_row_offset_idx': 2,\n",
              "      'end_row_offset_idx': 3,\n",
              "      'start_col_offset_idx': 3,\n",
              "      'end_col_offset_idx': 4,\n",
              "      'text': 'default',\n",
              "      'column_header': False,\n",
              "      'row_header': False,\n",
              "      'row_section': False,\n",
              "      'fillable': False},\n",
              "     {'bbox': {'l': 379.492,\n",
              "       't': 112.09699999999998,\n",
              "       'r': 404.302,\n",
              "       'b': 119.79399999999998,\n",
              "       'coord_origin': 'TOPLEFT'},\n",
              "      'row_span': 1,\n",
              "      'col_span': 1,\n",
              "      'start_row_offset_idx': 2,\n",
              "      'end_row_offset_idx': 3,\n",
              "      'start_col_offset_idx': 4,\n",
              "      'end_col_offset_idx': 5,\n",
              "      'text': 'default',\n",
              "      'column_header': False,\n",
              "      'row_header': False,\n",
              "      'row_section': False,\n",
              "      'fillable': False},\n",
              "     {'bbox': {'l': 180.413,\n",
              "       't': 127.97299999999996,\n",
              "       'r': 208.801,\n",
              "       'b': 135.66999999999996,\n",
              "       'coord_origin': 'TOPLEFT'},\n",
              "      'row_span': 1,\n",
              "      'col_span': 1,\n",
              "      'start_row_offset_idx': 3,\n",
              "      'end_row_offset_idx': 4,\n",
              "      'start_col_offset_idx': 0,\n",
              "      'end_col_offset_idx': 1,\n",
              "      'text': 'MinerU',\n",
              "      'column_header': False,\n",
              "      'row_header': False,\n",
              "      'row_section': False,\n",
              "      'fillable': False},\n",
              "     {'bbox': {'l': 220.753,\n",
              "       't': 127.97299999999996,\n",
              "       'r': 238.686,\n",
              "       'b': 135.66999999999996,\n",
              "       'coord_origin': 'TOPLEFT'},\n",
              "      'row_span': 1,\n",
              "      'col_span': 1,\n",
              "      'start_row_offset_idx': 3,\n",
              "      'end_row_offset_idx': 4,\n",
              "      'start_col_offset_idx': 1,\n",
              "      'end_col_offset_idx': 2,\n",
              "      'text': '0.9.3',\n",
              "      'column_header': False,\n",
              "      'row_header': False,\n",
              "      'row_section': False,\n",
              "      'fillable': False},\n",
              "     {'bbox': {'l': 261.702,\n",
              "       't': 126.11000000000001,\n",
              "       'r': 280.127,\n",
              "       'b': 135.66999999999996,\n",
              "       'coord_origin': 'TOPLEFT'},\n",
              "      'row_span': 1,\n",
              "      'col_span': 1,\n",
              "      'start_row_offset_idx': 3,\n",
              "      'end_row_offset_idx': 4,\n",
              "      'start_col_offset_idx': 2,\n",
              "      'end_col_offset_idx': 3,\n",
              "      'text': 'auto *',\n",
              "      'column_header': False,\n",
              "      'row_header': False,\n",
              "      'row_section': False,\n",
              "      'fillable': False},\n",
              "     {'bbox': {'l': 313.006,\n",
              "       't': 127.97299999999996,\n",
              "       'r': 367.539,\n",
              "       'b': 135.66999999999996,\n",
              "       'coord_origin': 'TOPLEFT'},\n",
              "      'row_span': 1,\n",
              "      'col_span': 1,\n",
              "      'start_row_offset_idx': 3,\n",
              "      'end_row_offset_idx': 4,\n",
              "      'start_col_offset_idx': 3,\n",
              "      'end_col_offset_idx': 4,\n",
              "      'text': 'doclayout yolo',\n",
              "      'column_header': False,\n",
              "      'row_header': False,\n",
              "      'row_section': False,\n",
              "      'fillable': False},\n",
              "     {'bbox': {'l': 379.491,\n",
              "       't': 126.11000000000001,\n",
              "       'r': 421.567,\n",
              "       'b': 135.66999999999996,\n",
              "       'coord_origin': 'TOPLEFT'},\n",
              "      'row_span': 1,\n",
              "      'col_span': 1,\n",
              "      'start_row_offset_idx': 3,\n",
              "      'end_row_offset_idx': 4,\n",
              "      'start_col_offset_idx': 4,\n",
              "      'end_col_offset_idx': 5,\n",
              "      'text': 'rapid table *',\n",
              "      'column_header': False,\n",
              "      'row_header': False,\n",
              "      'row_section': False,\n",
              "      'fillable': False},\n",
              "     {'bbox': {'l': 161.987,\n",
              "       't': 142.938,\n",
              "       'r': 208.801,\n",
              "       'b': 150.635,\n",
              "       'coord_origin': 'TOPLEFT'},\n",
              "      'row_span': 1,\n",
              "      'col_span': 1,\n",
              "      'start_row_offset_idx': 4,\n",
              "      'end_row_offset_idx': 5,\n",
              "      'start_col_offset_idx': 0,\n",
              "      'end_col_offset_idx': 1,\n",
              "      'text': 'Unstructured',\n",
              "      'column_header': False,\n",
              "      'row_header': False,\n",
              "      'row_section': False,\n",
              "      'fillable': False},\n",
              "     {'bbox': {'l': 220.753,\n",
              "       't': 142.938,\n",
              "       'r': 243.169,\n",
              "       'b': 150.635,\n",
              "       'coord_origin': 'TOPLEFT'},\n",
              "      'row_span': 1,\n",
              "      'col_span': 1,\n",
              "      'start_row_offset_idx': 4,\n",
              "      'end_row_offset_idx': 5,\n",
              "      'start_col_offset_idx': 1,\n",
              "      'end_col_offset_idx': 2,\n",
              "      'text': '0.16.5',\n",
              "      'column_header': False,\n",
              "      'row_header': False,\n",
              "      'row_section': False,\n",
              "      'fillable': False},\n",
              "     {'bbox': {'l': 305.057,\n",
              "       't': 142.938,\n",
              "       'r': 406.656,\n",
              "       'b': 150.635,\n",
              "       'coord_origin': 'TOPLEFT'},\n",
              "      'row_span': 1,\n",
              "      'col_span': 2,\n",
              "      'start_row_offset_idx': 4,\n",
              "      'end_row_offset_idx': 5,\n",
              "      'start_col_offset_idx': 3,\n",
              "      'end_col_offset_idx': 5,\n",
              "      'text': 'hi res with table structure',\n",
              "      'column_header': False,\n",
              "      'row_header': False,\n",
              "      'row_section': False,\n",
              "      'fillable': False}],\n",
              "    'num_rows': 5,\n",
              "    'num_cols': 5,\n",
              "    'grid': [[{'bbox': {'l': 188.384,\n",
              "        't': 79.99400000000003,\n",
              "        'r': 208.8,\n",
              "        'b': 88.05499999999995,\n",
              "        'coord_origin': 'TOPLEFT'},\n",
              "       'row_span': 1,\n",
              "       'col_span': 1,\n",
              "       'start_row_offset_idx': 0,\n",
              "       'end_row_offset_idx': 1,\n",
              "       'start_col_offset_idx': 0,\n",
              "       'end_col_offset_idx': 1,\n",
              "       'text': 'Asset',\n",
              "       'column_header': True,\n",
              "       'row_header': False,\n",
              "       'row_section': False,\n",
              "       'fillable': False},\n",
              "      {'bbox': {'l': 220.753,\n",
              "        't': 79.99400000000003,\n",
              "        'r': 249.741,\n",
              "        'b': 88.05499999999995,\n",
              "        'coord_origin': 'TOPLEFT'},\n",
              "       'row_span': 1,\n",
              "       'col_span': 1,\n",
              "       'start_row_offset_idx': 0,\n",
              "       'end_row_offset_idx': 1,\n",
              "       'start_col_offset_idx': 1,\n",
              "       'end_col_offset_idx': 2,\n",
              "       'text': 'Version',\n",
              "       'column_header': True,\n",
              "       'row_header': False,\n",
              "       'row_section': False,\n",
              "       'fillable': False},\n",
              "      {'bbox': {'l': 261.702,\n",
              "        't': 79.99400000000003,\n",
              "        'r': 281.626,\n",
              "        'b': 88.05499999999995,\n",
              "        'coord_origin': 'TOPLEFT'},\n",
              "       'row_span': 1,\n",
              "       'col_span': 1,\n",
              "       'start_row_offset_idx': 0,\n",
              "       'end_row_offset_idx': 1,\n",
              "       'start_col_offset_idx': 2,\n",
              "       'end_col_offset_idx': 3,\n",
              "       'text': 'OCR',\n",
              "       'column_header': True,\n",
              "       'row_header': False,\n",
              "       'row_section': False,\n",
              "       'fillable': False},\n",
              "      {'bbox': {'l': 313.008,\n",
              "        't': 79.99400000000003,\n",
              "        'r': 340.185,\n",
              "        'b': 88.05499999999995,\n",
              "        'coord_origin': 'TOPLEFT'},\n",
              "       'row_span': 1,\n",
              "       'col_span': 1,\n",
              "       'start_row_offset_idx': 0,\n",
              "       'end_row_offset_idx': 1,\n",
              "       'start_col_offset_idx': 3,\n",
              "       'end_col_offset_idx': 4,\n",
              "       'text': 'Layout',\n",
              "       'column_header': True,\n",
              "       'row_header': False,\n",
              "       'row_section': False,\n",
              "       'fillable': False},\n",
              "      {'bbox': {'l': 379.494,\n",
              "        't': 79.99400000000003,\n",
              "        'r': 404.08,\n",
              "        'b': 88.05499999999995,\n",
              "        'coord_origin': 'TOPLEFT'},\n",
              "       'row_span': 1,\n",
              "       'col_span': 1,\n",
              "       'start_row_offset_idx': 0,\n",
              "       'end_row_offset_idx': 1,\n",
              "       'start_col_offset_idx': 4,\n",
              "       'end_col_offset_idx': 5,\n",
              "       'text': 'Tables',\n",
              "       'column_header': True,\n",
              "       'row_header': False,\n",
              "       'row_section': False,\n",
              "       'fillable': False}],\n",
              "     [{'bbox': {'l': 179.911,\n",
              "        't': 96.22000000000003,\n",
              "        'r': 208.801,\n",
              "        'b': 103.91700000000003,\n",
              "        'coord_origin': 'TOPLEFT'},\n",
              "       'row_span': 1,\n",
              "       'col_span': 1,\n",
              "       'start_row_offset_idx': 1,\n",
              "       'end_row_offset_idx': 2,\n",
              "       'start_col_offset_idx': 0,\n",
              "       'end_col_offset_idx': 1,\n",
              "       'text': 'Docling',\n",
              "       'column_header': False,\n",
              "       'row_header': False,\n",
              "       'row_section': False,\n",
              "       'fillable': False},\n",
              "      {'bbox': {'l': 220.753,\n",
              "        't': 96.22000000000003,\n",
              "        'r': 238.686,\n",
              "        'b': 103.91700000000003,\n",
              "        'coord_origin': 'TOPLEFT'},\n",
              "       'row_span': 1,\n",
              "       'col_span': 1,\n",
              "       'start_row_offset_idx': 1,\n",
              "       'end_row_offset_idx': 2,\n",
              "       'start_col_offset_idx': 1,\n",
              "       'end_col_offset_idx': 2,\n",
              "       'text': '2.5.2',\n",
              "       'column_header': False,\n",
              "       'row_header': False,\n",
              "       'row_section': False,\n",
              "       'fillable': False},\n",
              "      {'bbox': {'l': 261.703,\n",
              "        't': 94.35699999999997,\n",
              "        'r': 300.553,\n",
              "        'b': 103.91700000000003,\n",
              "        'coord_origin': 'TOPLEFT'},\n",
              "       'row_span': 1,\n",
              "       'col_span': 1,\n",
              "       'start_row_offset_idx': 1,\n",
              "       'end_row_offset_idx': 2,\n",
              "       'start_col_offset_idx': 2,\n",
              "       'end_col_offset_idx': 3,\n",
              "       'text': 'EasyOCR *',\n",
              "       'column_header': False,\n",
              "       'row_header': False,\n",
              "       'row_section': False,\n",
              "       'fillable': False},\n",
              "      {'bbox': {'l': 313.006,\n",
              "        't': 96.22000000000003,\n",
              "        'r': 337.816,\n",
              "        'b': 103.91700000000003,\n",
              "        'coord_origin': 'TOPLEFT'},\n",
              "       'row_span': 1,\n",
              "       'col_span': 1,\n",
              "       'start_row_offset_idx': 1,\n",
              "       'end_row_offset_idx': 2,\n",
              "       'start_col_offset_idx': 3,\n",
              "       'end_col_offset_idx': 4,\n",
              "       'text': 'default',\n",
              "       'column_header': False,\n",
              "       'row_header': False,\n",
              "       'row_section': False,\n",
              "       'fillable': False},\n",
              "      {'bbox': {'l': 379.492,\n",
              "        't': 94.35699999999997,\n",
              "        'r': 449.515,\n",
              "        'b': 103.91700000000003,\n",
              "        'coord_origin': 'TOPLEFT'},\n",
              "       'row_span': 1,\n",
              "       'col_span': 1,\n",
              "       'start_row_offset_idx': 1,\n",
              "       'end_row_offset_idx': 2,\n",
              "       'start_col_offset_idx': 4,\n",
              "       'end_col_offset_idx': 5,\n",
              "       'text': 'TableFormer (fast) *',\n",
              "       'column_header': False,\n",
              "       'row_header': False,\n",
              "       'row_section': False,\n",
              "       'fillable': False}],\n",
              "     [{'bbox': {'l': 182.502,\n",
              "        't': 112.09699999999998,\n",
              "        'r': 208.8,\n",
              "        'b': 119.79399999999998,\n",
              "        'coord_origin': 'TOPLEFT'},\n",
              "       'row_span': 1,\n",
              "       'col_span': 1,\n",
              "       'start_row_offset_idx': 2,\n",
              "       'end_row_offset_idx': 3,\n",
              "       'start_col_offset_idx': 0,\n",
              "       'end_col_offset_idx': 1,\n",
              "       'text': 'Marker',\n",
              "       'column_header': False,\n",
              "       'row_header': False,\n",
              "       'row_section': False,\n",
              "       'fillable': False},\n",
              "      {'bbox': {'l': 220.753,\n",
              "        't': 112.09699999999998,\n",
              "        'r': 243.169,\n",
              "        'b': 119.79399999999998,\n",
              "        'coord_origin': 'TOPLEFT'},\n",
              "       'row_span': 1,\n",
              "       'col_span': 1,\n",
              "       'start_row_offset_idx': 2,\n",
              "       'end_row_offset_idx': 3,\n",
              "       'start_col_offset_idx': 1,\n",
              "       'end_col_offset_idx': 2,\n",
              "       'text': '0.3.10',\n",
              "       'column_header': False,\n",
              "       'row_header': False,\n",
              "       'row_section': False,\n",
              "       'fillable': False},\n",
              "      {'bbox': {'l': 261.702,\n",
              "        't': 110.23400000000004,\n",
              "        'r': 285.606,\n",
              "        'b': 119.79399999999998,\n",
              "        'coord_origin': 'TOPLEFT'},\n",
              "       'row_span': 1,\n",
              "       'col_span': 1,\n",
              "       'start_row_offset_idx': 2,\n",
              "       'end_row_offset_idx': 3,\n",
              "       'start_col_offset_idx': 2,\n",
              "       'end_col_offset_idx': 3,\n",
              "       'text': 'Surya *',\n",
              "       'column_header': False,\n",
              "       'row_header': False,\n",
              "       'row_section': False,\n",
              "       'fillable': False},\n",
              "      {'bbox': {'l': 313.006,\n",
              "        't': 112.09699999999998,\n",
              "        'r': 337.816,\n",
              "        'b': 119.79399999999998,\n",
              "        'coord_origin': 'TOPLEFT'},\n",
              "       'row_span': 1,\n",
              "       'col_span': 1,\n",
              "       'start_row_offset_idx': 2,\n",
              "       'end_row_offset_idx': 3,\n",
              "       'start_col_offset_idx': 3,\n",
              "       'end_col_offset_idx': 4,\n",
              "       'text': 'default',\n",
              "       'column_header': False,\n",
              "       'row_header': False,\n",
              "       'row_section': False,\n",
              "       'fillable': False},\n",
              "      {'bbox': {'l': 379.492,\n",
              "        't': 112.09699999999998,\n",
              "        'r': 404.302,\n",
              "        'b': 119.79399999999998,\n",
              "        'coord_origin': 'TOPLEFT'},\n",
              "       'row_span': 1,\n",
              "       'col_span': 1,\n",
              "       'start_row_offset_idx': 2,\n",
              "       'end_row_offset_idx': 3,\n",
              "       'start_col_offset_idx': 4,\n",
              "       'end_col_offset_idx': 5,\n",
              "       'text': 'default',\n",
              "       'column_header': False,\n",
              "       'row_header': False,\n",
              "       'row_section': False,\n",
              "       'fillable': False}],\n",
              "     [{'bbox': {'l': 180.413,\n",
              "        't': 127.97299999999996,\n",
              "        'r': 208.801,\n",
              "        'b': 135.66999999999996,\n",
              "        'coord_origin': 'TOPLEFT'},\n",
              "       'row_span': 1,\n",
              "       'col_span': 1,\n",
              "       'start_row_offset_idx': 3,\n",
              "       'end_row_offset_idx': 4,\n",
              "       'start_col_offset_idx': 0,\n",
              "       'end_col_offset_idx': 1,\n",
              "       'text': 'MinerU',\n",
              "       'column_header': False,\n",
              "       'row_header': False,\n",
              "       'row_section': False,\n",
              "       'fillable': False},\n",
              "      {'bbox': {'l': 220.753,\n",
              "        't': 127.97299999999996,\n",
              "        'r': 238.686,\n",
              "        'b': 135.66999999999996,\n",
              "        'coord_origin': 'TOPLEFT'},\n",
              "       'row_span': 1,\n",
              "       'col_span': 1,\n",
              "       'start_row_offset_idx': 3,\n",
              "       'end_row_offset_idx': 4,\n",
              "       'start_col_offset_idx': 1,\n",
              "       'end_col_offset_idx': 2,\n",
              "       'text': '0.9.3',\n",
              "       'column_header': False,\n",
              "       'row_header': False,\n",
              "       'row_section': False,\n",
              "       'fillable': False},\n",
              "      {'bbox': {'l': 261.702,\n",
              "        't': 126.11000000000001,\n",
              "        'r': 280.127,\n",
              "        'b': 135.66999999999996,\n",
              "        'coord_origin': 'TOPLEFT'},\n",
              "       'row_span': 1,\n",
              "       'col_span': 1,\n",
              "       'start_row_offset_idx': 3,\n",
              "       'end_row_offset_idx': 4,\n",
              "       'start_col_offset_idx': 2,\n",
              "       'end_col_offset_idx': 3,\n",
              "       'text': 'auto *',\n",
              "       'column_header': False,\n",
              "       'row_header': False,\n",
              "       'row_section': False,\n",
              "       'fillable': False},\n",
              "      {'bbox': {'l': 313.006,\n",
              "        't': 127.97299999999996,\n",
              "        'r': 367.539,\n",
              "        'b': 135.66999999999996,\n",
              "        'coord_origin': 'TOPLEFT'},\n",
              "       'row_span': 1,\n",
              "       'col_span': 1,\n",
              "       'start_row_offset_idx': 3,\n",
              "       'end_row_offset_idx': 4,\n",
              "       'start_col_offset_idx': 3,\n",
              "       'end_col_offset_idx': 4,\n",
              "       'text': 'doclayout yolo',\n",
              "       'column_header': False,\n",
              "       'row_header': False,\n",
              "       'row_section': False,\n",
              "       'fillable': False},\n",
              "      {'bbox': {'l': 379.491,\n",
              "        't': 126.11000000000001,\n",
              "        'r': 421.567,\n",
              "        'b': 135.66999999999996,\n",
              "        'coord_origin': 'TOPLEFT'},\n",
              "       'row_span': 1,\n",
              "       'col_span': 1,\n",
              "       'start_row_offset_idx': 3,\n",
              "       'end_row_offset_idx': 4,\n",
              "       'start_col_offset_idx': 4,\n",
              "       'end_col_offset_idx': 5,\n",
              "       'text': 'rapid table *',\n",
              "       'column_header': False,\n",
              "       'row_header': False,\n",
              "       'row_section': False,\n",
              "       'fillable': False}],\n",
              "     [{'bbox': {'l': 161.987,\n",
              "        't': 142.938,\n",
              "        'r': 208.801,\n",
              "        'b': 150.635,\n",
              "        'coord_origin': 'TOPLEFT'},\n",
              "       'row_span': 1,\n",
              "       'col_span': 1,\n",
              "       'start_row_offset_idx': 4,\n",
              "       'end_row_offset_idx': 5,\n",
              "       'start_col_offset_idx': 0,\n",
              "       'end_col_offset_idx': 1,\n",
              "       'text': 'Unstructured',\n",
              "       'column_header': False,\n",
              "       'row_header': False,\n",
              "       'row_section': False,\n",
              "       'fillable': False},\n",
              "      {'bbox': {'l': 220.753,\n",
              "        't': 142.938,\n",
              "        'r': 243.169,\n",
              "        'b': 150.635,\n",
              "        'coord_origin': 'TOPLEFT'},\n",
              "       'row_span': 1,\n",
              "       'col_span': 1,\n",
              "       'start_row_offset_idx': 4,\n",
              "       'end_row_offset_idx': 5,\n",
              "       'start_col_offset_idx': 1,\n",
              "       'end_col_offset_idx': 2,\n",
              "       'text': '0.16.5',\n",
              "       'column_header': False,\n",
              "       'row_header': False,\n",
              "       'row_section': False,\n",
              "       'fillable': False},\n",
              "      {'row_span': 1,\n",
              "       'col_span': 1,\n",
              "       'start_row_offset_idx': 4,\n",
              "       'end_row_offset_idx': 5,\n",
              "       'start_col_offset_idx': 2,\n",
              "       'end_col_offset_idx': 3,\n",
              "       'text': '',\n",
              "       'column_header': False,\n",
              "       'row_header': False,\n",
              "       'row_section': False,\n",
              "       'fillable': False},\n",
              "      {'bbox': {'l': 305.057,\n",
              "        't': 142.938,\n",
              "        'r': 406.656,\n",
              "        'b': 150.635,\n",
              "        'coord_origin': 'TOPLEFT'},\n",
              "       'row_span': 1,\n",
              "       'col_span': 2,\n",
              "       'start_row_offset_idx': 4,\n",
              "       'end_row_offset_idx': 5,\n",
              "       'start_col_offset_idx': 3,\n",
              "       'end_col_offset_idx': 5,\n",
              "       'text': 'hi res with table structure',\n",
              "       'column_header': False,\n",
              "       'row_header': False,\n",
              "       'row_section': False,\n",
              "       'fillable': False},\n",
              "      {'bbox': {'l': 305.057,\n",
              "        't': 142.938,\n",
              "        'r': 406.656,\n",
              "        'b': 150.635,\n",
              "        'coord_origin': 'TOPLEFT'},\n",
              "       'row_span': 1,\n",
              "       'col_span': 2,\n",
              "       'start_row_offset_idx': 4,\n",
              "       'end_row_offset_idx': 5,\n",
              "       'start_col_offset_idx': 3,\n",
              "       'end_col_offset_idx': 5,\n",
              "       'text': 'hi res with table structure',\n",
              "       'column_header': False,\n",
              "       'row_header': False,\n",
              "       'row_section': False,\n",
              "       'fillable': False}]]},\n",
              "   'annotations': []}],\n",
              " 'key_value_items': [],\n",
              " 'form_items': [],\n",
              " 'pages': {'1': {'size': {'width': 612.0, 'height': 792.0}, 'page_no': 1},\n",
              "  '2': {'size': {'width': 612.0, 'height': 792.0}, 'page_no': 2},\n",
              "  '3': {'size': {'width': 612.0, 'height': 792.0}, 'page_no': 3},\n",
              "  '4': {'size': {'width': 612.0, 'height': 792.0}, 'page_no': 4},\n",
              "  '5': {'size': {'width': 612.0, 'height': 792.0}, 'page_no': 5},\n",
              "  '6': {'size': {'width': 612.0, 'height': 792.0}, 'page_no': 6},\n",
              "  '7': {'size': {'width': 612.0, 'height': 792.0}, 'page_no': 7},\n",
              "  '8': {'size': {'width': 612.0, 'height': 792.0}, 'page_no': 8}}}"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "296cf9bc"
      },
      "source": [
        "## Summarize DoclingDocument Structure"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b9544e28"
      },
      "source": [
        "import json\n",
        "\n",
        "# Create a dictionary with key information from the doc object\n",
        "doc_summary = {\n",
        "    \"schema_name\": doc.schema_name,\n",
        "    \"version\": doc.version,\n",
        "    \"name\": doc.name,\n",
        "    \"origin\": doc.origin.model_dump() if doc.origin else None, # Include origin details\n",
        "    \"furniture_item_count\": len(doc.furniture.children) if doc.furniture and hasattr(doc.furniture, 'children') else 0, # Count furniture items\n",
        "    \"body_item_count\": len(doc.body.children) if doc.body and hasattr(doc.body, 'children') else 0, # Count body items\n",
        "    \"text_count\": len(doc.texts), # Count text items\n",
        "    \"table_count\": len(doc.tables), # Count table items\n",
        "    \"picture_count\": len(doc.pictures), # Count picture items\n",
        "    \"group_count\": len(doc.groups), # Count group items\n",
        "    # You can add other top-level attributes if needed\n",
        "    # \"metadata\": doc.metadata.model_dump() if doc.metadata else None,\n",
        "}\n",
        "\n",
        "# Convert the dictionary to a JSON string with indentation for pretty printing\n",
        "doc_json_summary = json.dumps(doc_summary, indent=4)\n",
        "\n",
        "print(doc_json_summary)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6c98a42f"
      },
      "source": [
        "### Exploring Text Elements"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "display(doc.texts[0].model_dump())"
      ],
      "metadata": {
        "id": "G_NHptScWafd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "514f7e44"
      },
      "source": [
        "print(\"Exploring Text Elements:\")\n",
        "# Iterate through the text items in the document\n",
        "for i, text_item in enumerate(doc.texts[:10]): # Limit to the first 10 items\n",
        "    print(f\"Text Item {i}:\")\n",
        "    print(f\"  Label: {text_item.label}\")\n",
        "    # Print the first 200 characters of the text to avoid overly long output\n",
        "    print(f\"  Text: {text_item.text[:200]}...\")\n",
        "    if hasattr(text_item, 'prov'):\n",
        "        print(f\"  Provenance (first item): Page {text_item.prov[0].page_no}, Bbox: {text_item.prov[0].bbox}\")\n",
        "    print(\"-\" * 20)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f78a9061"
      },
      "source": [
        "### Exploring Table Elements"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d2a546f6"
      },
      "source": [
        "print(\"Exploring Table Elements:\")\n",
        "# Iterate through the table items in the document\n",
        "for i, table_item in enumerate(doc.tables):\n",
        "    print(f\"Table Item {i}:\")\n",
        "    print(f\"  Label: {table_item.label}\")\n",
        "    if hasattr(table_item, 'prov'):\n",
        "        print(f\"  Provenance (first item): Page {table_item.prov[0].page_no}, Bbox: {table_item.prov[0].bbox}\")\n",
        "\n",
        "    # Displaying table data can be complex, here's a simple representation\n",
        "    if hasattr(table_item, 'data') and hasattr(table_item.data, 'table_cells'):\n",
        "        print(f\"  Number of cells: {len(table_item.data.table_cells)}\")\n",
        "        # You can add code here to extract and display table data more formally (like a DataFrame)\n",
        "        # as shown in the previous examples.\n",
        "    print(\"-\" * 20)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ef89ef46"
      },
      "source": [
        "### Exploring Picture Elements"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4f3e432d"
      },
      "source": [
        "print(\"Exploring Picture Elements:\")\n",
        "# Iterate through the picture items in the document\n",
        "for i, picture_item in enumerate(doc.pictures):\n",
        "    print(f\"Picture Item {i}:\")\n",
        "    print(f\"  Label: {picture_item.label}\")\n",
        "    if hasattr(picture_item, 'prov'):\n",
        "        print(f\"  Provenance (first item): Page {picture_item.prov[0].page_no}, Bbox: {picture_item.prov[0].bbox}\")\n",
        "    # You can add code here to display the image as shown in the previous examples.\n",
        "    print(\"-\" * 20)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7b5f3ecf"
      },
      "source": [
        "## Visualize Bounding Boxes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c7edc87a"
      },
      "source": [
        "from PIL import Image, ImageDraw\n",
        "import matplotlib.pyplot as plt\n",
        "import io # Import the io module for handling byte streams\n",
        "\n",
        "# Assuming the document is a PDF, you might need a way to get an image of a specific page.\n",
        "# Docling might provide a method for this, or you might need another library like pypdfium2.\n",
        "# For demonstration, let's assume you have an image file of a page.\n",
        "# Replace 'path/to/your/page_image.png' with the actual path to your image file.\n",
        "# If the source is a PDF, you can use pypdfium2 to render a page to an image.\n",
        "\n",
        "# Example using pypdfium2 (install with !pip install pypdfium2)\n",
        "import pypdfium2 as pdfium\n",
        "\n",
        "# Load the PDF document\n",
        "pdf = pdfium.PdfDocument(source)\n",
        "\n",
        "# --- Specify the page number here (0-indexed) ---\n",
        "page_index = 4\n",
        "# -------------------------------------------------\n",
        "\n",
        "page = pdf.get_page(page_index)\n",
        "\n",
        "# Render the page to a PdfBitmap and then convert to PIL Image using to_pil()\n",
        "bitmap = page.render(scale=2) # Scale up for better resolution\n",
        "pil_image = bitmap.to_pil()\n",
        "\n",
        "\n",
        "# Create a drawing object\n",
        "draw = ImageDraw.Draw(pil_image)\n",
        "\n",
        "# Iterate through the elements in the document and draw their bounding boxes\n",
        "# You can choose which elements to visualize (e.g., texts, tables, figures)\n",
        "# We will check the provenance to ensure the element is on the selected page\n",
        "for item in doc.texts + doc.tables + doc.pictures + doc.groups: # Include all relevant item types\n",
        "    if hasattr(item, 'prov'): # Check if the item has provenance information\n",
        "        for prov_item in item.prov:\n",
        "            if prov_item.page_no == page_index + 1: # Check if the provenance item is on the current page (page_no is 1-indexed)\n",
        "                bbox = prov_item.bbox\n",
        "                # Convert the bbox coordinates to the image's coordinate system (top-left origin)\n",
        "                # Docling uses BOTTOMLEFT, Pillow uses TOPLEFT\n",
        "                img_width, img_height = pil_image.size\n",
        "\n",
        "                # Assuming bbox coordinates are relative to the bottom-left of the page and scaled to 1\n",
        "                # You might need to scale the bbox coordinates by the image dimensions\n",
        "                # Example:\n",
        "                page_width = page.get_width()\n",
        "                page_height = page.get_height()\n",
        "                scale_x = img_width / page_width\n",
        "                scale_y = img_height / page_height\n",
        "\n",
        "                top_left_x = bbox.l * scale_x\n",
        "                top_left_y = img_height - (bbox.t * scale_y) # Flip y-axis\n",
        "                bottom_right_x = bbox.r * scale_x\n",
        "                bottom_right_y = img_height - (bbox.b * scale_y) # Flip y-axis\n",
        "\n",
        "\n",
        "                # Draw the rectangle\n",
        "                # You can customize the color and width based on item type if you want\n",
        "                color = \"red\"\n",
        "                if item in doc.tables:\n",
        "                    color = \"blue\"\n",
        "                elif item in doc.pictures:\n",
        "                    color = \"green\"\n",
        "                elif item in doc.groups:\n",
        "                    color = \"purple\"\n",
        "\n",
        "                draw.rectangle([top_left_x, top_left_y, bottom_right_x, bottom_right_y], outline=color, width=2)\n",
        "\n",
        "# Display the image\n",
        "plt.figure(figsize=(10, 10))\n",
        "plt.imshow(pil_image)\n",
        "plt.axis('off')\n",
        "plt.show()\n",
        "\n",
        "# Don't forget to close the PDF document\n",
        "pdf.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "120f79be"
      },
      "source": [
        "## Extract Images and Charts with Associated Text"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "55ad1f37"
      },
      "source": [
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "import pypdfium2 as pdfium # Import pypdfium2\n",
        "\n",
        "# Get the page index and the rendered image from the previous visualization cell\n",
        "# Make sure to run the visualization cell first to set these variables\n",
        "try:\n",
        "    page_to_extract = page_index + 1 # Convert 0-indexed page_index to 1-indexed page_no\n",
        "    pil_image_page = pil_image # Use the PIL image of the page from the previous cell\n",
        "    # Re-obtain the page object within this cell\n",
        "    pdf = pdfium.PdfDocument(source) # Load the PDF again\n",
        "    page = pdf.get_page(page_index) # Get the specific page\n",
        "except NameError:\n",
        "    print(\"Please run the visualization cell first to define 'page_index' and generate 'pil_image'.\")\n",
        "    page_to_extract = None\n",
        "    pil_image_page = None\n",
        "    page = None # Ensure page is None if previous variables are not set\n",
        "\n",
        "if page_to_extract is not None and pil_image_page is not None and page is not None:\n",
        "    print(f\"Extracting images and charts from page {page_to_extract}:\")\n",
        "    for item in doc.pictures:\n",
        "        # Check if the item is on the specified page\n",
        "        item_on_page = False\n",
        "        if hasattr(item, 'prov'):\n",
        "            for prov_item in item.prov:\n",
        "                if prov_item.page_no == page_to_extract:\n",
        "                    item_on_page = True\n",
        "                    bbox = prov_item.bbox # Get the bounding box\n",
        "                    break # Found provenance on the target page, no need to check further\n",
        "\n",
        "        if item_on_page:\n",
        "            print(f\"\\nFound image or chart:\")\n",
        "            if bbox:\n",
        "                # Convert the bbox coordinates to the image's coordinate system (top-left origin)\n",
        "                # Docling uses BOTTOMLEFT, Pillow uses TOPLEFT\n",
        "                img_width, img_height = pil_image_page.size\n",
        "                page_width = page.get_width()\n",
        "                page_height = page.get_height()\n",
        "                scale_x = img_width / page_width\n",
        "                scale_y = img_height / page_height\n",
        "\n",
        "                top_left_x = bbox.l * scale_x\n",
        "                top_left_y = img_height - (bbox.t * scale_y) # Flip y-axis\n",
        "                bottom_right_x = bbox.r * scale_x\n",
        "                bottom_right_y = img_height - (bbox.b * scale_y) # Flip y-axis\n",
        "\n",
        "                # Crop the image using the bounding box\n",
        "                try:\n",
        "                    cropped_img = pil_image_page.crop((top_left_x, top_left_y, bottom_right_x, bottom_right_y))\n",
        "                    display(cropped_img)\n",
        "\n",
        "                    # Attempt to find and print associated text\n",
        "                    associated_text = []\n",
        "                    if hasattr(item, 'children'):\n",
        "                        for child_ref in item.children:\n",
        "                            # Assuming children are text references\n",
        "                            if child_ref.cref.startswith('#/texts/'):\n",
        "                                text_index = int(child_ref.cref.split('/')[-1])\n",
        "                                if text_index < len(doc.texts):\n",
        "                                    associated_text.append(doc.texts[text_index].text)\n",
        "                    # Also check for captions attribute if available\n",
        "                    if hasattr(item, 'captions'):\n",
        "                        for caption_ref in item.captions:\n",
        "                              if caption_ref.cref.startswith('#/texts/'):\n",
        "                                text_index = int(caption_ref.cref.split('/')[-1])\n",
        "                                if text_index < len(doc.texts):\n",
        "                                    associated_text.append(doc.texts[text_index].text)\n",
        "\n",
        "                    if associated_text:\n",
        "                        print(\"Associated Text:\")\n",
        "                        for text in associated_text:\n",
        "                            print(text)\n",
        "                    else:\n",
        "                        print(\"No directly associated text found in children or captions.\")\n",
        "\n",
        "\n",
        "                except Exception as e:\n",
        "                    print(f\"Could not crop or display image: {e}\")\n",
        "            else:\n",
        "                print(\"No bounding box found for this image item.\")\n",
        "\n",
        "    # Don't forget to close the PDF document\n",
        "    pdf.close()\n",
        "else:\n",
        "    print(\"Could not proceed with image extraction because required variables or page object were not available.\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c8da9d2a"
      },
      "source": [
        "## Extract Table Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f409d295"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Get the page index from the previous cell\n",
        "# Make sure to run the previous cell first to set the page_index variable\n",
        "try:\n",
        "    page_to_extract = page_index + 1 # Convert 0-indexed page_index to 1-indexed page_no\n",
        "except NameError:\n",
        "    print(\"Please run the previous cell first to define 'page_index'.\")\n",
        "    page_to_extract = None\n",
        "\n",
        "if page_to_extract is not None:\n",
        "    print(f\"Extracting tables from page {page_to_extract}:\")\n",
        "    for table_item in doc.tables:\n",
        "        # Check if the table is on the specified page\n",
        "        table_on_page = False\n",
        "        if hasattr(table_item, 'prov'):\n",
        "            for prov_item in table_item.prov:\n",
        "                if prov_item.page_no == page_to_extract:\n",
        "                    table_on_page = True\n",
        "                    break # Found provenance on the target page, no need to check further\n",
        "\n",
        "        if table_on_page:\n",
        "            print(f\"\\nFound table:\")\n",
        "            # Extract table data into a list of lists\n",
        "            table_data = []\n",
        "            if hasattr(table_item, 'data') and hasattr(table_item.data, 'table_cells'):\n",
        "                # Sort cells by row and then by column for correct order\n",
        "                sorted_cells = sorted(table_item.data.table_cells, key=lambda cell: (cell.start_row_offset_idx, cell.start_col_offset_idx))\n",
        "\n",
        "                # Determine the number of rows and columns\n",
        "                max_row = max(cell.end_row_offset_idx for cell in sorted_cells) if sorted_cells else 0\n",
        "                max_col = max(cell.end_col_offset_idx for cell in sorted_cells) if sorted_cells else 0\n",
        "\n",
        "                # Initialize table_data with empty strings\n",
        "                table_data = [['' for _ in range(max_col)] for _ in range(max_row)]\n",
        "\n",
        "                # Fill table_data with cell text, considering row and column spans\n",
        "                for cell in sorted_cells:\n",
        "                    for r in range(cell.start_row_offset_idx, cell.end_row_offset_idx):\n",
        "                        for c in range(cell.start_col_offset_idx, cell.end_col_offset_idx):\n",
        "                            if r < max_row and c < max_col: # Ensure within bounds\n",
        "                                table_data[r][c] = cell.text\n",
        "\n",
        "            # Display the table data, for example as a pandas DataFrame\n",
        "            if table_data:\n",
        "                try:\n",
        "                    df = pd.DataFrame(table_data)\n",
        "                    display(df)\n",
        "                except Exception as e:\n",
        "                    print(f\"Could not display table as DataFrame: {e}\")\n",
        "                    print(\"Raw table data:\")\n",
        "                    print(table_data)\n",
        "            else:\n",
        "                print(\"No cells found for this table.\")"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}